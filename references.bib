@misc{101HealthResearch,
  title = {101 {{Health Research}} \& {{Statistics}} \textendash{} {{Quality}}. {{Efficiency}}. {{Ethics}}. {{Teamwork}}.},
  urldate = {2023-07-17},
  langid = {american}
}

@misc{14:00-17:00ISO92412102019,
  title = {{{ISO}} 9241-210:2019},
  shorttitle = {{{ISO}} 9241-210},
  author = {{14:00-17:00}},
  journal = {ISO},
  urldate = {2023-10-06},
  abstract = {Ergonomics of human-system interaction \textemdash{} Part 210: Human-centred design for interactive systems},
  howpublished = {https://www.iso.org/standard/77520.html},
  langid = {english}
}

@misc{8guildSearchDownloadFree,
  title = {Search and Download {{Free}} Vector Icons, Stickers, Illustrations, {{UI Kits}} and More},
  author = {8Guild and {madebyoliver}},
  journal = {Smashicons | The largest icon set in the world.},
  urldate = {2023-10-03},
  abstract = {More free graphic design resources than you can shake a stick at. Get access to over 526,301 icons and thousands of design resources available in PNG, SVG, EPS and SKETCH formats.},
  howpublished = {http://www.smashicons.com/},
  langid = {english}
}

@article{alburyGenderConsolidatedCriteria2021,
  title = {Gender in the Consolidated Criteria for Reporting Qualitative Research ({{COREQ}}) Checklist},
  author = {Albury, Charlotte and Pope, Catherine and Shaw, Sara and Greenhalgh, Trisha and Ziebland, Sue and Martin, Sam and Rai, Tanvi and Chisholm, Alison and Barnes, Rebecca and White, Ashley and Wanat, Marta and Santillo, Marta and Boylan, Anne-marie and Tremblett, Madeline and {Tonkin-crine}, Sarah and Borek, Aleksandra and Sanders, Ruth and Koutoukidis, Dimitrios and Scragg, Jadine and Lee, Charlotte and Russell, Siabhainn and Mikulak, Magdalena and Logan, Mary and Spratt, Tanisha and {Livingston-banks}, Jonathan and Mcniven, Abigall and Stepney, Melissa and Talbot, Amelia and Crocker, Joanna and Powell, John and Paparini, Sara and {Van der westhuizen}, Helene-mari and Walumbe, Jackie and Newhouse, Nicola and Ryan, Sara and Webb, Helena and Mellor, Katie and Potter, Caroline and Butler, Ailsa and Pilbeam, Caitlin},
  year = {2021},
  month = oct,
  journal = {International Journal for Quality in Health Care},
  volume = {33},
  number = {4},
  pages = {mzab123},
  issn = {1353-4505},
  doi = {10.1093/intqhc/mzab123},
  urldate = {2023-08-08},
  file = {/Users/james/Library/Mobile Documents/iCloud~QReader~MarginStudy/Documents/DPhil/Albury et al_2021_Gender in the consolidated criteria for reporting qualitative research (COREQ).pdf}
}

@article{allisonComprehensiveFrameworkEvaluate2019,
  title = {A {{Comprehensive Framework}} to {{Evaluate Websites}}: {{Literature Review}} and {{Development}} of {{GoodWeb}}},
  shorttitle = {A {{Comprehensive Framework}} to {{Evaluate Websites}}},
  author = {Allison, Rosalie and Hayes, Catherine and McNulty, Cliodna A M and Young, Vicki},
  year = {2019},
  month = oct,
  journal = {JMIR Formative Research},
  volume = {3},
  number = {4},
  pages = {e14372},
  issn = {2561-326X},
  doi = {10.2196/14372},
  urldate = {2023-08-01},
  abstract = {Background Attention is turning toward increasing the quality of websites and quality evaluation to attract new users and retain existing users. Objective This scoping study aimed to review and define existing worldwide methodologies and techniques to evaluate websites and provide a framework of appropriate website attributes that could be applied to any future website evaluations. Methods We systematically searched electronic databases and gray literature for studies of website evaluation. The results were exported to EndNote software, duplicates were removed, and eligible studies were identified. The results have been presented in narrative form. Results A total of 69 studies met the inclusion criteria. The extracted data included type of website, aim or purpose of the study, study populations (users and experts), sample size, setting (controlled environment and remotely assessed), website attributes evaluated, process of methodology, and process of analysis. Methods of evaluation varied and included questionnaires, observed website browsing, interviews or focus groups, and Web usage analysis. Evaluations using both users and experts and controlled and remote settings are represented. Website attributes that were examined included usability or ease of use, content, design criteria, functionality, appearance, interactivity, satisfaction, and loyalty. Website evaluation methods should be tailored to the needs of specific websites and individual aims of evaluations. GoodWeb, a website evaluation guide, has been presented with a case scenario. Conclusions This scoping study supports the open debate of defining the quality of websites, and there are numerous approaches and models to evaluate it. However, as this study provides a framework of the existing literature of website evaluation, it presents a guide of options for evaluating websites, including which attributes to analyze and options for appropriate methods.},
  pmcid = {PMC6914275},
  pmid = {31651406},
  file = {/Users/james/Library/Mobile Documents/iCloud~QReader~MarginStudy/Documents/DPhil/Allison et al_2019_A Comprehensive Framework to Evaluate Websites.pdf}
}

@article{altmanBetterReportingRandomised1996,
  title = {Better Reporting of Randomised Controlled Trials: The {{CONSORT}} Statement},
  shorttitle = {Better Reporting of Randomised Controlled Trials},
  author = {Altman, D. G.},
  year = {1996},
  month = sep,
  journal = {BMJ (Clinical research ed.)},
  volume = {313},
  number = {7057},
  pages = {570--571},
  issn = {0959-8138},
  doi = {10.1136/bmj.313.7057.570},
  langid = {english},
  pmcid = {PMC2352018},
  pmid = {8806240},
  keywords = {Periodicals as Topic,Publishing,Randomized Controlled Trials as Topic},
  file = {/Users/james/Zotero/storage/KVZIG6MN/Altman - 1996 - Better reporting of randomised controlled trials .pdf}
}

@article{altmanHistoryEvolutionGuidelines2016a,
  title = {A History of the Evolution of Guidelines for Reporting Medical Research: The Long Road to the {{EQUATOR Network}}},
  shorttitle = {A History of the Evolution of Guidelines for Reporting Medical Research},
  author = {Altman, Douglas G and Simera, Iveta},
  year = {2016},
  month = feb,
  journal = {Journal of the Royal Society of Medicine},
  volume = {109},
  number = {2},
  pages = {67--77},
  issn = {0141-0768},
  doi = {10.1177/0141076815625599},
  urldate = {2023-08-15},
  pmcid = {PMC4793768},
  pmid = {26880653},
  file = {/Users/james/Library/Mobile Documents/iCloud~QReader~MarginStudy/Documents/DPhil/Altman_Simera_2016_A history of the evolution of guidelines for reporting medical research.pdf}
}

@article{altmanReportingRecommendationsTumor2012,
  title = {Reporting {{Recommendations}} for {{Tumor Marker Prognostic Studies}} ({{REMARK}}): Explanation and Elaboration},
  shorttitle = {Reporting {{Recommendations}} for {{Tumor Marker Prognostic Studies}} ({{REMARK}})},
  author = {Altman, Douglas G. and McShane, Lisa M. and Sauerbrei, Willi and Taube, Sheila E.},
  year = {2012},
  journal = {PLoS medicine},
  volume = {9},
  number = {5},
  pages = {e1001216},
  issn = {1549-1676},
  doi = {10.1371/journal.pmed.1001216},
  abstract = {The REMARK (Reporting Recommendations for Tumor Marker Prognostic Studies) guideline includes a checklist which aims to improve the reporting of these types of studies. Here, we expand on the REMARK checklist to enhance its use and effectiveness through better understanding of the intent of each item and why the information is important to report. Each checklist item of the REMARK guideline is explained in detail and accompanied by published examples of good reporting. The paper provides a comprehensive overview to educate on good reporting and provide a valuable reference of issues to consider when designing, conducting, and analyzing tumor marker studies and prognostic studies in medicine in general.},
  langid = {english},
  pmcid = {PMC3362085},
  pmid = {22675273},
  keywords = {{Biomarkers, Tumor},Biomedical Research,Checklist,Guidelines as Topic,Humans,Neoplasms,Prognosis,Publishing,Research Design,Research Report},
  file = {/Users/james/Library/Mobile Documents/iCloud~QReader~MarginStudy/Documents/DPhil/Altman et al_2012_Reporting Recommendations for Tumor Marker Prognostic Studies (REMARK).pdf}
}

@article{altmanRevisedCONSORTStatement2001,
  title = {The {{Revised CONSORT Statement}} for {{Reporting Randomized Trials}}: {{Explanation}} and {{Elaboration}}},
  shorttitle = {The {{Revised CONSORT Statement}} for {{Reporting Randomized Trials}}},
  author = {Altman, Douglas G. and Schulz, Kenneth F. and Moher, David and Egger, Matthias and Davidoff, Frank and Elbourne, Diana and G{\o}tzsche, Peter C. and Lang, Thomas},
  year = {2001},
  month = apr,
  journal = {Annals of Internal Medicine},
  volume = {134},
  number = {8},
  pages = {663--694},
  publisher = {{American College of Physicians}},
  issn = {0003-4819},
  doi = {10.7326/0003-4819-134-8-200104170-00012},
  urldate = {2023-10-23}
}

@misc{alvesGlobalIndexMedicus,
  title = {Global {{Index Medicus}} \textendash{} {{World Health Organization}}},
  author = {Alves, BIREME / OPAS / OMS-M{\'a}rcio},
  urldate = {2021-02-19},
  abstract = {World Health Organization},
  langid = {american}
}

@misc{AnalyticsToolsSolutions,
  title = {Analytics {{Tools}} \& {{Solutions}} for {{Your Business}} \textendash{} {{Google Analytics}}},
  journal = {Google Marketing Platform},
  urldate = {2022-07-27},
  abstract = {Google Analytics gives you the tools you need to better understand your customers. You can then use those business insights to take action, such as improving your website, creating tailored audience lists and more.},
  howpublished = {https://marketingplatform.google.com/intl/en\_uk/about/analytics/},
  langid = {english}
}

@misc{AnalyticsToolsSolutionsa,
  title = {Analytics {{Tools}} \& {{Solutions}} for {{Your Business}} \textendash{} {{Google Analytics}}},
  journal = {Google Marketing Platform},
  urldate = {2023-07-31},
  abstract = {Google Analytics gives you the tools you need to better understand your customers. You can then use those business insights to take action, such as improving your website, creating tailored audience lists and more.},
  howpublished = {https://marketingplatform.google.com/intl/en\_uk/about/analytics/},
  langid = {english}
}

@misc{APAPsycNetFullTextHTML,
  title = {{{APA PsycNet FullTextHTML}} Page},
  urldate = {2023-06-28},
  howpublished = {https://psycnet.apa.org/fulltext/2018-00750-002.html},
  file = {/Users/james/Zotero/storage/MVVNVB8Z/2018-00750-002.html}
}

@article{appelbaumJournalArticleReporting2018,
  title = {Journal Article Reporting Standards for Quantitative Research in Psychology: {{The APA Publications}} and {{Communications Board}} Task Force Report.},
  shorttitle = {Journal Article Reporting Standards for Quantitative Research in Psychology},
  author = {Appelbaum, Mark and Cooper, Harris and Kline, Rex B. and {Mayo-Wilson}, Evan and Nezu, Arthur M. and Rao, Stephen M.},
  year = {2018},
  month = jan,
  journal = {American Psychologist},
  volume = {73},
  number = {1},
  pages = {3--25},
  issn = {1935-990X, 0003-066X},
  doi = {10.1037/amp0000191},
  urldate = {2023-06-28},
  abstract = {Following a review of extant reporting standards for scientific publication, and reviewing 10 years of experience since publication of the first set of reporting standards by the American Psychological Association (APA; APA Publications and Communications Board Working Group on Journal Article Reporting Standards, 2008), the APA Working Group on Quantitative Research Reporting Standards recommended some modifications to the original standards. Examples of modifications include division of hypotheses, analyses, and conclusions into 3 groupings (primary, secondary, and exploratory) and some changes to the section on meta-analysis. Several new modules are included that report standards for observational studies, clinical trials, longitudinal studies, replication studies, and N-of-1 studies. In addition, standards for analytic methods with unique characteristics and output (structural equation modeling and Bayesian analysis) are included. These proposals were accepted by the Publications and Communications Board of APA and supersede the standards included in the 6th edition of the Publication Manual of the American Psychological Association (APA, 2010).},
  langid = {english},
  file = {/Users/james/Zotero/storage/N6Z3I76M/Appelbaum et al. - 2018 - Journal article reporting standards for quantitati.pdf}
}

@misc{ARINHomePage,
  title = {{{ARIN}} Home Page},
  journal = {ARIN},
  urldate = {2023-07-17},
  abstract = {This site describes the Background to ARIN, What is ARIN, and its objectives},
  howpublished = {https://africarinetwork.wixsite.com/website},
  langid = {english}
}

@article{atkinsGuideUsingTheoretical2017,
  title = {A Guide to Using the {{Theoretical Domains Framework}} of Behaviour Change to Investigate Implementation Problems},
  author = {Atkins, Lou and Francis, Jill and Islam, Rafat and O'Connor, Denise and Patey, Andrea and Ivers, Noah and Foy, Robbie and Duncan, Eilidh M. and Colquhoun, Heather and Grimshaw, Jeremy M. and Lawton, Rebecca and Michie, Susan},
  year = {2017},
  month = jun,
  journal = {Implementation Science},
  volume = {12},
  number = {1},
  pages = {77},
  issn = {1748-5908},
  doi = {10.1186/s13012-017-0605-9},
  urldate = {2023-07-14},
  abstract = {Implementing new practices requires changes in the behaviour of relevant actors, and this is facilitated by understanding of the determinants of current and desired behaviours. The Theoretical Domains Framework (TDF) was developed by a collaboration of behavioural scientists and implementation researchers who identified theories relevant to implementation and grouped constructs from these theories into domains. The collaboration aimed to provide a comprehensive, theory-informed approach to identify determinants of behaviour. The first version was published in 2005, and a subsequent version following a validation exercise was published in 2012. This guide offers practical guidance for those who wish to apply the TDF to assess implementation problems and support intervention design. It presents a brief rationale for using a theoretical approach to investigate and address implementation problems, summarises the TDF and its development, and describes how to apply the TDF to achieve implementation objectives. Examples from the implementation research literature are presented to illustrate relevant methods and practical considerations.},
  keywords = {Guide,Methods,Theoretical Domains Framework},
  file = {/Users/james/Library/Mobile Documents/iCloud~QReader~MarginStudy/Documents/DPhil/Atkins et al_2017_A guide to using the Theoretical Domains Framework of behaviour change to.pdf}
}

@misc{AuthorAIDHome,
  title = {{{AuthorAID}} - {{Home}}},
  urldate = {2020-02-14},
  howpublished = {https://www.authoraid.info/en/},
  file = {/Users/james/Zotero/storage/WTUNHUFN/en.html}
}

@misc{AuthorAIDHomea,
  title = {{{AuthorAID}} - {{Home}}},
  urldate = {2023-07-17},
  howpublished = {https://www.authoraid.info/en/}
}

@article{babatundeDevelopmentUsabilityTesting2020,
  title = {Development and {{Usability Testing}} of a {{Web-Based}} and {{Therapist-Assisted Coping Skills Program}} for {{Managing Psychosocial Problems}} in {{Individuals With Hand}} and {{Upper Limb Injuries}}: {{Mixed Methods Study}}},
  shorttitle = {Development and {{Usability Testing}} of a {{Web-Based}} and {{Therapist-Assisted Coping Skills Program}} for {{Managing Psychosocial Problems}} in {{Individuals With Hand}} and {{Upper Limb Injuries}}},
  author = {Babatunde, Folarin Omoniyi and MacDermid, Joy and Grewal, Ruby and Macedo, Luciana and Szekeres, Mike},
  year = {2020},
  month = may,
  journal = {JMIR Human Factors},
  volume = {7},
  number = {2},
  pages = {e17088},
  publisher = {{JMIR Publications Inc., Toronto, Canada}},
  doi = {10.2196/17088},
  urldate = {2021-04-20},
  abstract = {Background: Ineffective coping has been linked to prolonged pain, distress, anxiety, and depression after a hand and upper limb injury. Evidence shows that interventions based on cognitive behavioral therapy (CBT) may be effective in improving treatment outcomes, but traditional psychological interventions are resource intensive and unrealistic in busy hand therapy practices. Developing web-based, evidence-based psychological interventions specifically for hand therapy may be feasible in clinical practice and at home with reduced training and travel costs. Hand Therapy Online Coping Skills (HOCOS) is a program developed to supplement traditional hand therapy with therapist-assisted coping skills training based on principles from CBT and the Technology Acceptance Model. Objective: This study aimed to describe the development and assess the usability of HOCOS to support hand therapists in the management of psychosocial problems. Methods: The ADDIE model (Analysis, Design, Development, Implementation, and Evaluation) of system design was applied to create HOCOS. The usability testing of HOCOS involved a 2-stage process. In the first step, heuristic testing with information and communications technology (ICT) experts was completed using two sets of heuristics: Monkman heuristics and the Health Literacy Online (HLO) checklist. The second step involved user testing with hand therapists performing a series of online and face-to-face activities, completing 12 tasks on the website using the think-aloud protocol, completing the system usability scale (SUS) questionnaire, and a semistructured feedback interview in 2 iterative cycles. Descriptive statistics and content analyses were used to organize the data. Results: In total, 4 ICT experts and 12 therapists completed usability testing. The heuristic evaluation revealed 15 of 35 violations on the HLO checklist and 5 of 11 violations on the Monkman heuristics. Initially, hand therapists found 5 tasks to be difficult but were able to complete all 12 tasks after the second cycle of testing. The cognitive interview findings were organized into 6 themes: task performance, navigation, design esthetics, content, functionality and features, and desire for future use. Usability issues identified were addressed in two iterative cycles. There was good agreement on all items of the SUS. Overall, therapists found that HOCOS was a detailed and helpful learning resource for therapists and patients. Conclusions: We describe the development and usability testing of HOCOS; a new web-based psychosocial intervention for individuals with a hand and upper limb injuries. HOCOS targets psychosocial problems linked to prolonged pain and disability by increasing access to therapist-guided coping skills training. We actively involved target users in the development and usability evaluation of the website. The final website was modified to meet the needs and preferences of the participants.},
  copyright = {Unless stated otherwise, all articles are open-access distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/2.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work ("first published in the Journal of Medical Internet Research...") is properly cited with original URL and bibliographic citation information. The complete bibliographic information, a link to the original publication on http://www.jmir.org/, as well as this copyright and license information must be included.},
  langid = {english},
  keywords = {\_tablet},
  file = {/Users/james/Zotero/storage/K9HP88AE/Babatunde et al_2020_Development and Usability Testing of a Web-Based and Therapist-Assisted Coping.pdf;/Users/james/Zotero/storage/ZMKQDHK6/Babatunde et al_2020_Development and Usability Testing of a Web-Based and Therapist-Assisted Coping.pdf;/Users/james/Zotero/storage/J6NNWBRK/e17088.html}
}

@article{bakerTwoYearsLater2014,
  title = {Two {{Years Later}}: {{Journals Are Not Yet Enforcing}} the {{ARRIVE Guidelines}} on {{Reporting Standards}} for {{Pre-Clinical Animal Studies}}},
  shorttitle = {Two {{Years Later}}},
  author = {Baker, David and Lidster, Katie and Sottomayor, Ana and Amor, Sandra},
  year = {2014},
  month = jan,
  journal = {PLOS Biology},
  volume = {12},
  number = {1},
  pages = {e1001756},
  publisher = {{Public Library of Science}},
  issn = {1545-7885},
  doi = {10.1371/journal.pbio.1001756},
  urldate = {2023-10-11},
  abstract = {A study by David Baker and colleagues reveals poor quality of reporting in pre-clinical animal research and a failure of journals to implement the ARRIVE guidelines.},
  langid = {english},
  keywords = {Animal models,Animal models of disease,Animal studies,Experimental design,Medical journals,Research reporting guidelines,Scientific publishing,Statistical data},
  file = {/Users/james/Library/Mobile Documents/iCloud~QReader~MarginStudy/Documents/DPhil/Baker et al_2014_Two Years Later.pdf}
}

@article{bandInterventionPlanningDigital2017a,
  title = {Intervention Planning for a Digital Intervention for Self-Management of Hypertension: A Theory-, Evidence- and Person-Based Approach},
  shorttitle = {Intervention Planning for a Digital Intervention for Self-Management of Hypertension},
  author = {Band, Rebecca and Bradbury, Katherine and Morton, Katherine and May, Carl and Michie, Susan and Mair, Frances S. and Murray, Elizabeth and McManus, Richard J. and Little, Paul and Yardley, Lucy},
  year = {2017},
  month = feb,
  journal = {Implementation Science},
  volume = {12},
  number = {1},
  pages = {25},
  issn = {1748-5908},
  doi = {10.1186/s13012-017-0553-4},
  urldate = {2023-04-25},
  abstract = {This paper describes the intervention planning process for the Home and Online Management and Evaluation of Blood Pressure (HOME BP), a digital intervention to promote hypertension self-management. It illustrates how a Person-Based Approach can be integrated with theory- and evidence-based approaches. The Person-Based Approach to intervention development emphasises the use of qualitative research to ensure that the intervention is acceptable, persuasive, engaging and easy to implement.},
  keywords = {Blood pressure,Hypertension,Intervention planning,Methodological study,Self-management,Self-monitoring,Theoretical modelling},
  file = {/Users/james/Library/Mobile Documents/iCloud~QReader~MarginStudy/Documents/DPhil/Band et al_2017_Intervention planning for a digital intervention for self-management of2.pdf}
}

@article{barnesImpactOnlineWriting2015,
  title = {Impact of an Online Writing Aid Tool for Writing a Randomized Trial Report: The {{COBWEB}} ({{Consort-based WEB}} Tool) Randomized Controlled Trial},
  shorttitle = {Impact of an Online Writing Aid Tool for Writing a Randomized Trial Report},
  author = {Barnes, Caroline and Boutron, Isabelle and Giraudeau, Bruno and Porcher, Raphael and Altman, Douglas G. and Ravaud, Philippe},
  year = {2015},
  month = sep,
  journal = {BMC Medicine},
  volume = {13},
  number = {1},
  pages = {221},
  issn = {1741-7015},
  doi = {10.1186/s12916-015-0460-y},
  urldate = {2020-10-21},
  abstract = {Incomplete reporting is a frequent waste in research. Our aim was to evaluate the impact of a writing aid tool (WAT) based on the CONSORT statement and its extension for non-pharmacologic treatments on the completeness of reporting of randomized controlled trials (RCTs).},
  keywords = {Clinical epidemiology,CONSORT statement,Randomized controlled trial,Reporting guidelines,Transparency},
  file = {/Users/james/Library/Mobile Documents/iCloud~QReader~MarginStudy/Documents/DPhil/Barnes et al_2015_Impact of an online writing aid tool for writing a randomized trial report.pdf;/Users/james/Zotero/storage/85AY3LXG/Barnes et al_2015_Impact of an online writing aid tool for writing a randomized trial report.pdf;/Users/james/Zotero/storage/Q9AMQS2S/s12916-015-0460-y.html}
}

@article{bastuji-garinImpactSTROBEStatement2013,
  title = {Impact of {{STROBE}} Statement Publication on Quality of Observational Study Reporting: Interrupted Time Series versus before-after Analysis},
  shorttitle = {Impact of {{STROBE}} Statement Publication on Quality of Observational Study Reporting},
  author = {{Bastuji-Garin}, Sylvie and Sbidian, Emilie and {Gaudy-Marqueste}, Caroline and Ferrat, Emilie and Roujeau, Jean-Claude and Richard, Marie-Aleth and {Canoui-Poitrine}, Florence and {European Dermatology Network (EDEN)}},
  year = {2013},
  journal = {PloS One},
  volume = {8},
  number = {8},
  pages = {e64733},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0064733},
  abstract = {BACKGROUND: In uncontrolled before-after studies, CONSORT was shown to improve the reporting of randomised trials. Before-after studies ignore underlying secular trends and may overestimate the impact of interventions. Our aim was to assess the impact of the 2007 STROBE statement publication on the quality of observational study reporting, using both uncontrolled before-after analyses and interrupted time series. METHODS: For this quasi-experimental study, original articles reporting cohort, case-control, and cross-sectional studies published between 2004 and 2010 in the four dermatological journals having the highest 5-year impact factors ({$\geq$} 4) were selected. We compared the proportions of STROBE items (STROBE score) adequately reported in each article during three periods, two pre STROBE period (2004-2005 and 2006-2007) and one post STROBE period (2008-2010). Segmented regression analysis of interrupted time series was also performed. RESULTS: Of the 456 included articles, 187 (41\%) reported cohort studies, 166 (36.4\%) cross-sectional studies, and 103 (22.6\%) case-control studies. The median STROBE score was 57\% (range, 18\%-98\%). Before-after analysis evidenced significant STROBE score increases between the two pre-STROBE periods and between the earliest pre-STROBE period and the post-STROBE period (median score2004-05 48\% versus median score2008-10 58\%, p{$<$}0.001) but not between the immediate pre-STROBE period and the post-STROBE period (median score2006-07 58\% versus median score2008-10 58\%, p{$\mkern1mu$}={$\mkern1mu$}0.42). In the pre STROBE period, the six-monthly mean STROBE score increased significantly, by 1.19\% per six-month period (absolute increase 95\%CI, 0.26\% to 2.11\%, p{$\mkern1mu$}={$\mkern1mu$}0.016). By segmented analysis, no significant changes in STROBE score trends occurred (-0.40\%; 95\%CI, -2.20 to 1.41; p{$\mkern1mu$}={$\mkern1mu$}0.64) in the post STROBE statement publication. INTERPRETATION: The quality of reports increased over time but was not affected by STROBE. Our findings raise concerns about the relevance of uncontrolled before-after analysis for estimating the impact of guidelines.},
  langid = {english},
  pmcid = {PMC3753332},
  pmid = {23990867},
  keywords = {Abstracting and Indexing,Bibliometrics,Case-Control Studies,Cohort Studies,Cross-Sectional Studies,Dermatology,Observational Studies as Topic,Publishing,Regression Analysis,Reproducibility of Results,Research Design,Time Factors},
  file = {/Users/james/Library/Mobile Documents/iCloud~QReader~MarginStudy/Documents/DPhil/Bastuji-Garin et al_2013_Impact of STROBE statement publication on quality of observational study.pdf}
}

@article{beggImprovingQualityReporting1996,
  title = {Improving the {{Quality}} of {{Reporting}} of {{Randomized Controlled Trials}}: {{The CONSORT Statement}}},
  shorttitle = {Improving the {{Quality}} of {{Reporting}} of {{Randomized Controlled Trials}}},
  author = {Begg, Colin and Cho, Mildred and Eastwood, Susan and Horton, Richard and Moher, David and Olkin, Ingram and Pitkin, Roy and Rennie, Drummond and Schulz, Kenneth F. and Simel, David and Stroup, Donna F.},
  year = {1996},
  month = aug,
  journal = {JAMA},
  volume = {276},
  number = {8},
  pages = {637--639},
  issn = {0098-7484},
  doi = {10.1001/jama.1996.03540080059030},
  urldate = {2021-02-08},
  abstract = {THE RANDOMIZED controlled trial (RCT), more than any other methodology, can have a powerful and immediate impact on patient care. Ideally, the report of such an evaluation needs to convey to the reader relevant information concerning the design, conduct, analysis, and generalizability of the trial. This information should provide the reader with the ability to make informed judgments regarding the internal and external validity of the trial. Accurate and complete reporting also benefits editors and reviewers in their deliberations regarding submitted manuscripts. For RCTs to ultimately benefit patients, the published report should be of the highest possible standard.For editorial comment see p 649.Evidence produced repeatedly over the last 30 years indicates a wide chasm between what a trial should report and what is actually published in the literature. In a review of 71 RCTs with negative results published between 1960 and 1975, the authors reported that the vast},
  file = {/Users/james/Zotero/storage/DUMK8RWZ/407167.html}
}

@misc{biernerMarkdownPreviewMermaid2022,
  title = {Markdown {{Preview Mermaid Support}}},
  author = {Bierner, Matt},
  year = {2022},
  month = apr,
  urldate = {2022-04-13},
  abstract = {Adds Mermaid diagram and flowchart support to VS Code's builtin markdown preview},
  copyright = {MIT}
}

@article{borenThinkingAloudReconciling2000,
  title = {Thinking Aloud: Reconciling Theory and Practice},
  shorttitle = {Thinking Aloud},
  author = {Boren, T. and Ramey, J.},
  year = {2000},
  month = sep,
  journal = {IEEE Transactions on Professional Communication},
  volume = {43},
  number = {3},
  pages = {261--278},
  issn = {1558-1500},
  doi = {10.1109/47.867942},
  urldate = {2023-11-15},
  abstract = {Thinking-aloud protocols may be the most widely used method in usability testing, but the descriptions of this practice in the usability literature and the work habits of practitioners do not conform to the theoretical basis most often cited for it: K.A. Ericsson and H.A. Simon's (1984) seminal work. After reviewing Ericsson and Simon's theoretical basis for thinking aloud, we review the ways in which actual usability practice diverges from this model. We then explore the concept of speech genre as an alternative theoretical framework. We first consider uses of this new framework that are consistent with Ericsson and Simon's goal of eliciting a verbal report that is as undirected, undisturbed and constant as possible. We then go on to consider how the proposed new approach might handle problems that arise in usability testing that appear to require interventions not supported in the older model.},
  file = {/Users/james/Library/Mobile Documents/iCloud~QReader~MarginStudy/Documents/DPhil/Boren_Ramey_2000_Thinking aloud.pdf}
}

@article{bossuytSTARDStatementReporting2003,
  title = {The {{STARD}} Statement for Reporting Studies of Diagnostic Accuracy: Explanation and Elaboration},
  shorttitle = {The {{STARD}} Statement for Reporting Studies of Diagnostic Accuracy},
  author = {Bossuyt, Patrick M. and Reitsma, Johannes B. and Bruns, David E. and Gatsonis, Constantine A. and Glasziou, Paul P. and Irwig, Les M. and Moher, David and Rennie, Drummond and {de Vet}, Henrica C. W. and Lijmer, Jeroen G. and {Standards for Reporting of Diagnostic Accuracy}},
  year = {2003},
  month = jan,
  journal = {Annals of Internal Medicine},
  volume = {138},
  number = {1},
  pages = {W1-12},
  issn = {1539-3704},
  doi = {10.7326/0003-4819-138-1-200301070-00012-w1},
  abstract = {The quality of reporting of studies of diagnostic accuracy is less than optimal. Complete and accurate reporting is necessary to enable readers to assess the potential for bias in the study and to evaluate the generalizability of the results. A group of scientists and editors has developed the STARD (Standards for Reporting of Diagnostic Accuracy) statement to improve the reporting the quality of reporting of studies of diagnostic accuracy. The statement consists of a checklist of 25 items and flow diagram that authors can use to ensure that all relevant information is present. This explanatory document aims to facilitate the use, understanding, and dissemination of the checklist. The document contains a clarification of the meaning, rationale, and optimal use of each item on the checklist, as well as a short summary of the available evidence on bias and applicability. The STARD statement, checklist, flowchart, and this explanation and elaboration document should be useful resources to improve reporting of diagnostic accuracy studies. Complete and informative reporting can only lead to better decisions in health care.},
  langid = {english},
  pmid = {12513067},
  keywords = {Algorithms,Bias,Clinical Trials as Topic,Diagnostic Techniques and Procedures,Publishing,Reference Standards,Reproducibility of Results,Research Design,Sensitivity and Specificity,Statistics as Topic}
}

@article{botosReportedUseReporting2018a,
  title = {Reported Use of Reporting Guidelines among {{JNCI}}: {{Journal}} of the {{National Cancer Institute}} Authors, Editorial Outcomes, and Reviewer Ratings Related to Adherence to Guidelines and Clarity of Presentation},
  shorttitle = {Reported Use of Reporting Guidelines among {{JNCI}}},
  author = {Botos, Jeannine},
  year = {2018},
  month = sep,
  journal = {Research Integrity and Peer Review},
  volume = {3},
  number = {1},
  pages = {7},
  issn = {2058-8615},
  doi = {10.1186/s41073-018-0052-4},
  urldate = {2023-10-11},
  abstract = {Associations were examined between author-reported uses of reporting guidelines to prepare JNCI: Journal of the National Cancer Institute (JNCI) submissions, editorial decisions, and reviewer ratings for adherence to reporting guidelines and clarity of presentation.},
  keywords = {Adherence,Clarity,Editorial decisions,Peer review,Presentation,Reporting guidelines,Submissions},
  file = {/Users/james/Library/Mobile Documents/iCloud~QReader~MarginStudy/Documents/DPhil/Botos_2018_Reported use of reporting guidelines among JNCI.pdf}
}

@article{bradshawEmployingQualitativeDescription2017,
  title = {Employing a {{Qualitative Description Approach}} in {{Health Care Research}}},
  author = {Bradshaw, Carmel and Atkinson, Sandra and Doody, Owen},
  year = {2017},
  month = jan,
  journal = {Global Qualitative Nursing Research},
  volume = {4},
  pages = {2333393617742282},
  publisher = {{SAGE Publications Inc}},
  issn = {2333-3936},
  doi = {10.1177/2333393617742282},
  urldate = {2022-12-27},
  abstract = {A qualitative description design is particularly relevant where information is required directly from those experiencing the phenomenon under investigation and where time and resources are limited. Nurses and midwives often have clinical questions suitable to a qualitative approach but little time to develop an exhaustive comprehension of qualitative methodological approaches. Qualitative description research is sometimes considered a less sophisticated approach for epistemological reasons. Another challenge when considering qualitative description design is differentiating qualitative description from other qualitative approaches. This article provides a systematic and robust journey through the philosophical, ontological, and epistemological perspectives, which evidences the purpose of qualitative description research. Methods and rigor issues underpinning qualitative description research are also appraised to provide the researcher with a systematic approach to conduct research utilizing this approach. The key attributes and value of qualitative description research in the health care professions will be highlighted with the aim of extending its usage.},
  langid = {english},
  keywords = {\_tablet},
  file = {/Users/james/Library/Mobile Documents/iCloud~QReader~MarginStudy/Documents/DPhil/Bradshaw et al_2017_Employing a Qualitative Description Approach in Health Care Research.pdf}
}

@article{brouwersAGREEReportingChecklist2016,
  title = {The {{AGREE Reporting Checklist}}: A Tool to Improve Reporting of Clinical Practice Guidelines},
  shorttitle = {The {{AGREE Reporting Checklist}}},
  author = {Brouwers, Melissa C. and Kerkvliet, Kate and Spithoff, Karen and Consortium, AGREE Next Steps},
  year = {2016},
  month = mar,
  journal = {BMJ},
  volume = {352},
  pages = {i1152},
  publisher = {{British Medical Journal Publishing Group}},
  issn = {1756-1833},
  doi = {10.1136/bmj.i1152},
  urldate = {2021-10-03},
  abstract = {{$<$}p{$>$}AGREE II is a widely used standard for assessing the methodological quality of practice guidelines. This article describes the development of the AGREE Reporting Checklist, which was designed to improve the quality of practice guideline reporting and aligns with AGREE II in its structure and content.{$<$}/p{$>$}},
  chapter = {Research Methods \&amp; Reporting},
  copyright = {Published by the BMJ Publishing Group Limited. For permission to use (where not already granted under a licence) please go to http://group.bmj.com/group/rights-licensing/permissions .  This is an Open Access article distributed in accordance with the Creative Commons Attribution Non Commercial (CC BY-NC 3.0) license, which permits others to distribute, remix, adapt, build upon this work non-commercially, and license their derivative works on different terms, provided the original work is properly cited and the use is noncommercial. See: http://creativecommons.org/licenses/by-nc/3.0/ .},
  langid = {english},
  pmid = {26957104},
  keywords = {\_tablet,QES-exclude},
  file = {/Users/james/Zotero/storage/LIUH5T8U/Brouwers et al_2016_The AGREE Reporting Checklist.pdf;/Users/james/Zotero/storage/7YSTJWDQ/bmj.html}
}

@article{burfordTestingPRISMAEquity20122013,
  title = {Testing the {{PRISMA-Equity}} 2012 Reporting Guideline: The Perspectives of Systematic Review Authors.},
  shorttitle = {Testing the {{PRISMA-Equity}} 2012 Reporting Guideline},
  author = {Burford, Belinda J. and Welch, Vivian and Waters, Elizabeth and Tugwell, Peter and Moher, David and O'Neill, Jennifer and Koehlmoos, Tracey and Petticrew, Mark},
  year = {2013},
  journal = {PloS one},
  volume = {8},
  number = {10},
  pages = {e75122},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  urldate = {2020-12-09},
  abstract = {Reporting guidelines can be used to encourage standardised and comprehensive reporting of health research. In light of the global commitment to health equity, we have previously developed and published a reporting guideline for equity-focused systematic reviews (PRISMA-E 2012). The objectives of this study were to explore the utility of the equity extension items included in PRISMA-E 2012 from a systematic review author perspective, including facilitators and barriers to its use. This will assist in designing dissemination and knowledge translation strategies. We conducted a survey of systematic review authors to expose them to the new items in PRISMA-E 2012, establish the extent to which they had historically addressed those items in their own reviews, and gather feedback on the usefulness of the new items. Data were analysed using Microsoft Excel 2008 and Stata (version 11.2 for Mac). Of 151 respondents completing the survey, 18.5\% (95\% CI: 12.7\% to 25.7\%) had not heard of the PRISMA statement before, although 83.4\% (95\% CI: 77.5\% to 89.3\%) indicated that they plan to use PRISMA-E 2012 in the future, depending on the focus of their review. Most (68.9\%; 95\% CI: 60.8\% to 76.2\%) thought that using PRISMA-E 2012 would lead them to conduct their reviews differently. Important facilitators to using PRISMA-E 2012 identified by respondents were journal endorsement and incorporation of the elements of the guideline into systematic review software. Barriers identified were lack of time, word limits and the availability of equity data in primary research. This study has been the first to 'road-test' the new PRISMA-E 2012 reporting guideline and the findings are encouraging. They confirm the acceptability and potential utility of the guideline to assist review authors in reporting on equity in their reviews. The uptake and impact of PRISMA-E 2012 over time on design, conduct and reporting of primary research and systematic reviews should continue to be examined.},
  copyright = {cc\_by},
  langid = {english},
  keywords = {\_tablet,*medical research,*practice guideline,*Review Literature as Topic,*systematic review (topic),article,Behavioral and social aspects of health,Computer software,Global health,Guidelines as Topic,human,medical literature,Metaanalysis,publication,QES-include,quality control,Research design,Research reporting guidelines,standardization,study design,Surveys,Systematic reviews},
  file = {/Users/james/Zotero/storage/HDM9SWTR/Burford et al. - 2013 - Testing the PRISMA-Equity 2012 Reporting Guideline.pdf;/Users/james/Zotero/storage/LG4FPHH5/Burford et al_2013_Testing the PRISMA-Equity 2012 reporting guideline.pdf;/Users/james/Zotero/storage/FUH8VRUS/1380016.html;/Users/james/Zotero/storage/VGAFSVAI/1380016.html}
}

@article{CallCommentsProposal1994,
  title = {Call for Comments on a Proposal to Improve Reporting of Clinical Trials in the Biomedical Literature. {{Working Group}} on {{Recommendations}} for {{Reporting}} of {{Clinical Trials}} in the {{Biomedical Literature}}},
  year = {1994},
  month = dec,
  journal = {Annals of Internal Medicine},
  volume = {121},
  number = {11},
  pages = {894--895},
  issn = {0003-4819},
  doi = {10.7326/0003-4819-121-11-199412010-00015},
  langid = {english},
  pmid = {7978706},
  keywords = {Clinical Trials as Topic,Humans,Publishing}
}

@article{caneValidationTheoreticalDomains2012,
  title = {Validation of the Theoretical Domains Framework for Use in Behaviour Change and Implementation Research},
  author = {Cane, James and O'Connor, Denise and Michie, Susan},
  year = {2012},
  month = apr,
  journal = {Implementation Science},
  volume = {7},
  number = {1},
  pages = {37},
  issn = {1748-5908},
  doi = {10.1186/1748-5908-7-37},
  urldate = {2023-01-09},
  abstract = {An integrative theoretical framework, developed for cross-disciplinary implementation and other behaviour change research, has been applied across a wide range of clinical situations. This study tests the validity of this framework.},
  keywords = {Behaviour,Change,Implementation,Theoretical domains framework,Theory,Validation},
  file = {/Users/james/Library/Mobile Documents/iCloud~QReader~MarginStudy/Documents/DPhil/Cane et al_2012_Validation of the theoretical domains framework for use in behaviour change and.pdf}
}

@article{carpSecretLivesExperiments2012,
  title = {The Secret Lives of Experiments: Methods Reporting in the {{fMRI}} Literature},
  shorttitle = {The Secret Lives of Experiments},
  author = {Carp, Joshua},
  year = {2012},
  month = oct,
  journal = {NeuroImage},
  volume = {63},
  number = {1},
  pages = {289--300},
  issn = {1095-9572},
  doi = {10.1016/j.neuroimage.2012.07.004},
  abstract = {Replication of research findings is critical to the progress of scientific understanding. Accordingly, most scientific journals require authors to report experimental procedures in sufficient detail for independent researchers to replicate their work. To what extent do research reports in the functional neuroimaging literature live up to this standard? The present study evaluated methods reporting and methodological choices across 241 recent fMRI articles. Many studies did not report critical methodological details with regard to experimental design, data acquisition, and analysis. Further, many studies were underpowered to detect any but the largest statistical effects. Finally, data collection and analysis methods were highly flexible across studies, with nearly as many unique analysis pipelines as there were studies in the sample. Because the rate of false positive results is thought to increase with the flexibility of experimental designs, the field of functional neuroimaging may be particularly vulnerable to false positives. In sum, the present study documented significant gaps in methods reporting among fMRI studies. Improved methodological descriptions in research reports would yield significant benefits for the field.},
  langid = {english},
  pmid = {22796459},
  keywords = {Biomedical Research,Brain Mapping,Humans,Knowledge Discovery,Magnetic Resonance Imaging,Periodicals as Topic,Reproducibility of Results,Sensitivity and Specificity}
}

@phdthesis{carvalhoParticipatoryDesignBehaviour2020,
  title = {Participatory {{Design}} for {{Behaviour Change}}: {{An Integrative Approach}} to {{Improving Healthcare Practice Focused}} on {{Staff Participation}}},
  author = {Carvalho, Fernando},
  year = {2020}
}

@article{caulleyCitationImpactWas2020,
  title = {Citation Impact Was Highly Variable for Reporting Guidelines of Health Research: A Citation Analysis},
  shorttitle = {Citation Impact Was Highly Variable for Reporting Guidelines of Health Research},
  author = {Caulley, Lisa and Cheng, Wei and {Catal{\'a}-L{\'o}pez}, Ferr{\'a}n and Whelan, Jonathan and Khoury, Michel and Ferraro, Jennifer and Husereau, Don and Altman, Douglas G. and Moher, David},
  year = {2020},
  month = nov,
  journal = {Journal of Clinical Epidemiology},
  volume = {127},
  pages = {96--104},
  issn = {0895-4356},
  doi = {10.1016/j.jclinepi.2020.07.013},
  urldate = {2023-09-19},
  abstract = {Objectives Over 400 reporting guidelines are currently published, but the frequency of their use by authors to accurately and transparently report research remains unclear. This study examined citation counts of reporting guidelines and characteristics contributing to their citation impact. Study Design and Setting Web of Science database was searched for citation counts of all reporting guidelines with a minimum citation age of 5~years. The total citation impact, mean citation impact and the factors contributing to 2- and 5-year citation rate were established. Results The search identified 296 articles of reporting guidelines from 1995 to 2013. The mean citations per year was 32.4 (95\% confidence interval, 22.3\textendash 42.4 citations). The factors associated with 2- and 5-year citation performance of reporting guidelines included the following: open access to the reporting guideline, field of the publishing journal (general vs. specialized medical journal), impact factor of the publishing journal, simultaneous publication in multiple journals, and a male first author. Conclusion The citation rate across reporting guidelines varied with journal impact factor, open access publication, field of the publishing journal, simultaneous publications, and a male first author. Gaps in citations highlight opportunities to increase visibility and encourage author use of reporting guidelines.},
  keywords = {Citation analysis,Citation impact,Clinical trials,Quality of reporting,Reporting guidelines,Standardized reporting},
  file = {/Users/james/Library/Mobile Documents/iCloud~QReader~MarginStudy/Documents/DPhil/Caulley et al_2020_Citation impact was highly variable for reporting guidelines of health research.pdf}
}

@misc{ChinaNationalKnowledge,
  title = {China {{National Knowledge Infrastructure}}},
  urldate = {2021-03-01},
  howpublished = {https://www.cnki.net/},
  file = {/Users/james/Zotero/storage/Z43P7747/www.cnki.net.html}
}

@misc{ChineseBiomedicalLiterature,
  title = {Chinese {{Biomedical Literature Database}}},
  urldate = {2021-03-01},
  howpublished = {https://www.imicams.ac.cn/},
  file = {/Users/james/Zotero/storage/Y5XNE87B/www.imicams.ac.cn.html}
}

@book{cloughNarrativesFictionsEducational2002,
  title = {Narratives and {{Fictions}} in {{Educational Research}}},
  author = {Clough, Peter},
  year = {2002},
  publisher = {{Open University Press}},
  abstract = {"In this bold and very important work, Peter Clough shows how the truths about educational issues can be told using fictional devices. This work legitimates the narrative turn in the human disciplines. He shows educational researchers how narrative inquiry can be used for progressive moral and political purposes". - Norman K. Denzin, University of Illinois at Urbana-Champaign  This compelling book takes a fresh approach to educational research, considering the role and use of literary and ethnographic approaches. There is growing interest in the use of narrative and fictional methods and this book sets out to:  * locate narrative and fictional methods within the traditions of education research;  * exemplify the use of narrative in studies of educational and social settings;  * explain the processes of composing narrative and fictional research  A distinctive feature of the book is the inclusion of five 'fictional' stories which demonstrate the use of narrative in reporting research. Detailed discussion of these five stories shows how they were created from actual events and the varied role of the author in their creation. The methodological implications of such an approach are considered along with its potential merits and difficulties and its possible uses.},
  googlebooks = {eBMiAQAAIAAJ},
  isbn = {978-0-335-20792-3},
  langid = {english}
}

@article{coboEffectUsingReporting2011,
  title = {Effect of Using Reporting Guidelines during Peer Review on Quality of Final Manuscripts Submitted to a Biomedical Journal: Masked Randomised Trial},
  shorttitle = {Effect of Using Reporting Guidelines during Peer Review on Quality of Final Manuscripts Submitted to a Biomedical Journal},
  author = {Cobo, E. and Cort{\'e}s, J. and Ribera, J. M. and Cardellach, F. and {Selva-O'Callaghan}, A. and Kostov, B. and Garc{\'i}a, L. and Cirugeda, L. and Altman, D. G. and Gonz{\'a}lez, J. A. and S{\`a}nchez, J. A. and Miras, F. and Urrutia, A. and Fonollosa, V. and {Rey-Joly}, C. and Vilardell, M.},
  year = {2011},
  month = nov,
  journal = {BMJ},
  volume = {343},
  pages = {d6783},
  publisher = {{British Medical Journal Publishing Group}},
  issn = {0959-8138, 1468-5833},
  doi = {10.1136/bmj.d6783},
  urldate = {2023-09-22},
  abstract = {Objective To investigate the effect of an additional review based on reporting guidelines such as STROBE and CONSORT on quality of manuscripts. Design Masked randomised trial. Population Original research manuscripts submitted to the Medicina Cl\'inica journal from May 2008 to April 2009 and considered suitable for publication. Intervention Control group: conventional peer reviews alone. Intervention group: conventional review plus an additional review looking for missing items from reporting guidelines. Outcomes Manuscript quality, assessed with a 5 point Likert scale (primary: overall quality; secondary: average quality of specific items in paper). Main analysis compared groups as allocated, after adjustment for baseline factors (analysis of covariance); sensitivity analysis compared groups as reviewed. Adherence to reviewer suggestions assessed with Likert scale. Results Of 126 consecutive papers receiving conventional review, 34 were not suitable for publication. The remaining 92 papers were allocated to receive conventional reviews alone (n=41) or additional reviews (n=51). Four papers assigned to the conventional review group deviated from protocol; they received an additional review based on reporting guidelines. We saw an improvement in manuscript quality in favour of the additional review group (comparison as allocated, 0.25, 95\% confidence interval \textendash 0.05 to 0.54; as reviewed, 0.33, 0.03 to 0.63). More papers with additional reviews than with conventional reviews alone improved from baseline (22 (43\%) v eight (20\%), difference 23.6\% (3.2\% to 44.0\%), number needed to treat 4.2 (from 2.3 to 31.2), relative risk 2.21 (1.10 to 4.44)). Authors in the additional review group adhered more to suggestions from conventional reviews than to those from additional reviews (average increase 0.43 Likert points (0.19 to 0.67)). Conclusions Additional reviews based on reporting guidelines improve manuscript quality, although the observed effect was smaller than hypothesised and not definitively demonstrated. Authors adhere more to suggestions from conventional reviews than to those from additional reviews, showing difficulties in adhering to high methodological standards at the latest research phases. To boost paper quality and impact, authors should be aware of future requirements of reporting guidelines at the very beginning of their study. Trial registration and protocol Although registries do not include trials of peer review, the protocol design was submitted to sponsored research projects (Instituto de Salud Carlos III, PI081903).},
  chapter = {Research},
  copyright = {\textcopyright{} Cobo et al 2011. This is an open-access article distributed under the terms of the Creative Commons Attribution Non-commercial License, which permits use, distribution, and reproduction in any medium, provided the original work is properly cited, the use is non commercial and is otherwise in compliance with the license. See: http://creativecommons.org/licenses/by-nc/2.0/  and  http://creativecommons.org/licenses/by-nc/2.0/legalcode.},
  langid = {english},
  pmid = {22108262},
  file = {/Users/james/Library/Mobile Documents/iCloud~QReader~MarginStudy/Documents/DPhil/Cobo et al_2011_Effect of using reporting guidelines during peer review on quality of final.pdf}
}

@article{coboStatisticalReviewersImprove2007,
  title = {Statistical {{Reviewers Improve Reporting}} in {{Biomedical Articles}}: {{A Randomized Trial}}},
  shorttitle = {Statistical {{Reviewers Improve Reporting}} in {{Biomedical Articles}}},
  author = {Cobo, Erik and {Selva-O'Callagham}, Albert and Ribera, Josep-Maria and Cardellach, Francesc and Dominguez, Ruth and Vilardell, Miquel},
  year = {2007},
  month = mar,
  journal = {PLoS ONE},
  volume = {2},
  number = {3},
  pages = {e332},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0000332},
  urldate = {2023-09-22},
  abstract = {Background Although peer review is widely considered to be the most credible way of selecting manuscripts and improving the quality of accepted papers in scientific journals, there is little evidence to support its use. Our aim was to estimate the effects on manuscript quality of either adding a statistical peer reviewer or suggesting the use of checklists such as CONSORT or STARD to clinical reviewers or both. Methodology and Principal Findings Interventions were defined as 1) the addition of a statistical reviewer to the clinical peer review process, and 2) suggesting reporting guidelines to reviewers; with ``no statistical expert'' and ``no checklist'' as controls. The two interventions were crossed in a 2\texttimes 2 balanced factorial design including original research articles consecutively selected, between May 2004 and March 2005, by the Medicina Clinica (Barc) editorial committee. We randomized manuscripts to minimize differences in terms of baseline quality and type of study (intervention, longitudinal, cross-sectional, others). Sample-size calculations indicated that 100 papers provide an 80\% power to test a 55\% standardized difference. We specified the main outcome as the increment in quality of papers as measured on the Goodman Scale. Two blinded evaluators rated the quality of manuscripts at initial submission and final post peer review version. Of the 327 manuscripts submitted to the journal, 131 were accepted for further review, and 129 were randomized. Of those, 14 that were lost to follow-up showed no differences in initial quality to the followed-up papers. Hence, 115 were included in the main analysis, with 16 rejected for publication after peer review. 21 (18.3\%) of the 115 included papers were interventions, 46 (40.0\%) were longitudinal designs, 28 (24.3\%) cross-sectional and 20 (17.4\%) others. The 16 (13.9\%) rejected papers had a significantly lower initial score on the overall Goodman scale than accepted papers (difference 15.0, 95\% CI: 4.6\textendash 24.4). The effect of suggesting a guideline to the reviewers had no effect on change in overall quality as measured by the Goodman scale (0.9, 95\% CI: -0.3\textendash +2.1). The estimated effect of adding a statistical reviewer was 5.5 (95\% CI: 4.3\textendash 6.7), showing a significant improvement in quality. Conclusions and Significance This prospective randomized study shows the positive effect of adding a statistical reviewer to the field-expert peers in improving manuscript quality. We did not find a statistically significant positive effect by suggesting reviewers use reporting guidelines.},
  pmcid = {PMC1824709},
  pmid = {17389922},
  file = {/Users/james/Library/Mobile Documents/iCloud~QReader~MarginStudy/Documents/DPhil/Cobo et al_2007_Statistical Reviewers Improve Reporting in Biomedical Articles.pdf}
}

@misc{ComplianceQuestionnaireARRIVE,
  title = {Compliance {{Questionnaire}} | {{ARRIVE Guidelines}}},
  urldate = {2023-10-24},
  abstract = {Designed for use by journals assessing manuscripts submitted for publication, this questionnaire allows for streamlined evaluation of how well a manuscript complies with the ARRIVE Essential 10. , standard},
  howpublished = {https://arriveguidelines.org/resources/compliance-questionnaire},
  langid = {english},
  file = {/Users/james/Zotero/storage/DB3FY8RQ/ARRIVE Compliance Questionnaire.pdf}
}

@misc{craigDevelopingEvaluatingComplex2021,
  title = {Developing and Evaluating Complex Interventions},
  author = {Craig, Peter and Dieppe, Paul and Macintyre, Sally and Michie, Susan and Nazareth, Irwin and Petticrew, Mark},
  year = {2021},
  publisher = {{Medical Research Council}},
  urldate = {2021-12-10},
  keywords = {\_tablet},
  file = {/Users/james/Zotero/storage/C7P2835S/Craig et al_2021_Developing and evaluating complex interventions.pdf}
}

@misc{criticalappraisalskillsprogrammeCASPQualitativeChecklist2018,
  title = {{{CASP Qualitative Checklist}}},
  author = {Critical Appraisal Skills Programme},
  year = {2018},
  journal = {CASP - Critical Appraisal Skills Programme},
  urldate = {2022-05-05},
  abstract = {This set of eight critical appraisal tools are designed to be used when reading research. CASP has appraisal checklists designed for use with Systematic Reviews, Randomised Controlled Trials, Cohort Studies, Case Control Studies, Economic Evaluations, Diagnostic Studies, Qualitative studies and Clinical Prediction Rule. This work is licensed under a~Creative Commons Attribution-ShareAlike 4.0},
  howpublished = {https://casp-uk.net/casp-tools-checklists/},
  langid = {american},
  file = {/Users/james/Zotero/storage/9Q7R7KH4/CASP-Qualitative-Checklist-2018_fillable_form.pdf}
}

@article{davidsonExerciseInterventionsLow2021,
  title = {Exercise Interventions for Low Back Pain Are Poorly Reported: A Systematic Review},
  shorttitle = {Exercise Interventions for Low Back Pain Are Poorly Reported},
  author = {Davidson, Simon R. E. and Kamper, Steven J. and Haskins, Robin and Robson, Emma and Gleadhill, Connor and {da Silva}, Priscilla Viana and Williams, Amanda and Yu, Zhongming and Williams, Christopher M.},
  year = {2021},
  month = nov,
  journal = {Journal of Clinical Epidemiology},
  volume = {139},
  pages = {279--286},
  issn = {1878-5921},
  doi = {10.1016/j.jclinepi.2021.05.020},
  abstract = {OBJECTIVE: To assess the reporting quality of exercise interventions from clinical trials of low back pain (LBP). STUDY DESIGN AND SETTING: We conducted a systematic review to assess the reporting quality of randomised controlled trials (RCTs) that investigated the effectiveness of exercise interventions for patients with LBP. Five online databases and Clinical Trial Registries were searched (October 2018). We included RCTs that reported interventions for LBP, containing at least 50\% exercise. The Template for Intervention Description and Replication (TIDieR) and the Consensus on Exercise Reporting Template (CERT) reporting checklists were then used to assess quality of reporting. RESULTS: 582 trials were eligible for inclusion. Due to the large number of eligible studies, 100 studies were randomly selected for data extraction and coding with the TIDieR and CERT checklists. The random sample was representative of the 582 eligible trials. The overall completeness of reporting (median (IQR)) of TIDieR items was 59.2\% (45.5\%-72.7\%) and CERT was 33.3\% (22.2\%-52.6\%). CONCLUSIONS: We found poor overall reporting with both checklists, which has not improved over time or since the introduction of the checklists. More dedicated work is required to address poor reporting of exercise interventions in clinical trials.},
  langid = {english},
  pmid = {34091020},
  keywords = {Adult,Biomedical Research,CERT,Clinical Trials as Topic,Data Accuracy,Exercise,Exercise Therapy,Female,Guidelines,Humans,Low back pain,Low Back Pain,Male,Middle Aged,Reporting quality,Research Design,Research Report,TIDieR},
  file = {/Users/james/Library/Mobile Documents/iCloud~QReader~MarginStudy/Documents/DPhil/Davidson et al_2021_Exercise interventions for low back pain are poorly reported.pdf}
}

@article{daviesFindingsNovelApproach2016,
  title = {Findings from a Novel Approach to Publication Guideline Revision: User Road Testing of a Draft Version of {{SQUIRE}} 2.0},
  shorttitle = {Findings from a Novel Approach to Publication Guideline Revision},
  author = {Davies, Louise and Donnelly, Kyla Z. and Goodman, Daisy J. and Ogrinc, Greg},
  year = {2016},
  month = apr,
  journal = {BMJ quality \& safety},
  volume = {25},
  number = {4},
  pages = {265--272},
  issn = {2044-5423},
  doi = {10.1136/bmjqs-2015-004117},
  abstract = {BACKGROUND: The Standards for Quality Improvement Reporting Excellence (SQUIRE) Guideline was published in 2008 (SQUIRE 1.0) and was the first publication guideline specifically designed to advance the science of healthcare improvement. Advances in the discipline of improvement prompted us to revise it. We adopted a novel approach to the revision by asking end-users to 'road test' a draft version of SQUIRE 2.0. The aim was to determine whether they understood and implemented the guidelines as intended by the developers. METHODS: Forty-four participants were assigned a manuscript section (ie, introduction, methods, results, discussion) and asked to use the draft Guidelines to guide their writing process. They indicated the text that corresponded to each SQUIRE item used and submitted it along with a confidential survey. The survey examined usability of the Guidelines using Likert-scaled questions and participants' interpretation of key concepts in SQUIRE using open-ended questions. On the submitted text, we evaluated concordance between participants' item usage/interpretation and the developers' intended application. For the survey, the Likert-scaled responses were summarised using descriptive statistics and the open-ended questions were analysed by content analysis. RESULTS: Consistent with the SQUIRE Guidelines' recommendation that not every item be included, less than one-third (n=14) of participants applied every item in their section in full. Of the 85 instances when an item was partially used or was omitted, only 7 (8.2\%) of these instances were due to participants not understanding the item. Usage of Guideline items was highest for items most similar to standard scientific reporting (ie, 'Specific aim of the improvement' (introduction), 'Description of the improvement' (methods) and 'Implications for further studies' (discussion)) and lowest ({$<$}20\% of the time) for those unique to healthcare improvement (ie, 'Assessment methods for context factors that contributed to success or failure' and 'Costs and strategic trade-offs'). Items unique to healthcare improvement, specifically 'Evolution of the improvement', 'Context elements that influenced the improvement', 'The logic on which the improvement was based', 'Process and outcome measures', demonstrated poor concordance between participants' interpretation and developers' intended application. CONCLUSIONS: User testing of a draft version of SQUIRE 2.0 revealed which items have poor concordance between developer intent and author usage, which will inform final editing of the Guideline and development of supporting supplementary materials. It also identified the items that require special attention when teaching about scholarly writing in healthcare improvement.},
  langid = {english},
  pmcid = {PMC4819644},
  pmid = {26263916},
  keywords = {Adult,Female,Guidelines as Topic,Health policy,Health Services Research,Healthcare quality improvement,Humans,Male,Middle Aged,Publishing,Qualitative research,Quality improvement,Quality of Health Care,United States},
  file = {/Users/james/Zotero/storage/LH3TYFUQ/265.full.pdf}
}

@article{daviesSQUIREGuidelinesEvaluation2015,
  title = {The {{SQUIRE Guidelines}}: An Evaluation from the Field, 5\hspace{0.25em}Years Post Release},
  shorttitle = {The {{SQUIRE Guidelines}}},
  author = {Davies, Louise and Batalden, Paul and Davidoff, Frank and Stevens, David and Ogrinc, Greg},
  year = {2015},
  month = dec,
  journal = {BMJ quality \& safety},
  volume = {24},
  number = {12},
  pages = {769--775},
  issn = {2044-5423},
  doi = {10.1136/bmjqs-2015-004116},
  abstract = {BACKGROUND: The Standards for Quality Improvement Reporting Excellence (SQUIRE) Guidelines were published in 2008 to increase the completeness, precision and accuracy of published reports of systematic efforts to improve the quality, value and safety of healthcare. Since that time, the field has expanded. We asked people from the field to evaluate the Guidelines, a novel approach to a first step in revision. METHODS: Evaluative design using focus groups and semi-structured interviews with 29 end users and an advisory group of 18 thinkers in the field. Sampling of end users was purposive to achieve variation in work setting, geographic location, area of expertise, manuscript writing experience, healthcare improvement and research experience. RESULTS: Study participants reported that SQUIRE was useful in planning a healthcare improvement project, but not as helpful during writing because of redundancies, uncertainty about what was important to include and lack of clarity in items. The concept "planning the study of the intervention" (item 10) was hard for many participants to understand. Participants varied in their interpretation of the meaning of item 10b "the concept of the mechanism by which changes were expected to occur". Participants disagreed about whether iterations of an intervention should be reported. Level of experience in writing, knowledge of the science of improvement and the evolving meaning of some terms in the field are hypothesised as the reasons for these findings. CONCLUSIONS: The original SQUIRE Guidelines help with planning healthcare improvement work, but are perceived as complicated and unclear during writing. Key goals of the revision will be to clarify items where conflict was identified and outline the key components necessary for complete reporting of improvement work.},
  langid = {english},
  pmcid = {PMC4680161},
  pmid = {26089206},
  keywords = {\_tablet,Health Services Research,Healthcare quality improvement,Humans,Interviews as Topic,Periodicals as Topic,Publishing,Qualitative research,Qualitative Research,Quality improvement,Quality Improvement,Quality of Health Care,Writing},
  file = {/Users/james/Zotero/storage/BHVV3ZHJ/Davies et al. - 2015 - The SQUIRE Guidelines an evaluation from the fiel.pdf;/Users/james/Zotero/storage/G68XATQ5/Davies et al_2015_The SQUIRE Guidelines.pdf}
}

@article{dechartresEvolutionPoorReporting2017,
  title = {Evolution of Poor Reporting and Inadequate Methods over Time in 20 920 Randomised Controlled Trials Included in {{Cochrane}} Reviews: Research on Research Study},
  shorttitle = {Evolution of Poor Reporting and Inadequate Methods over Time in 20 920 Randomised Controlled Trials Included in {{Cochrane}} Reviews},
  author = {Dechartres, Agnes and Trinquart, Ludovic and Atal, Ignacio and Moher, David and Dickersin, Kay and Boutron, Isabelle and Perrodeau, Elodie and Altman, Douglas G. and Ravaud, Philippe},
  year = {2017},
  month = jun,
  journal = {BMJ},
  volume = {357},
  pages = {j2490},
  publisher = {{British Medical Journal Publishing Group}},
  issn = {0959-8138, 1756-1833},
  doi = {10.1136/bmj.j2490},
  urldate = {2023-08-16},
  abstract = {Objective To examine how poor reporting and inadequate methods for key methodological features in randomised controlled trials (RCTs) have changed over the past three decades. Design Mapping of trials included in Cochrane reviews. Data sources Data from RCTs included in all Cochrane reviews published between March 2011 and September 2014 reporting an evaluation of the Cochrane risk of bias items: sequence generation, allocation concealment, blinding, and incomplete outcome data. Data extraction For each RCT, we extracted consensus on risk of bias made by the review authors and identified the primary reference to extract publication year and journal. We matched journal names with Journal Citation Reports to get 2014 impact factors. Main outcomes measures We considered the proportions of trials rated by review authors at unclear and high risk of bias as surrogates for poor reporting and inadequate methods, respectively. Results We analysed 20 920 RCTs (from 2001 reviews) published in 3136 journals. The proportion of trials with unclear risk of bias was 48.7\% for sequence generation and 57.5\% for allocation concealment; the proportion of those with high risk of bias was 4.0\% and 7.2\%, respectively. For blinding and incomplete outcome data, 30.6\% and 24.7\% of trials were at unclear risk and 33.1\% and 17.1\% were at high risk, respectively. Higher journal impact factor was associated with a lower proportion of trials at unclear or high risk of bias. The proportion of trials at unclear risk of bias decreased over time, especially for sequence generation, which fell from 69.1\% in 1986-1990 to 31.2\% in 2011-14 and for allocation concealment (70.1\% to 44.6\%). After excluding trials at unclear risk of bias, use of inadequate methods also decreased over time: from 14.8\% to 4.6\% for sequence generation and from 32.7\% to 11.6\% for allocation concealment. Conclusions Poor reporting and inadequate methods have decreased over time, especially for sequence generation and allocation concealment. But more could be done, especially in lower impact factor journals.},
  chapter = {Research},
  copyright = {Published by the BMJ Publishing Group Limited. For permission to use (where not already granted under a licence) please go to http://group.bmj.com/group/rights-licensing/permissions},
  langid = {english},
  pmid = {28596181},
  keywords = {Bias,Humans,Journal Impact Factor,Randomized Controlled Trials as Topic,Reference Standards,Research Design,Review Literature as Topic,Time Factors},
  file = {/Users/james/Library/Mobile Documents/iCloud~QReader~MarginStudy/Documents/DPhil/Dechartres et al_2017_Evolution of poor reporting and inadequate methods over time in 20 920.pdf;/Users/james/Zotero/storage/82TIH7QZ/Dechartres et al_2017_Evolution of poor reporting and inadequate methods over time in 20 920.pdf}
}

@article{dejongMetareviewDemonstratesImproved2021,
  title = {A Meta-Review Demonstrates Improved Reporting Quality of Qualitative Reviews Following the Publication of {{COREQ-}} and {{ENTREQ-checklists}}, Regardless of Modest Uptake},
  author = {{de Jong}, Y. and {van der Willik}, E. M. and Milders, J. and Voorend, C. G. N. and Morton, Rachael L. and Dekker, F. W. and Meuleman, Y. and {van Diepen}, M.},
  year = {2021},
  month = sep,
  journal = {BMC Medical Research Methodology},
  volume = {21},
  number = {1},
  pages = {184},
  issn = {1471-2288},
  doi = {10.1186/s12874-021-01363-1},
  urldate = {2023-08-17},
  abstract = {Reviews of qualitative studies allow for deeper understanding of concepts and findings beyond the single qualitative studies. Concerns on study reporting quality led to the publication of the COREQ-guidelines for qualitative studies~in 2007, followed by the ENTREQ-guidelines for qualitative reviews in 2012. The aim of this meta-review is to: 1) investigate the uptake of the COREQ- and ENTREQ- checklists in qualitative reviews; and 2) compare the~quality of reporting of the primary qualitative studies included~within these reviews prior- and post COREQ-publication.},
  keywords = {Appraisal,COREQ,ENTREQ,Impact study,Meta-review,Methodology,Qualitative research,Systematic review,Uptake},
  file = {/Users/james/Library/Mobile Documents/iCloud~QReader~MarginStudy/Documents/DPhil/de Jong et al_2021_A meta-review demonstrates improved reporting quality of qualitative reviews.pdf}
}

@article{dejongReaderFocusedTextEvaluation1997,
  title = {Reader-{{Focused Text Evaluation}}: {{An Overview}} of {{Goals}} and {{Methods}}},
  shorttitle = {Reader-{{Focused Text Evaluation}}},
  author = {DEJONG, {\relax MENNO} and SCHELLENS, PETER JAN},
  year = {1997},
  month = oct,
  journal = {Journal of Business and Technical Communication},
  volume = {11},
  number = {4},
  pages = {402--432},
  publisher = {{SAGE Publications Inc}},
  issn = {1050-6519},
  doi = {10.1177/1050651997011004003},
  urldate = {2022-10-17},
  abstract = {This article presents a review of the literature on reader-focused text evaluation. First, an account is given of the document characteristics that can be evaluated. Then the possible functions of evaluations are considered, a distinction being made between verifying, troubleshooting, and choice-supporting research. Finally, an overview is presented of methods appropriate for the various document characteristics and evaluation functions. Relevant research findings on the methodological strengths and constraints of each method are discussed.},
  langid = {english},
  file = {/Users/james/Library/Mobile Documents/iCloud~QReader~MarginStudy/Documents/DPhil/DEJONG_SCHELLENS_1997_Reader-Focused Text Evaluation.pdf}
}

@article{devriesProtocolFormatPreparation2015,
  title = {A Protocol Format for the Preparation, Registration and Publication of Systematic Reviews of Animal Intervention Studies},
  author = {{de Vries}, Rob B. M. and Hooijmans, Carlijn R. and Langendam, Miranda W. and {van Luijk}, Judith and Leenaars, Marlies and {Ritskes-Hoitinga}, Merel and Wever, Kimberley E.},
  year = {2015},
  journal = {Evidence-based Preclinical Medicine},
  volume = {2},
  number = {1},
  pages = {e00007},
  issn = {2054-703X},
  doi = {10.1002/ebm2.7},
  urldate = {2021-12-14},
  abstract = {Systematic reviews are an important method to support evidence-based decisions in healthcare (research). Although not yet as common as clinical systematic reviews, the number of systematic reviews of animal studies has been increasing steadily in recent years. An important method to promote high-quality systematic reviews is to pre-specify the review methodology in a protocol, before the conduct of the systematic review itself. In contrast to clinical systematic reviews, a standard protocol format for systematic reviews of animal studies is not yet available. Here, we present a protocol format tailored to the preparation, registration and publication of systematic reviews of animal intervention studies (i.e. systematic reviews of animal experiments studying the efficacy and/or safety of interventions intended for use in human patients). In analogy to the Cochrane review protocol, the format helps authors predefine the methodological approach of their systematic review, from research question to data synthesis. We recommend that authors prospectively complete and agree on the protocol, and register and/or publish it to allow feedback on the proposed methodology and to avoid the introduction of bias during the review process. Opportunities for obtaining feedback, and for registration and publication of review protocols are also discussed.},
  langid = {english},
  keywords = {\_tablet,animal,meta-analysis,pre-clinical studies,protocol,registration,systematic review},
  file = {/Users/james/Zotero/storage/EBTCPPU2/de Vries et al_2015_A protocol format for the preparation, registration and publication of.pdf;/Users/james/Zotero/storage/CD34AJMP/ebm2.html}
}

@article{deweyImpactPerceivedValue2019,
  title = {Impact and Perceived Value of Journal Reporting Guidelines among {{Radiology}} Authors and Reviewers},
  author = {Dewey, Marc and Levine, Deborah and Bossuyt, Patrick M. and Kressel, Herbert Y.},
  year = {2019},
  month = aug,
  journal = {European Radiology},
  volume = {29},
  number = {8},
  pages = {3986--3995},
  publisher = {{Springer Berlin Heidelberg}},
  issn = {1432-1084},
  doi = {10.1007/s00330-018-5980-3},
  urldate = {2021-09-03},
  abstract = {Objectives To analyse the author-perceived impact on the final manuscript and perceived value of journal reporting guidelines among Radiology authors and reviewers. Methods This survey was conducted among all corresponding authors of original research submissions to Radiology. Separately, we surveyed active Radiology reviewers. Results were analysed using logistic multivariate regression. Results Overall, 60\% of authors (831/1391) completed the survey. Only 15\% (120/821) had used the guideline and checklist when designing the study, significantly more so for PRISMA (55\%, 16/29) compared with STARD and STROBE users (17\%, 52/310; p\,{$<$}\,0.001 and 10\%, 46/443; p\,{$<$}\,0.001). For 23\% of the surveyed manuscripts (189/821), authors used the guidelines when writing the manuscript; these authors more often reported an impact on the final manuscript (i.e. changes in the content, 57\%, 107/189) compared to those who used the guideline when submitting the manuscript (35\%, 95/272; p\,{$<$}\,0.001; OR 0.433, 95\% confidence interval [CI] 0.288\textendash 0.648, p\,{$<$}\,0.001) or when the checklist was requested by the editorial office (17\%, 41/240; p\,{$<$}\,0.001; OR 0.156, CI 0.097\textendash 0.247, p\,{$<$}\,0.001). The perceived value of the reporting guideline was rated significantly higher the earlier the authors used the guideline in the research process (p\,{$<$}\,0.001). The checklist was used by 77\% of reviewers (200/259) some or all of the time; 60\% (119/199) said it affected their reviews. Conclusion Reporting guidelines had more author-perceived impact on the final manuscript and higher perceived value the earlier they were used, suggesting that there is a need for enhanced education on the use of these guidelines. Key Points \textbullet{} Only 15\% of authors had used the respective reporting guideline and checklist when designing the study. \textbullet{} Almost 4 out of 5 Radiology authors and half of reviewers judged the guideline checklists to be useful or very useful. \textbullet{} Reporting guidelines had more author-perceived impact on manuscripts, i.e. changes that were made in the final manuscript, the earlier authors used them in the research process.},
  copyright = {2019 European Society of Radiology},
  langid = {english},
  keywords = {\_tablet,*Checklist,*diagnostic imaging,*Guidelines as Topic,*information dissemination,*Periodicals as Topic,*practice guideline,*questionnaire,*radiology,*Radiology,*Research Report/st [Standards],*Writing,article,checklist,education,human,human experiment,Humans,Peer Review,publication,QES-include,Radiology,Research/st [Standards],writing},
  file = {/Users/james/Zotero/storage/SGHZRN7D/Dewey et al_2019_Impact and perceived value of journal reporting guidelines among Radiology.pdf;/Users/james/Zotero/storage/8TVXMS29/s00330-018-5980-3.html}
}

@article{dolanMINDSPACEInfluencingBehaviour2010,
  title = {{{MINDSPACE}}: Influencing Behaviour for Public Policy},
  author = {Dolan, Paul and Hallsworth, Michael and Halpern, David and King, Dominic and Vlaev, Ivo},
  year = {2010},
  publisher = {{Institute of Government}}
}

@misc{DownloadFreeVectors,
  title = {Download {{Free Vectors}}, {{Images}}, {{Stock Photos}} \& {{Stock Videos}}},
  journal = {Vecteezy},
  urldate = {2023-10-03},
  abstract = {Explore millions of royalty free vectors, images, photos, and videos! Find the perfect graphic, background, illustration, template, or icon for your design.},
  howpublished = {https://www.vecteezy.com/},
  langid = {english}
}

@misc{ecommercefoundationEcommerceBenchmarkRetail,
  title = {Ecommerce {{Benchmark Retail Report}} 2016},
  author = {{Ecommerce Foundation}},
  journal = {Ecommerce Europe},
  urldate = {2023-08-02},
  howpublished = {https://www.ecommerce-europe.eu/wp-content/uploads/2016/06/Ecommerce-Benchmark-Retail-Report-2016.pdf},
  file = {/Users/james/Zotero/storage/6XE97NT9/Ecommerce-Benchmark-Retail-Report-2016.pdf}
}

@misc{EQUATORNetworkEnhancing,
  title = {The {{EQUATOR Network}} | {{Enhancing}} the {{QUAlity}} and {{Transparency Of Health Research}}},
  urldate = {2020-02-14},
  howpublished = {https://www.equator-network.org/},
  file = {/Users/james/Zotero/storage/9ACX4BQX/www.equator-network.org.html}
}

@misc{EQUATORNetworkGoogle,
  title = {The {{EQUATOR Network Google Analytics}}},
  urldate = {2022-07-28},
  howpublished = {https://www.equator-network.org/analytics}
}

@misc{experienceGuideUsingUserExperience,
  title = {A {{Guide}} to {{Using User-Experience Research Methods}}},
  author = {Experience, World Leaders in Research-Based User},
  journal = {Nielsen Norman Group},
  urldate = {2022-09-30},
  abstract = {Modern day UX research methods answer a wide range of questions. To help you know when to use which user research method, each of 20 methods is mapped across 3 dimensions and over time within a typical product-development process.},
  howpublished = {https://www.nngroup.com/articles/guide-ux-research-methods/},
  langid = {english}
}

@misc{experienceNielsenNormanGroup,
  title = {Nielsen {{Norman Group}}: {{UX Training}}, {{Consulting}}, \& {{Research}}},
  shorttitle = {Nielsen {{Norman Group}}},
  author = {Experience, World Leaders in Research-Based User},
  journal = {Nielsen Norman Group},
  urldate = {2023-10-05},
  abstract = {A leader in the user experience field, NN/g conducts groundbreaking research, trains and certifies UX practitioners, and provides UX consulting to clients.},
  howpublished = {https://www.nngroup.com/},
  langid = {english}
}

@misc{experiencePersonasMakeUsers,
  title = {Personas {{Make Users Memorable}} for {{Product Team Members}}},
  author = {Experience, World Leaders in Research-Based User},
  journal = {Nielsen Norman Group},
  urldate = {2023-10-06},
  abstract = {When based on user research, personas support user-centered design throughout a project's lifecycle by making characteristics of key user segments more salient.},
  howpublished = {https://www.nngroup.com/articles/persona/},
  langid = {english}
}

@article{eysenbachg.CONSORTEHEALTHImplementationChecklist2013,
  title = {{{CONSORT-EHEALTH}}: Implementation of a Checklist for Authors and Editors to Improve Reporting of Web-Based and Mobile Randomized Controlled Trials},
  author = {{Eysenbach G.}},
  year = {2013},
  journal = {Studies in health technology and informatics},
  volume = {192},
  pages = {657--661},
  issn = {0926-9630},
  abstract = {BACKGROUND: Randomized trials of web-based and mobile interventions pose very specific issues and challenges. A set of best practices on how to conduct and report such trials was recently summarized in the CONSORT-EHEALTH statement (Consolidated Standards of Reporting Trials of Electronic and Mobile HEalth Applications and onLine TeleHealth), published in August 2011 as draft and in December 2011 as journal article (V1.6.1). The purpose of this presentation is to review the results of the pilot implementation at the Journal of Medical Internet Research (JMIR), a leading eHealth journal, where reporting of trials in accordance with CONSORT-EHEALTH became mandatory in late 2011., METHODS: Authors of all randomized trials submitted to JMIR were asked to complete an electronic questionnaire, which involved copying pertinent manuscript sections into a CONSORT EHEALTH database form, were asked to score the importance of CONSORT EHEALTH items, and were asked to provide narrative feedback on the value of the process., RESULTS: Between August 2011 and November 2012, 67 randomized trials were submitted, of which 61 were intended for publication in JMIR. Authors reported that it took between 1 and 16 hours to complete the checklist including making required changes to their manuscripts. 72\textbackslash\% (48/67) of authors reported they made minor changes to the manuscript, 6\textbackslash\% (4/67) made major changes. Most authors felt it was a useful process that improved their manuscripts: 63\textbackslash\% (42/67) said it improved their manuscript, 13\textbackslash\% (9/67) said it did not, 12\textbackslash\% (8/67) indicated that it had improved a little., CONCLUSIONS: The CONSORT EHEALTH statement and checklist appeared successful in improving the quality of reporting. The checklist should be endorsed and used by authors and editors of other journals.},
  langid = {english},
  keywords = {\_tablet,*Checklist/st [Standards],*Internet/st [Standards],*Manuscripts as Topic,*practice guideline,*Practice Guidelines as Topic,*publication,*Randomized Controlled Trials as Topic/st [Standards],*standards,*Telemedicine/st [Standards],*Writing/st [Standards],Canada,checklist,Guideline Adherence,Internet,randomized controlled trial (topic),telemedicine,Telemedicine,writing},
  file = {/Users/james/Zotero/storage/I6A7NSAU/Eysenbach G._2013_CONSORT-EHEALTH.pdf}
}

@article{fangSurveyAwarenessARRIVE2015,
  title = {{A survey on awareness of the ARRIVE guideline and GSPC in researchers field in animal experiments field in Lanzhou city}},
  author = {{Fang Z.-P.} and {Leng X.} and {Liu Y.-L.} and {Liu W.-B.} and {Hu W.-J.} and {Zhang Z.-J.} and {Ma B.} and {Li D.-M.}},
  year = {2015},
  journal = {Chinese Journal of Evidence-Based Medicine},
  volume = {15},
  number = {7},
  pages = {797--801},
  issn = {1672-2531},
  abstract = {Objective To investigate the awareness situation on the ARRIVE guideline and the Gold Standard Publication Checklist (GSPC) of animal experiments in researchers in animal experiments field in Lanzhou city, in order to improve the promotion of the two reporting guidelines in China. Methods A self-designed questionnaire was used to investigate the clinical graduate students and teachers in medical college in Lanzhou city. The investigation contents mainly included the basic information of the respondents, the awareness situation on the ARRIVE guideline, GSPC and other medical reporting guidelines. SPSS 21.0 software was used for data analysis. Results A total of 329 questionnaires (40 were from teachers and 289 were from graduate students) were issued, of which, 287 questionnaires were effective. The results showed that the awareness rate on the ARRIVE guideline and GSPC in clinical graduate students and teachers in medical college in Lanzhou city were 11.8\textbackslash\% and 12.5\textbackslash\%, respectively, and there was no significant difference between students and teachers in awareness rate (P=0.903). The survey approaches, the age, education, job, and the organization of the respondents were all not the influence factors of awareness rate (P\{\textbackslash textgreater\}0.05). The respondents knew about the reporting guidelines mainly through the website (33.4\textbackslash\%), related studies (21.2\textbackslash\%) and academic reports (17.4\textbackslash\%). Conclusion The awareness rate on the ARRIVE guideline and GSPC is relative low in researchers in animal experiments field in Lanzhou city, and it needed to take purposeful measures to promote and popularize them.Copyright \textcopyright{} 2015 Editorial Board of Chin J Evid-based Med.},
  langid = {chinese},
  keywords = {\_tablet,*ARRIVE guideline,*gold standard publication checklist,*medical research,*practice guideline,animal experiment,Animal Shells,Animals,article,graduate student,human,medical school,publication,questionnaire,scientist,teacher},
  file = {/Users/james/Zotero/storage/N3ULDD54/Fang Z.-P. et al_2015_A survey on awareness of the ARRIVE guideline and GSPC in researchers field in.pdf}
}

@article{feinsteinClinicalBiostatisticsXXV1974,
  title = {Clinical Biostatistics. {{XXV}}. {{A}} Survey of the Statistical Procedures in General Medical Journals},
  author = {Feinstein, A. R.},
  year = {1974},
  month = jan,
  journal = {Clinical Pharmacology and Therapeutics},
  volume = {15},
  number = {1},
  pages = {97--107},
  issn = {0009-9236},
  doi = {10.1002/cpt197415197},
  langid = {english},
  pmid = {4808744},
  keywords = {Analysis of Variance,Canada,Medicine,Periodicals as Topic,Statistics as Topic,United Kingdom,United States}
}

@article{fishbeinFactorsInfluencingBehavior2001,
  title = {Factors Influencing Behavior and Behavior Change},
  author = {Fishbein, Martin and Triandis, Harry C and Kanfer, Frederick H and Becker, Marshall and Middlestadt, Susan E and Eichler, Anita and others},
  year = {2001},
  journal = {Handbook of health psychology},
  volume = {3},
  number = {1},
  pages = {3--17}
}

@misc{FreeIconsStickers,
  title = {Free {{Icons}} and {{Stickers}} - {{Millions}} of Images to Download},
  journal = {Flaticon},
  urldate = {2023-10-03},
  abstract = {Download Free Icons and Stickers for your projects. Images made by and for designers in PNG, SVG, EPS, PSD and CSS formats},
  howpublished = {https://www.flaticon.com/https\%3A\%2F\%2Fwww.flaticon.com\%2F},
  langid = {english}
}

@misc{FreepikDownloadFree,
  title = {Freepik: {{Download Free Videos}}, {{Vectors}}, {{Photos}}, and {{PSD}}},
  shorttitle = {Freepik},
  journal = {Freepik},
  urldate = {2023-10-03},
  abstract = {Millions of Free Graphic Resources. \ding{51} Videos \ding{51}Vectors \ding{51} Photos \ding{51} PSD \ding{51} Icons. All that you need for your Creative Projects. \#freepik},
  howpublished = {https://www.freepik.com},
  langid = {english}
}

@article{fullerWhatAffectsAuthors2015,
  title = {What Affects Authors' and Editors' Use of Reporting Guidelines? {{Findings}} from an Online Survey and Qualitative Interviews.},
  shorttitle = {What Affects Authors' and Editors' Use of Reporting Guidelines?},
  author = {Fuller, Thomas and Pearson, Mark and Peters, Jaime and Anderson, Rob},
  year = {2015},
  month = jan,
  journal = {PLoS ONE},
  volume = {10},
  number = {4},
  pages = {e0121585},
  publisher = {{Public Library of Science (PLoS)}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0121585},
  urldate = {2020-12-03},
  abstract = {OBJECTIVES:To identify and understand, through data from multiple sources, some of the factors that affect authors' and editors' decisions to use reporting...},
  langid = {english},
  keywords = {\_tablet},
  file = {/Users/james/Zotero/storage/ZTPBAP4X/Fuller et al_2015_What affects authors' and editors' use of reporting guidelines.pdf;/Users/james/Zotero/storage/FELLCV7U/36330708eb094f5f987c245860786e4c.html;/Users/james/Zotero/storage/Z4JQ2LZR/36330708eb094f5f987c245860786e4c.html}
}

@misc{GA4AutomaticallyCollected,
  title = {[{{GA4}}] {{Automatically}} Collected Events - {{Firebase Help}}},
  urldate = {2023-07-31},
  howpublished = {https://support.google.com/firebase/answer/9234069?sjid=11808073354477924035-EU\&visit\_id=638263997154270219-1141820337\&rd=1}
}

@misc{GA4PredefinedUser,
  title = {[{{GA4}}] {{Predefined}} User Dimensions - {{Firebase Help}}},
  urldate = {2023-07-31},
  howpublished = {https://support.google.com/firebase/answer/9268042?sjid=11808073354477924035-EU\&visit\_id=638263997154270219-1141820337\&rd=1}
}

@article{girayAssessmentKnowledgeAwareness2020a,
  title = {Assessment of the Knowledge and Awareness of a Sample of Young Researcher Physicians on Reporting Guidelines and the {{EQUATOR}} Network: {{A}} Single Center Cross-Sectional Study},
  shorttitle = {Assessment of the Knowledge and Awareness of a Sample of Young Researcher Physicians on Reporting Guidelines and the {{EQUATOR}} Network},
  author = {G{\.i}ray, Esra and Coskun, Ozge KENIS and Karacaatli, Meltem and Gunduz, Osman Hakan and Yagci, {\.I}lker},
  year = {2020},
  month = jan,
  journal = {Marmara Medical Journal},
  volume = {33},
  number = {1},
  pages = {1--6},
  issn = {1019-1941},
  doi = {10.5472/marumj.682337},
  urldate = {2021-12-29},
  langid = {english},
  keywords = {\_tablet,*awareness,*cross-sectional study,*practice guideline,*resident,adult,article,Cesarean Section,Cross-Sectional Studies,female,human,human experiment,male,questionnaire,writing},
  file = {/Users/james/Zotero/storage/6FLRQJ5J/Giray et al_2020_Assessment of the knowledge and awareness of a sample of young researcher.pdf;/Users/james/Zotero/storage/4E6UUX47/682337.html}
}

@misc{GitHubPages,
  title = {{{GitHub Pages}}},
  journal = {GitHub Pages},
  urldate = {2023-08-04},
  abstract = {Websites for you and your projects, hosted directly from your GitHub repository. Just edit, push, and your changes are live.},
  howpublished = {https://pages.github.com/},
  langid = {english}
}

@incollection{givenFocusGroups2008,
  title = {Focus {{Groups}}},
  booktitle = {The {{SAGE Encyclopedia}} of {{Qualitative Research Methods}}},
  author = {Given, Lisa},
  year = {2008},
  pages = {353--354},
  publisher = {{SAGE Publications, Inc.}},
  address = {{Thousand Oaks}},
  doi = {10.4135/9781412963909},
  urldate = {2023-06-26},
  keywords = {depth interviews,focus groups,group composition,group interview,in-depth interviews,interviews,moderator}
}

@article{glasziouReducingWasteIncomplete2014,
  title = {Reducing Waste from Incomplete or Unusable Reports of Biomedical Research},
  author = {Glasziou, Paul and Altman, Douglas G. and Bossuyt, Patrick and Boutron, Isabelle and Clarke, Mike and Julious, Steven and Michie, Susan and Moher, David and Wager, Elizabeth},
  year = {2014},
  month = jan,
  journal = {Lancet (London, England)},
  volume = {383},
  number = {9913},
  pages = {267--276},
  issn = {1474-547X},
  doi = {10.1016/S0140-6736(13)62228-X},
  abstract = {Research publication can both communicate and miscommunicate. Unless research is adequately reported, the time and resources invested in the conduct of research is wasted. Reporting guidelines such as CONSORT, STARD, PRISMA, and ARRIVE aim to improve the quality of research reports, but all are much less adopted and adhered to than they should be. Adequate reports of research should clearly describe which questions were addressed and why, what was done, what was shown, and what the findings mean. However, substantial failures occur in each of these elements. For example, studies of published trial reports showed that the poor description of interventions meant that 40-89\% were non-replicable; comparisons of protocols with publications showed that most studies had at least one primary outcome changed, introduced, or omitted; and investigators of new trials rarely set their findings in the context of a systematic review, and cited a very small and biased selection of previous relevant trials. Although best documented in reports of controlled trials, inadequate reporting occurs in all types of studies-animal and other preclinical studies, diagnostic studies, epidemiological studies, clinical prediction research, surveys, and qualitative studies. In this report, and in the Series more generally, we point to a waste at all stages in medical research. Although a more nuanced understanding of the complex systems involved in the conduct, writing, and publication of research is desirable, some immediate action can be taken to improve the reporting of research. Evidence for some recommendations is clear: change the current system of research rewards and regulations to encourage better and more complete reporting, and fund the development and maintenance of infrastructure to support better reporting, linkage, and archiving of all elements of research. However, the high amount of waste also warrants future investment in the monitoring of and research into reporting of research, and active implementation of the findings to ensure that research reports better address the needs of the range of research users.},
  langid = {english},
  pmid = {24411647},
  keywords = {Access to Information,Biomedical Research,Documentation,Guidelines as Topic,Humans,Information Dissemination,Periodicals as Topic,Publishing,Randomized Controlled Trials as Topic,Research Design},
  file = {/Users/james/Zotero/storage/B2H6QN6B/Glasziou et al. - 2014 - Reducing waste from incomplete or unusable reports.pdf;/Users/james/Zotero/storage/9L4CDWIA/fulltext.html}
}

@article{glasziouReducingWasteIncomplete2014a,
  title = {Reducing Waste from Incomplete or Unusable Reports of Biomedical Research},
  author = {Glasziou, Paul and Altman, Douglas G. and Bossuyt, Patrick and Boutron, Isabelle and Clarke, Mike and Julious, Steven and Michie, Susan and Moher, David and Wager, Elizabeth},
  year = {2014},
  month = jan,
  journal = {The Lancet},
  volume = {383},
  number = {9913},
  pages = {267--276},
  publisher = {{Elsevier}},
  issn = {0140-6736, 1474-547X},
  doi = {10.1016/S0140-6736(13)62228-X},
  urldate = {2023-08-08},
  langid = {english},
  pmid = {24411647}
}

@article{glasziouWhatMissingDescriptions2008,
  title = {What Is Missing from Descriptions of Treatment in Trials and Reviews?},
  author = {Glasziou, Paul and Meats, Emma and Heneghan, Carl and Shepperd, Sasha},
  year = {2008},
  month = jun,
  journal = {BMJ},
  volume = {336},
  number = {7659},
  pages = {1472--1474},
  publisher = {{British Medical Journal Publishing Group}},
  issn = {0959-8138, 1756-1833},
  doi = {10.1136/bmj.39590.732037.47},
  urldate = {2023-08-29},
  abstract = {{$<$}p{$>$}Replicating non-pharmacological treatments in practice depends on how well they have been described in research studies{$<$}/p{$>$}},
  chapter = {Analysis},
  copyright = {\textcopyright{} BMJ Publishing Group Ltd 2008},
  langid = {english},
  pmid = {18583680},
  file = {/Users/james/Library/Mobile Documents/iCloud~QReader~MarginStudy/Documents/DPhil/Glasziou et al_2008_What is missing from descriptions of treatment in trials and reviews.pdf}
}

@article{glickInadequaciesReportingClinical1963,
  title = {Inadequacies in the Reporting of Clinical Drug Research},
  author = {Glick, B. S.},
  year = {1963},
  month = apr,
  journal = {The Psychiatric Quarterly},
  volume = {37},
  pages = {234--244},
  issn = {0033-2720},
  doi = {10.1007/BF01562195},
  langid = {english},
  pmid = {13948469},
  keywords = {Humans,Psychopharmacology,PSYCHOPHARMACOLOGY,Research,RESEARCH}
}

@misc{GoodReportsOrg,
  title = {{{GoodReports}}.Org},
  urldate = {2020-02-14},
  abstract = {GoodReports helps medical researchers find and use appropriate reporting guidelines and checklists.},
  howpublished = {https://www.goodreports.org},
  langid = {english},
  file = {/Users/james/Zotero/storage/MRJN2FXR/uHYDAr.html}
}

@misc{Guideline,
  title = {Guideline},
  urldate = {2023-01-10},
  abstract = {1. information intended to advise people on how something should be done or\ldots},
  howpublished = {https://dictionary.cambridge.org/dictionary/english/guideline},
  langid = {english}
}

@article{guoRecognitionStatusQuality2018,
  title = {Recognition Status of Quality Assessment and Standards for Reporting Randomized Controlled Trials of Traditional {{Chinese}} Medicine Researchers},
  author = {Guo, Sheng-nan and Qi, Shu-lan and Yang, Li-li and Wang, Xiao-hong and Zhu, Qi and Meng, Xing and Zeng, Yi and of Institute, Moxibustion {and} Acupuncture and China, Sciences Medical Chinese of Academy},
  year = {2018},
  journal = {China Journal of Traditional Chinese Medicine and Pharmacy},
  number = {3},
  pages = {1077--1081},
  urldate = {2022-06-20},
  abstract = {Objective: To clarify the degree of the comprehension and attaching importance of traditional Chinese medicine(TCM) researchers. To attain the current status of knowledge and quality of the scientific research and cover the shortage of the missing clinical research knowledge, and improve the study level. Methods: A cross-sectional study was established and the questionnaire was filled out by TCM researchers. A total of 180 pieces were collected as the qualified one. The descriptive statistic method, nonparametric method and the Spearman relevant analysis were used to deal with the collected data. Results: According to the mean rank of each items,(1)the degree of the comprehension of TCM researchers from high to low: Cochrane risk of bias{$>$} CONSORT statement{$>$} Jadad scale{$>$} modified Jadad scale{$>$} CONSORT statement expand(STRICTA){$>$} CONSORT statement expand(for TCM){$>$} CASP list(for RCT){$>$} other CONSORT statement expand.(2)the degree of attaching importance of TCM researchers from high to low: Cochrane risk of bias{$>$} CONSORT statement{$>$} Jadad scale{$>$} modified Jadad scale{$>$} CONSORT statement expand(STRICTA){$>$} CONSORT statement expand(for TCM){$>$} CASP list(for RCT){$>$} other CONSORT statement expand. Conclusion: The degree of the comprehension and attaching importance of TCM researchers are limited. There are great variances between different assessment tools and report standards. It is necessary to enhance the education of different kinds of researchers and establish the understanding of the randomized controlled trial from multiple aspects, so as to improve the clinical research level of TCM researchers.},
  keywords = {Quality assessment tool,Randomized controlled clinical trial,Report specification,Researchers,Status,Traditional Chinese medicine}
}

@article{haddawayPRISMA2020PackageShiny2022,
  title = {{{PRISMA2020}}: {{An R}} Package and {{Shiny}} App for Producing {{PRISMA}} 2020-Compliant Flow Diagrams, with Interactivity for Optimised Digital Transparency and {{Open Synthesis}}},
  shorttitle = {{{PRISMA2020}}},
  author = {Haddaway, Neal R. and Page, Matthew J. and Pritchard, Chris C. and McGuinness, Luke A.},
  year = {2022},
  journal = {Campbell Systematic Reviews},
  volume = {18},
  number = {2},
  pages = {e1230},
  issn = {1891-1803},
  doi = {10.1002/cl2.1230},
  urldate = {2023-10-24},
  abstract = {Background Reporting standards, such as PRISMA aim to ensure that the methods and results of systematic reviews are described in sufficient detail to allow full transparency. Flow diagrams in evidence syntheses allow the reader to rapidly understand the core procedures used in a review and examine the attrition of irrelevant records throughout the review process. Recent research suggests that use of flow diagrams in systematic reviews is poor and of low quality and called for standardised templates to facilitate better reporting in flow diagrams. The increasing options for interactivity provided by the Internet gives us an opportunity to support easy-to-use evidence synthesis tools, and here we report on the development of a tool for the production of PRISMA 2020-compliant systematic review flow diagrams. Methods and Findings We developed a free-to-use, Open Source R package and web-based Shiny app to allow users to design PRISMA flow diagrams for their own systematic reviews. Our tool allows users to produce standardised visualisations that transparently document the methods and results of a systematic review process in a variety of formats. In addition, we provide the opportunity to produce interactive, web-based flow diagrams (exported as HTML files), that allow readers to click on boxes of the diagram and navigate to further details on methods, results or data files. We provide an interactive example here; https://prisma-flowdiagram.github.io/. Conclusions We have developed a user-friendly tool for producing PRISMA 2020-compliant flow diagrams for users with coding experience and, importantly, for users without prior experience in coding by making use of Shiny (https://estech.shinyapps.io/prisma\_flowdiagram/). This free-to-use tool will make it easier to produce clear and PRISMA 2020-compliant systematic review flow diagrams. Significantly, users can also produce interactive flow diagrams for the first time, allowing readers of their reviews to smoothly and swiftly explore and navigate to further details of the methods and results of a review. We believe this tool will increase use of PRISMA flow diagrams, improve the compliance and quality of flow diagrams, and facilitate strong science communication of the methods and results of systematic reviews by making use of interactivity. We encourage the systematic review community to make use of the tool, and provide feedback to streamline and improve their usability and efficiency.},
  copyright = {\textcopyright{} 2022 The Authors. Campbell Systematic Reviews published by John Wiley \& Sons Ltd on behalf of The Campbell Collaboration.},
  langid = {english},
  file = {/Users/james/Library/Mobile Documents/iCloud~QReader~MarginStudy/Documents/DPhil/Haddaway et al_2022_PRISMA2020.pdf}
}

@article{hairRandomisedControlledTrial2019,
  title = {A Randomised Controlled Trial of an {{Intervention}} to {{Improve Compliance}} with the {{ARRIVE}} Guidelines ({{IICARus}})},
  author = {Hair, Kaitlyn and Macleod, Malcolm R. and Sena, Emily S. and Sena, Emily S. and Hair, Kaitlyn and Macleod, Malcolm R. and Howells, David and Bath, Philip and Irvine, Cadi and MacCallum, Catriona and Morrison, Gavin and Clark, Alejandra and Alvino, Gina and Dohm, Michelle and Liao, Jing and Sena, Chris and Moreland, Rosie and Cramond, Fala and Currie, Gillian L. and Bahor, Zsanett and Grill, Paula and {Bannach-Brown}, Alexandra and Marcu, Daniel-Cosmin and Antar, Sarah and Blazek, Katrina and Konold, Timm and Dingwall, Monica and Hohendorf, Victoria and Hosh, Mona and Gerlei, Klara Zsofia and Wever, Kimberley Elaine and Jones, Victor and Quinn, Terence J. and Karp, Natasha A. and Freymann, Jennifer and Shek, Anthony and Gregorc, Teja and Rinaldi, Arianna and Jheeta, Privjyot and Nazzal, Ahmed and Henshall, David Ewart and Storey, Joanne and Baginskaite, Julija and {de Oliveira}, Cilene Lino and Laban, Kamil and Charbonney, Emmanuel and Lynn, Savannah A. and Cascella, Marco and Wheater, Emily and Baker, Daniel and Cheyne, Ryan and Christopher, Edward and Roncon, Paolo and {De-Souza}, Evandro Ara{\'u}jo and Warda, Mahmoud and Corke, Sarah and Ammar, Zeinab and O'Connor, Leigh and Devonshire, Ian M. and McCann, Sarah K. and Gray, Laura J. and {Tanriver-Ayder}, Ezgi and {on behalf of the IICARus Collaboration}},
  year = {2019},
  month = jun,
  journal = {Research Integrity and Peer Review},
  volume = {4},
  number = {1},
  pages = {12},
  issn = {2058-8615},
  doi = {10.1186/s41073-019-0069-3},
  urldate = {2021-08-23},
  abstract = {The ARRIVE (Animal Research: Reporting of In Vivo Experiments) guidelines are widely endorsed but compliance is limited. We sought to determine whether journal-requested completion of an ARRIVE checklist improves full compliance with the guidelines.},
  keywords = {ARRIVE,Randomised controlled trial,Reporting guidelines},
  file = {/Users/james/Zotero/storage/4VGU2XPZ/Hair et al_2019_A randomised controlled trial of an Intervention to Improve Compliance with the.pdf;/Users/james/Zotero/storage/J2QWLZPM/s41073-019-0069-3.html}
}

@article{hawwashUsefulnessApplyingResearch2019,
  title = {Usefulness of Applying Research Reporting Guidelines as {{Writing Aid}} Software: A Crossover Randomised Controlled Trial},
  shorttitle = {Usefulness of Applying Research Reporting Guidelines as {{Writing Aid}} Software},
  author = {Hawwash, Dana and Sharp, Melissa K. and Argaw, Alemayehu and Kolsteren, Patrick and Lachat, Carl},
  year = {2019},
  month = nov,
  journal = {BMJ Open},
  volume = {9},
  number = {11},
  issn = {2044-6055, 2044-6055},
  doi = {10.1136/bmjopen-2019-030943},
  urldate = {2020-02-14},
  abstract = {{$<$}h3{$>$}Objectives{$<$}/h3{$>$} {$<$}p{$>$}To assess the intention of using a Writing Aid software, which integrates four research reporting guidelines (Consolidated Standards of Reporting Trials, Preferred Reporting Items for Systematic Reviews and Meta-Analyses, Strengthening the Reporting of Observational Studies in Epidemiology and STrengthening the Reporting of Observational Studies in Epidemiology-nutritional epidemiology) and their Elaboration \&amp; Explanation (E\&amp;E) documents during the write-up of research in Microsoft Word compared with current practices.{$<$}/p{$><$}h3{$>$}Design{$<$}/h3{$>$} {$<$}p{$>$}Two-arms crossover randomised controlled trial with no blinding and no washout period.{$<$}/p{$><$}h3{$>$}Setting{$<$}/h3{$>$} {$<$}p{$>$}Face-to-face or online sessions.{$<$}/p{$><$}h3{$>$}Participants{$<$}/h3{$>$} {$<$}p{$>$}54 (28 in arm 1 and 26 in arm 2) doctoral and postdoctoral researchers.{$<$}/p{$><$}h3{$>$}Interventions{$<$}/h3{$>$} {$<$}p{$>$}Reporting guidelines and their E\&amp;E document were randomly administered as Writing Aid or as Word documents in a single 30 min to 1 hour session, with a short break before crossing over to the other study intervention.{$<$}/p{$><$}h3{$>$}Primary and secondary outcomes{$<$}/h3{$>$} {$<$}p{$>$}Using the Technology Acceptance Model, we assessed the primary outcome: the difference in the mean of intention of use; and secondary outcomes: the difference in mean perceived ease of use and perceived usefulness. The three outcomes were measured using questions with a 7-point Likert-scale. Secondary analysis using structural equation modelling (SEM) was applied to explore the relationships between the outcomes.{$<$}/p{$><$}h3{$>$}Results{$<$}/h3{$>$} {$<$}p{$>$}No significant difference in reported intention of use (mean difference and 95\% CI 0.25 (\textendash 0.05 to 0.55), p=0.10), and perceived usefulness (mean difference and 95\% CI 0.19 (\textendash 0.04 to 0.41), p=0.10). The Writing Aid performed significantly better than the word document on researchers' perceived ease of use (mean difference and 95\% CI 0.59 (0.29 to 0.89), p\&lt;0.001). In the SEM analysis, participants' intention of using the tools was indirectly affected by perceived ease of use (beta 0.53 p\emph{=}0.002).{$<$}/p{$><$}h3{$>$}Conclusions{$<$}/h3{$>$} {$<$}p{$>$}Despite no significant difference in the intention of use between the tools, administering reporting guidelines as Writing Aid is perceived as easier to use, offering a possibility to further explore its applicability to enhance reporting adherence.{$<$}/p{$>$}},
  copyright = {\textcopyright{} Author(s) (or their employer(s)) 2019. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.. This is an open access article distributed in accordance with the Creative Commons Attribution Non Commercial (CC BY-NC 4.0) license, which permits others to distribute, remix, adapt, build upon this work non-commercially, and license their derivative works on different terms, provided the original work is properly cited, appropriate credit is given, any changes made indicated, and the use is non-commercial. See:~http://creativecommons.org/licenses/by-nc/4.0/.},
  langid = {english},
  pmid = {31699728},
  keywords = {Explanation,Extension,Science General,Strobe Statement,Technology Acceptance Model},
  file = {/Users/james/Zotero/storage/447K7CID/Hawwash et al_2019_Usefulness of applying research reporting guidelines as Writing Aid software.pdf;/Users/james/Zotero/storage/PVR7PF59/e030943.html}
}

@misc{HealthMedicalArticles,
  title = {Health and {{Medical Articles Database}} - {{African Index Medicus}}},
  urldate = {2021-03-01},
  howpublished = {https://indexmedicus.afro.who.int/},
  file = {/Users/james/Zotero/storage/GN4PPF26/indexmedicus.afro.who.int.html}
}

@article{hopewellEffectEditorsImplementation2012,
  title = {Effect of Editors' Implementation of {{CONSORT}} Guidelines on the Reporting of Abstracts in High Impact Medical Journals: Interrupted Time Series Analysis},
  shorttitle = {Effect of Editors' Implementation of {{CONSORT}} Guidelines on the Reporting of Abstracts in High Impact Medical Journals},
  author = {Hopewell, Sally and Ravaud, Philippe and Baron, Gabriel and Boutron, Isabelle},
  year = {2012},
  month = jun,
  journal = {BMJ},
  volume = {344},
  pages = {e4178},
  publisher = {{British Medical Journal Publishing Group}},
  issn = {1756-1833},
  doi = {10.1136/bmj.e4178},
  urldate = {2023-09-22},
  abstract = {Objective To investigate the effect of the CONSORT for Abstracts guidelines, and different editorial policies used by five leading general medical journals to implement the guidelines, on the reporting quality of abstracts of randomised trials. Design Interrupted time series analysis. Sample We randomly selected up to 60 primary reports of randomised trials per journal per year from five high impact, general medical journals in 2006-09, if indexed in PubMed with an electronic abstract. We excluded reports that did not include an electronic abstract, and any secondary trial publications or economic analyses. We classified journals in three categories: those not mentioning the guidelines in their instructions to authors (JAMA and New England Journal of Medicine), those referring to the guidelines in their instructions to authors but with no specific policy to implement them (BMJ), and those referring to the guidelines in their instructions to authors with an active policy to implement them (Annals of Internal Medicine and Lancet). Two authors extracted data independently using the CONSORT for Abstracts checklist. Main outcome Mean number of CONSORT items reported in selected abstracts, among nine items reported in fewer than 50\% of the abstracts published across the five journals in 2006. Results We assessed 955 reports of abstracts of randomised trials. Journals with an active policy to enforce the guidelines showed an immediate increase in the level of mean number of items reported (increase of 1.50 items; P=0.0037). At 23 months after publication of the guidelines, the mean number of items reported per abstract for the primary outcome was 5.41 of nine items, a 53\% increase compared with the expected level estimated on the basis of pre-intervention trends. The change in level or trend did not increase in journals with no policy to enforce the guidelines (BMJ, JAMA, and New England Journal of Medicine). Conclusion Active implementation of the CONSORT for Abstracts guidelines by journals can lead to improvements in the reporting of abstracts of randomised trials.},
  chapter = {Research},
  copyright = {\textcopyright{} Hopewell et al 2012. This is an open-access article distributed under the terms of the Creative Commons Attribution Non-commercial License, which permits use, distribution, and reproduction in any medium, provided the original work is properly cited, the use is non commercial and is otherwise in compliance with the license. See: http://creativecommons.org/licenses/by-nc/2.0/  and  http://creativecommons.org/licenses/by-nc/2.0/legalcode.},
  langid = {english},
  pmid = {22730543},
  file = {/Users/james/Library/Mobile Documents/iCloud~QReader~MarginStudy/Documents/DPhil/Hopewell et al_2012_Effect of editors implementation of CONSORT guidelines on the reporting of.pdf}
}

@article{hopewellImpactWebbasedTool2016,
  title = {Impact of a Web-Based Tool ({{WebCONSORT}}) to Improve the Reporting of Randomised Trials: Results of a Randomised Controlled Trial},
  shorttitle = {Impact of a Web-Based Tool ({{WebCONSORT}}) to Improve the Reporting of Randomised Trials},
  author = {Hopewell, Sally and Boutron, Isabelle and Altman, Douglas G. and Barbour, Ginny and Moher, David and Montori, Victor and Schriger, David and Cook, Jonathan and Gerry, Stephen and Omar, Omar and Dutton, Peter and Roberts, Corran and Frangou, Eleni and Clifton, Lei and Chiocchia, Virginia and Rombach, Ines and Wartolowska, Karolina and Ravaud, Philippe},
  year = {2016},
  month = nov,
  journal = {BMC Medicine},
  volume = {14},
  number = {1},
  pages = {199},
  issn = {1741-7015},
  doi = {10.1186/s12916-016-0736-x},
  urldate = {2020-11-05},
  abstract = {The CONSORT Statement is an evidence-informed guideline for reporting randomised controlled trials. A number of extensions have been developed that specify additional information to report for more complex trials. The aim of this study was to evaluate the impact of using a simple web-based tool (WebCONSORT, which incorporates a number of different CONSORT extensions) on the completeness of reporting of randomised trials published in biomedical publications.},
  keywords = {\_tablet},
  file = {/Users/james/Zotero/storage/CWBSXNFP/Hopewell et al_2016_Impact of a web-based tool (WebCONSORT) to improve the reporting of randomised.pdf;/Users/james/Zotero/storage/ZK3NGUZ5/s12916-016-0736-x.html}
}

@article{howellEffectSQUIREStandards2015,
  title = {The Effect of the {{SQUIRE}} ({{Standards}} of {{QUality Improvement Reporting Excellence}}) Guidelines on Reporting Standards in the Quality Improvement Literature: A before-and-after Study},
  shorttitle = {The Effect of the {{SQUIRE}} ({{Standards}} of {{QUality Improvement Reporting Excellence}}) Guidelines on Reporting Standards in the Quality Improvement Literature},
  author = {Howell, Victoria and Schwartz, Amanda Eva and O'Leary, James Daniel and Donnell, Conor Mc},
  year = {2015},
  month = jun,
  journal = {BMJ Quality \& Safety},
  volume = {24},
  number = {6},
  pages = {400--406},
  publisher = {{BMJ Publishing Group Ltd}},
  issn = {2044-5415, 2044-5423},
  doi = {10.1136/bmjqs-2014-003737},
  urldate = {2020-12-05},
  abstract = {Background The SQUIRE (Standards of QUality Improvement Reporting Excellence) guidelines were developed to improve the reporting of quality improvement (QI) projects. The effect of the guidelines on the completeness of reporting in the QI literature is unknown. Objectives Our primary objective was to determine if the completeness of reporting in the QI literature has been improved[OUP\_CE13] since the introduction of the SQUIRE guidelines. Methods We performed a before-and-after evaluation of QI articles selected from four prominent journals of healthcare quality. Twenty-five articles published in each of two time periods (2006\textendash 2008 and 2010\textendash 2011) were confirmed to be QI projects using a standardised definition and were independently evaluated by two investigators as an interim evaluation of a planned larger sample. Articles were assessed using 50 statements of the SQUIRE guidelines, and the overall change in the completeness of reporting between the two groups was determined. The value of p{$<$}0.05 was considered significant. Results Both groups were similar in characteristics. There was no significant difference in the mean (SD) number of SQUIRE statements completed by authors before and after publication of the SQUIRE guidelines, 20.2 (5.0) versus 20.4 (7.0), p=0.9. The study was stopped early due to the absence of any significant trend in the completeness of reporting. Discussion There was no overall improvement observed in the completeness of reporting of QI projects after the publication of the SQUIRE guidelines, and the study was stopped early. There is potential for improvement in reporting standards, particularly for those guideline items or statements specific to QI projects.},
  chapter = {Research and reporting methodology},
  copyright = {Published by the BMJ Publishing Group Limited. For permission to use (where not already granted under a licence) please go to http://ezproxy-prd.bodleian.ox.ac.uk:4140/group/rights-licensing/permissions},
  langid = {english},
  pmid = {25678444},
  keywords = {Healthcare quality improvement,Quality improvement,Quality improvement methodologies},
  file = {/Users/james/Zotero/storage/IZKCK4T9/Howell et al_2015_The effect of the SQUIRE (Standards of QUality Improvement Reporting.pdf;/Users/james/Zotero/storage/6HI3NYQM/400.html;/Users/james/Zotero/storage/T3D2NEJY/400.html}
}

@misc{ICMJERecommendationsPreparing,
  title = {{{ICMJE}} | {{Recommendations}} | {{Preparing}} a {{Manuscript}} for {{Submission}} to a {{Medical Journal}}},
  urldate = {2021-02-08},
  howpublished = {http://www.icmje.org/recommendations/browse/manuscript-preparation/preparing-for-submission.html\#two},
  file = {/Users/james/Zotero/storage/Y8N6CA4N/preparing-for-submission.html}
}

@misc{IMSEARSEAROHome,
  title = {{{IMSEAR}} at {{SEARO}}: {{Home}}},
  urldate = {2021-03-01},
  howpublished = {https://imsear.searo.who.int/},
  file = {/Users/james/Zotero/storage/38CAAKY3/imsear.searo.who.int.html}
}

@misc{ISO92412102019,
  title = {{{ISO}} 9241-210:2019(En), {{Ergonomics}} of Human-System Interaction \textemdash{} {{Part}} 210: {{Human-centred}} Design for Interactive Systems},
  urldate = {2023-10-06},
  howpublished = {https://www.iso.org/obp/ui/en/\#iso:std:iso:9241:-210:ed-2:v1:en}
}

@misc{ISOInternationalOrganization2023,
  title = {{{ISO}} - {{International Organization}} for {{Standardization}}},
  year = {2023},
  month = sep,
  journal = {ISO},
  urldate = {2023-10-03},
  abstract = {We're ISO, the International Organization for Standardization. We develop and publish International Standards.},
  howpublished = {https://www.iso.org/home.html},
  langid = {english}
}

@misc{jamesrharwoodEQUATORGuidelinesWebsite2023,
  title = {{{EQUATOR Guidelines Website}}},
  author = {{jamesrharwood}},
  year = {2023},
  month = jun,
  urldate = {2023-10-04}
}

@article{jinDoesMedicalLiterature2018,
  title = {Does the Medical Literature Remain Inadequately Described despite Having Reporting Guidelines for 21 Years? \textendash{} {{A}} Systematic Review of Reviews: An Update},
  shorttitle = {Does the Medical Literature Remain Inadequately Described despite Having Reporting Guidelines for 21 Years?},
  author = {Jin, Yanling and Sanger, Nitika and Shams, Ieta and Luo, Candice and Shahid, Hamnah and Li, Guowei and Bhatt, Meha and Zielinski, Laura and Bantoto, Bianca and Wang, Mei and Abbade, Luciana PF and Nwosu, Ikunna and Leenus, Alvin and Mbuagbaw, Lawrence and Maaz, Muhammad and Chang, Yaping and Sun, Guangwen and Levine, Mitchell AH and Adachi, Jonathan D and Thabane, Lehana and Samaan, Zainab},
  year = {2018},
  month = sep,
  journal = {Journal of Multidisciplinary Healthcare},
  volume = {11},
  pages = {495--510},
  issn = {1178-2390},
  doi = {10.2147/JMDH.S155103},
  urldate = {2020-02-14},
  abstract = {Purpose Reporting guidelines (eg, Consolidated Standards of Reporting Trials [CONSORT] statement) are intended to improve reporting standards and enhance the transparency and reproducibility of research findings. Despite accessibility of such guidelines, researchers are not required to adhere to them. Our goal was to determine the current status of reporting quality in the medical literature and examine whether adherence of reporting guidelines has improved since the inception of reporting guidelines. Materials and methods Eight reporting guidelines, such as CONSORT, Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA), STrengthening the Reporting of OBservational studies in Epidemiology (STROBE), Quality of Reporting of Meta-analysis (QUOROM), STAndards for Reporting of Diagnostic accuracy (STARD), Animal Research: Reporting In Vivo Experiments (ARRIVE), Consolidated Health Economic Evaluation Reporting Standards (CHEERS), and Meta-analysis of Observational Studies in Epidemiology (MOOSE) were examined. Our inclusion criteria included reviews published between January 1996 to September 2016 which investigated the adherence to reporting guidelines in the literature that addressed clinical trials, systematic reviews, observational studies, meta-analysis, diagnostic accuracy, economic evaluations, and preclinical animal studies that were in English. All reviews were found on Web of Science, Excerpta Medical Database (EMBASE), MEDLINE, and Cumulative Index to Nursing and Allied Health Literature (CINAHL). Results Among the general searching of 26,819 studies by using the designed searching method, 124 studies were included post screening. We found that 87.9\% of the included studies reported suboptimal adherence to reporting guidelines. Factors associated with poor adherence included non-pharmacological interventions, year of publication, and trials concluding with significant results. Improved adherence was associated with better study designs such as allocation concealment, random sequence, large sample sizes, adequately powered studies, multiple authorships, and being published in journals endorsing guidelines. Conclusion We conclude that the level of adherence to reporting guidelines remains suboptimal. Endorsement of reporting guidelines by journals is important and recommended.},
  pmcid = {PMC6166749},
  pmid = {30310289},
  file = {/Users/james/Zotero/storage/SGNNWIW8/Jin et al. - 2018 - Does the medical literature remain inadequately de.pdf}
}

@article{jonesWhyReportingQuality2019a,
  title = {Why Is Reporting Quality Improvement so Hard? {{A}} Qualitative Study in Perioperative Care},
  shorttitle = {Why Is Reporting Quality Improvement so Hard?},
  author = {Jones, Emma Leanne and {Dixon-Woods}, Mary and Martin, Graham P.},
  year = {2019},
  month = jul,
  journal = {BMJ Open},
  volume = {9},
  number = {7},
  pages = {e030269},
  publisher = {{British Medical Journal Publishing Group}},
  issn = {2044-6055, 2044-6055},
  doi = {10.1136/bmjopen-2019-030269},
  urldate = {2023-08-11},
  abstract = {Objectives Quality improvement (QI) may help to avert or mitigate the risks of suboptimal care, but it is often poorly reported in the healthcare literature. We aimed to identify the influences on reporting QI in the area of perioperative care, with a view to informing improvements in reporting QI across healthcare. Design Qualitative interview study. Setting Healthcare and academic organisations in Australia, Europe and North America. Participants Stakeholders involved in or influencing the publication, writing or consumption of reports of QI studies in perioperative care. Results Forty-two participants from six countries took part in the study. Participants included 15 authors (those who write QI reports), 12 consumers of QI reports (practitioners who apply QI research in practice), 11 journal editors and 4 authors of reporting guidelines. Participants identified three principal challenges in achieving high-quality QI reporting. First, the broad scope of QI reporting\textemdash ranging from small local projects to multisite research across different disciplines\textemdash causes uncertainty about where QI work should be published. Second, context is fundamental to the success of a QI intervention but is difficult to report in ways that support replication and development. Third, reporting is adversely affected by both proximal influences (such as lack of time to write up QI) and more distal, structural influences (such as norms about the format and content of biomedical research reporting), leading to incomplete reporting of QI findings. Conclusions Divergent terminology and understandings of QI, along with existing reporting norms and the challenges of capturing context adequately yet succinctly, make for challenges in reporting QI. We offer suggestions for improvement.},
  chapter = {Surgery},
  copyright = {\textcopyright{} Author(s) (or their employer(s)) 2019. Re-use permitted under CC BY. Published by BMJ.. This is an open access article distributed in accordance with the Creative Commons Attribution 4.0 Unported (CC BY 4.0) license, which permits others to copy, redistribute, remix, transform and build upon this work for any purpose, provided the original work is properly cited, a link to the licence is given, and indication of whether changes were made. See: https://creativecommons.org/licenses/by/4.0/.},
  langid = {english},
  pmid = {31345983},
  keywords = {publishing,qualitative,quality improvement,reporting},
  file = {/Users/james/Library/Mobile Documents/iCloud~QReader~MarginStudy/Documents/DPhil/Jones et al_2019_Why is reporting quality improvement so hard.pdf}
}

@article{karadagoncelKnowledgeAwarenessOptimal2018a,
  title = {Knowledge and Awareness of Optimal Use of Reporting Guidelines in Paediatricians: {{A}} Cross-Sectional Study},
  shorttitle = {Knowledge and Awareness of Optimal Use of Reporting Guidelines in Paediatricians},
  author = {Karada{\u g} {\"O}ncel, Eda and Ba{\c s}arano{\u g}lu, Sevgen Tan{\i}r and Ayka{\c c}, K{\"u}bra and K{\"o}m{\"u}rl{\"u}o{\u g}lu, Ay{\c c}a and Akman, Alk{\i}m {\"O}den and K{\i}ran, Sibel},
  year = {2018},
  month = sep,
  journal = {Turk Pediatri Arsivi},
  volume = {53},
  number = {3},
  pages = {163--168},
  issn = {1306-0015},
  doi = {10.5152/TurkPediatriArs.2018.6167},
  abstract = {Aim: The aim of this study was to investigate pediatricians' ideas and awareness of reporting guidelines of scientific researches, as well as the use of these guidelines in routine practice. Material and Methods: This cross-sectional survey was conducted among pediatricians working at two of the largest pediatric hospitals in Ankara. The pediatricians were asked to complete a 13-item questionnaire in Turkish about reporting guidelines and the Enhancing the Quality and Transparency of Health Research internet network, and their level of knowledge, awareness, and use of these guidelines were investigated. Results: A total of 224 physicians from both centers agreed to participate in the study (56.4\% of the target population). The average age of the participants was 34{$\pm$}9.24 years, their median age was 31 (min-max: 24-63) years, and 71.4\% were female physicians. The participants' median duration in their careers was 6 (min-max: 1-39) years and 63.8\% had participated in a scientific study as a researcher. Forty-five (20\%) of the participants had known about the reporting guidelines before and reported that they had most frequently heard about them via journals, congresses, and seminars. Twenty (26.6\%) of these physicians had used the guidelines. Sixty-five (29\%) of the participants had served as a reviewer for a scientific article, but only three (4.6\%) stated that they had made use of the guidelines while reviewing the articles. Some 83.5\% of the participants reported that they would like to be informed about reporting guidelines. Both centers had similar knowledge levels about the use of the guidelines. Conclusion: The awareness and use of reporting guidelines of scientific researches by pediatricians is insufficient.},
  langid = {english},
  pmcid = {PMC6239066},
  pmid = {30459515},
  keywords = {\_tablet,*awareness,*cross-sectional study,*pediatrician,*practice guideline,adolescent,adult,article,Awareness,career,Cesarean Section,child,Cross-Sectional Studies,female,female physician,human,human experiment,infant,Internet,knowledge,male,medical research,organization,pediatric hospital,pediatricians,questionnaire,reporting guidelines,scientist},
  file = {/Users/james/Zotero/storage/JPRE2NKY/Karada ncel et al_2018_Knowledge and awareness of optimal use of reporting guidelines in paediatricians.pdf}
}

@article{kilicogluMethodologyReportingImproved2023,
  title = {Methodology Reporting Improved over Time in 176,469 Randomized Controlled Trials},
  author = {Kilicoglu, Halil and Jiang, Lan and Hoang, Linh and {Mayo-Wilson}, Evan and Vinkers, Christiaan H. and Otte, Willem M.},
  year = {2023},
  month = aug,
  journal = {Journal of Clinical Epidemiology},
  issn = {0895-4356},
  doi = {10.1016/j.jclinepi.2023.08.004},
  urldate = {2023-08-16},
  abstract = {Objective To describe randomized controlled trial (RCT) methodology reporting over time. Study Design and Setting We used a deep learning-based sentence classification model based on the CONSORT Statement, considered minimum requirements for reporting RCTs. We included 176,469 RCT reports published between 1966 and 2018. We analyzed the reporting trends over 5-year time periods, grouping trials from 1966-1990 in a single stratum. We also explored the effect of journal impact factor (JIF) and medical discipline. Results Population, Intervention, Comparator, Outcome (PICO) items were commonly reported during each period, and reporting increased over time (e.g., Interventions: 79.1\% in 1966-1990 to 87.5\% in 2010-2018). Reporting of some methods information has increased, although there is room for improvement (e.g., Sequence Generation: 10.8\% to 41.8\%). Some items are reported infrequently (e.g., Allocation Concealment: 5.1\% to 19.3\%). The number of items reported and JIF are weakly correlated (Pearson's r(162,702)=0.16, p {$<$} .001). Differences in the proportion of items reported between disciplines are small ({$<$}10\%). Conclusion Our analysis provides large-scale quantitative support for the hypothesis that RCT methodology reporting has improved over time. Extending these models to all CONSORT items could facilitate compliance checking during manuscript authoring and peer review, and support meta-research.},
  keywords = {CONSORT,machine learning,meta-research,randomized controlled trials,reporting guidelines,text mining},
  file = {/Users/james/Library/Mobile Documents/iCloud~QReader~MarginStudy/Documents/DPhil/Kilicoglu et al_2023_Methodology reporting improved over time in 176,469 randomized controlled trials.pdf}
}

@article{kimCharacteristicsQualitativeDescriptive2017,
  title = {Characteristics of {{Qualitative Descriptive Studies}}: {{A Systematic Review}}},
  shorttitle = {Characteristics of {{Qualitative Descriptive Studies}}},
  author = {Kim, Hyejin and Sefcik, Justine S. and Bradway, Christine},
  year = {2017},
  month = feb,
  journal = {Research in nursing \& health},
  volume = {40},
  number = {1},
  pages = {23--42},
  issn = {0160-6891},
  doi = {10.1002/nur.21768},
  urldate = {2022-12-27},
  abstract = {Qualitative description (QD) is a term that is widely used to describe qualitative studies of health care and nursing-related phenomena. However, limited discussions regarding QD are found in the existing literature. In this systematic review, we identified characteristics of methods and findings reported in research articles published in 2014 whose authors identified the work as QD. After searching and screening, data were extracted from the sample of 55 QD articles and examined to characterize research objectives, design justification, theoretical/philosophical frameworks, sampling and sample size, data collection and sources, data analysis, and presentation of findings. In this review, three primary findings were identified. First, despite inconsistencies, most articles included characteristics consistent with limited, available QD definitions and descriptions. Next, flexibility or variability of methods was common and desirable for obtaining rich data and achieving understanding of a phenomenon. Finally, justification for how a QD approach was chosen and why it would be an appropriate fit for a particular study was limited in the sample and, therefore, in need of increased attention. Based on these findings, recommendations include encouragement to researchers to provide as many details as possible regarding the methods of their QD study so that readers can determine whether the methods used were reasonable and effective in producing useful findings.},
  pmcid = {PMC5225027},
  pmid = {27686751},
  keywords = {\_tablet},
  file = {/Users/james/Library/Mobile Documents/iCloud~QReader~MarginStudy/Documents/DPhil/Kim et al_2017_Characteristics of Qualitative Descriptive Studies.pdf}
}

@article{kochExplicitMentioningReporting2016,
  title = {The Explicit Mentioning of Reporting Guidelines in Urogynecology Journals in 2013: {{A}} Bibliometric Study},
  shorttitle = {The Explicit Mentioning of Reporting Guidelines in Urogynecology Journals in 2013},
  author = {Koch, Marianne and Riss, Paul and Umek, Wolfgang and Hanzal, Engelbert},
  year = {2016},
  month = mar,
  journal = {Neurourology and Urodynamics},
  volume = {35},
  number = {3},
  pages = {412--416},
  issn = {1520-6777},
  doi = {10.1002/nau.22726},
  abstract = {AIMS: Poor reporting of research may limit critical appraisal and reproducibility, whereas adherence to reporting guidelines (RG) can guarantee completeness and transparency. We aimed to determine the explicit citing of RGs (CONSORT, PRISMA, STROBE) in urogynecology articles in 2013, the requirements of relevant journals and a potential difference between urogynecology and general gynecology journals. METHODS: All urogynecologic articles published between January and December 2013 in the journals NAU, IUJ, FPMRS, GREEN, AJOG, and BJOG were included. Issues were searched for systematic reviews, RCTs, cohort studies, case-control studies and cross-sectional studies. Each electronic article was searched for the term PRISMA, CONSORT, or STROBE according to the study design. Instructions to Authors of the six journals were screened for requirement of using RGs. RESULTS: We included 296 articles (243 observational studies, 40 RCTs, and 13 systematic reviews). The use of PRISMA guidelines was explicitly declared in 54\% of systematic reviews, CONSORT guidelines were referenced in 25\% of RCTs and STROBE in 1.2\% of observational studies. The use of CONSORT is required by all journals except FPMRS. PRISMA and STROBE are only compulsory in the journals GREEN, AJOG, and BJOG. The overall rate of explicit mentioning of RGs comparing urogynecology and general gynecology journals was 6.7\% versus 7.1\%, respectively. CONCLUSIONS: The explicit mentioning of RGs was on a relatively low level. A slightly higher adherence was recognized among general gynecology journals compared to urogynecology journals. Stronger efforts should be taken to further promote the use of RGs in urogynecology.},
  langid = {english},
  pmid = {25620401},
  keywords = {Bibliometrics,Biomedical Research,CONSORT,Female,Guideline Adherence,Gynecology,Humans,Periodicals as Topic,Practice Guidelines as Topic,PRISMA,reporting guidelines,research design,Research Design,STROBE,urogynecology,Urology}
}

@article{korevaarUpdatingStandardsReporting2016,
  title = {Updating Standards for Reporting Diagnostic Accuracy: The Development of {{STARD}} 2015.},
  author = {Korevaar, Daniel A and Cohen, Jeremie F and Reitsma, Johannes B and Bruns, David E and Gatsonis, Constantine A and Glasziou, Paul P and Irwig, Les and Moher, David and {de Vet}, Henrica C W and Altman, Douglas G and Hooft, Lotty and Bossuyt, Patrick M M},
  year = {2016},
  journal = {Research integrity and peer review},
  volume = {1},
  number = {101676020},
  pages = {7},
  issn = {2058-8615},
  abstract = {Background: Although the number of reporting guidelines has grown rapidly, few have gone through an updating process. The STARD statement (Standards for Reporting Diagnostic Accuracy), published in 2003 to help improve the transparency and completeness of reporting of diagnostic accuracy studies, was recently updated in a systematic way. Here, we describe the steps taken and a justification for the changes made., Results: A 4-member Project Team coordinated the updating process; a 14-member Steering Committee was regularly solicited by the Project Team when making critical decisions. First, a review of the literature was performed to identify topics and items potentially relevant to the STARD updating process. After this, the 85 members of the STARD Group were invited to participate in two online surveys to identify items that needed to be modified, removed from, or added to the STARD checklist. Based on the results of the literature review process, 33 items were presented to the STARD Group in the online survey: 25 original items and 8 new items; 73 STARD Group members (86 \%) completed the first survey, and 79 STARD Group members (93 \%) completed the second survey. Then, an in-person consensus meeting was organized among the members of the Project Team and Steering Committee to develop a consensual draft version of STARD 2015. This version was piloted in three rounds among a total of 32 expert and non-expert users. Piloting mostly led to rewording of items. After this, the update was finalized. The updated STARD 2015 list now consists of 30 items. Compared to the previous version of STARD, three original items were each converted into two new items, four original items were incorporated into other items, and seven new items were added., Conclusions: After a systematic updating process, STARD 2015 provides an updated list of 30 essential items for reporting diagnostic accuracy studies.},
  keywords = {\_tablet,CONSORT,Diagnostic accuracy,EQUATOR,QES-include,Reporting quality,Research waste,Sensitivity and specificity,STARD},
  file = {/Users/james/Zotero/storage/7CI5PDZ5/41073_2016_14_MOESM7_ESM.docx;/Users/james/Zotero/storage/8WSFXE6M/Korevaar et al_2016_Updating standards for reporting diagnostic accuracy.pdf;/Users/james/Zotero/storage/M93MC982/Korevaar et al_2016_Updating standards for reporting diagnostic accuracy.pdf;/Users/james/Zotero/storage/4IKFP4PR/s41073-016-0014-7.html;/Users/james/Zotero/storage/B7FCM6SI/s41073-016-0014-7.html}
}

@book{l.morganFocusGroupsQualitative1997,
  title = {Focus {{Groups}} as {{Qualitative Research}}},
  author = {L.Morgan, David},
  year = {1997},
  publisher = {{SAGE Publications, Inc.}},
  doi = {10.4135/9781412984287},
  urldate = {2023-06-27},
  abstract = {{$<$}p{$>$}The extensively revised edition of the best-selling Focus Groups as Qualitative Research continues to provide an excellent guide for researchers across the d},
  isbn = {978-1-4129-8428-7},
  langid = {english}
}

@article{laffalEricssonAndersSimon1985,
  title = {Ericsson, {{K}}. {{Anders}}, and {{Simon}}, {{Herbert A}}. {{Protocol Analysis}}: {{Verbal Reports}} as {{Data}}. {{MIT Press}}, {{Cambridge}}, {{MA}}, 1984. Viii + 426 Pp. \$27.50},
  shorttitle = {Ericsson, {{K}}. {{Anders}}, and {{Simon}}, {{Herbert A}}. {{Protocol Analysis}}},
  author = {Laffal, Julius},
  year = {1985},
  month = nov,
  journal = {The Journal of Nervous and Mental Disease},
  volume = {173},
  number = {11},
  pages = {703},
  issn = {0022-3018},
  urldate = {2023-11-15},
  abstract = {An abstract is unavailable. This article is available as a PDF only.},
  langid = {american}
}

@inbook{lavrakasAcquiescenceResponseBias2008,
  title = {Acquiescence {{Response Bias}}},
  booktitle = {Encyclopedia of {{Survey Research Methods}}},
  year = {2008},
  publisher = {{Sage Publications, Inc.}},
  address = {{2455 Teller Road,~Thousand Oaks~California~91320~United States of America}},
  doi = {10.4135/9781412963947.n3},
  urldate = {2022-09-26},
  collaborator = {Lavrakas, Paul},
  isbn = {978-1-4129-1808-4 978-1-4129-6394-7}
}

@article{liberatiPRISMAStatementReporting2009,
  title = {The {{PRISMA}} Statement for Reporting Systematic Reviews and Meta-Analyses of Studies That Evaluate Healthcare Interventions: Explanation and Elaboration},
  shorttitle = {The {{PRISMA}} Statement for Reporting Systematic Reviews and Meta-Analyses of Studies That Evaluate Healthcare Interventions},
  author = {Liberati, Alessandro and Altman, Douglas G. and Tetzlaff, Jennifer and Mulrow, Cynthia and G{\o}tzsche, Peter C. and Ioannidis, John P. A. and Clarke, Mike and Devereaux, P. J. and Kleijnen, Jos and Moher, David},
  year = {2009},
  month = jul,
  journal = {BMJ},
  volume = {339},
  pages = {b2700},
  publisher = {{British Medical Journal Publishing Group}},
  issn = {0959-8138, 1468-5833},
  doi = {10.1136/bmj.b2700},
  urldate = {2023-08-16},
  abstract = {Systematic reviews and meta-analyses are essential to summarise evidence relating to efficacy and safety of healthcare interventions accurately and reliably. The clarity and transparency of these reports, however, are not optimal. Poor reporting of systematic reviews diminishes their value to clinicians, policy makers, and other users. Since the development of the QUOROM (quality of reporting of meta-analysis) statement\textemdash a reporting guideline published in 1999\textemdash there have been several conceptual, methodological, and practical advances regarding the conduct and reporting of systematic reviews and meta-analyses. Also, reviews of published systematic reviews have found that key information about these studies is often poorly reported. Realising these issues, an international group that included experienced authors and methodologists developed PRISMA (preferred reporting items for systematic reviews and meta-analyses) as an evolution of the original QUOROM guideline for systematic reviews and meta-analyses of evaluations of health care interventions. The PRISMA statement consists of a 27-item checklist and a four-phase flow diagram. The checklist includes items deemed essential for transparent reporting of a systematic review. In this explanation and elaboration document, we explain the meaning and rationale for each checklist item. For each item, we include an example of good reporting and, where possible, references to relevant empirical studies and methodological literature. The PRISMA statement, this document, and the associated website (www.prisma-statement.org/) should be helpful resources to improve reporting of systematic reviews and meta-analyses.},
  chapter = {Research Methods \&amp; Reporting},
  copyright = {\textcopyright{} Liberati et al 2009. This is an open-access article distributed under the terms of the Creative Commons Attribution Non-commercial License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.},
  langid = {english},
  pmid = {19622552},
  file = {/Users/james/Library/Mobile Documents/iCloud~QReader~MarginStudy/Documents/DPhil/Liberati et al_2009_The PRISMA statement for reporting systematic reviews and meta-analyses of.pdf}
}

@article{liberatiUnfinishedTripUncertainties2004,
  title = {An Unfinished Trip through Uncertainties},
  author = {Liberati, Alessandro},
  year = {2004},
  month = feb,
  journal = {BMJ : British Medical Journal},
  volume = {328},
  number = {7438},
  pages = {531},
  issn = {0959-8138},
  urldate = {2023-10-24},
  pmcid = {PMC351869},
  pmid = {null},
  file = {/Users/james/Library/Mobile Documents/iCloud~QReader~MarginStudy/Documents/DPhil/Liberati_2004_An unfinished trip through uncertainties.pdf}
}

@misc{LILACS,
  title = {| {{LILACS}}},
  urldate = {2021-02-19},
  langid = {american},
  file = {/Users/james/Zotero/storage/BXBXJGBU/en.html}
}

@book{lincolnNaturalisticInquiry1985,
  title = {Naturalistic {{Inquiry}}},
  author = {Lincoln, Yvonna S. and Guba, Egon G.},
  year = {1985},
  month = apr,
  publisher = {{SAGE}},
  abstract = {"Showing how science is limited by its dominant mode of investigation, Lincoln and Guba propose an alternative paradigm--a "naturalistic" rather than "rationalistic" method of inquiry--in which the investigator avoids manipulating research outcomes. A "paradigm shift" is under way in many fields, they contend, and go on to describe the different assumptions of the two approaches regarding the nature of reality, subject-object interaction, the possibility of generalization, the concept of causality, and the role of values. The authors also offer guidance for research in the field (where, they say, naturalistic inquiry always takes place). Useful tips are given, for example, on "designing" a study as it unfolds, establishing "trustworthiness," and writing a case report. This book helps researchers "both to understand and to do naturalistic inquiry." Of particular interest to educational researchers, it is valuable for all social scientists involved with questions of qualitative and quantitative methodology."--Publisher's description.},
  googlebooks = {2oA9aWlNeooC},
  isbn = {978-0-8039-2431-4},
  langid = {english},
  keywords = {Social Science / Research}
}

@book{m.givenSAGEEncyclopediaQualitative2008,
  title = {The {{SAGE Encyclopedia}} of {{Qualitative Research Methods}}},
  author = {M.Given, Lisa},
  year = {2008},
  publisher = {{SAGE Publications, Inc.}},
  doi = {10.4135/9781412963909},
  urldate = {2023-07-03},
  abstract = {{$<$}p{$>$}Qualitative research is designed to explore the human elements of a given topic, while specific qualitative methods examine how individuals see and experienc},
  isbn = {978-1-4129-6390-9},
  langid = {english},
  file = {/Users/james/Library/Mobile Documents/iCloud~QReader~MarginStudy/Documents/DPhil/M.Given_2008_The SAGE Encyclopedia of Qualitative Research Methods.pdf}
}

@article{macleodBiomedicalResearchIncreasing2014,
  title = {Biomedical Research: Increasing Value, Reducing Waste},
  shorttitle = {Biomedical Research},
  author = {Macleod, Malcolm R. and Michie, Susan and Roberts, Ian and Dirnagl, Ulrich and Chalmers, Iain and Ioannidis, John P. A. and Salman, Rustam Al-Shahi and Chan, An-Wen and Glasziou, Paul},
  year = {2014},
  month = jan,
  journal = {The Lancet},
  volume = {383},
  number = {9912},
  pages = {101--104},
  publisher = {{Elsevier}},
  issn = {0140-6736, 1474-547X},
  doi = {10.1016/S0140-6736(13)62329-6},
  urldate = {2023-08-08},
  langid = {english},
  pmid = {24411643}
}

@article{macleodMDARMaterialsDesign2021,
  title = {The {{MDAR}} ({{Materials Design Analysis Reporting}}) {{Framework}} for Transparent Reporting in the Life Sciences},
  author = {Macleod, Malcolm and Collings, Andrew M. and Graf, Chris and Kiermer, Veronique and Mellor, David and Swaminathan, Sowmya and Sweet, Deborah and Vinson, Valda},
  year = {2021},
  month = apr,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {118},
  number = {17},
  pages = {e2103238118},
  publisher = {{Proceedings of the National Academy of Sciences}},
  doi = {10.1073/pnas.2103238118},
  keywords = {\_tablet},
  file = {/Users/james/Zotero/storage/BPM5C8HK/Macleod et al_2021_The MDAR (Materials Design Analysis Reporting) Framework for transparent.pdf;/Users/james/Zotero/storage/GUE9S2A8/MDAR author and editor survey responses.pptx;/Users/james/Zotero/storage/RXE3YE2Z/Macleod et al_2021_The MDAR (Materials Design Analysis Reporting) Framework for transparent.pdf}
}

@article{malickiSystematicReviewMetaanalyses2021,
  title = {Systematic Review and Meta-Analyses of Studies Analysing Instructions to Authors from 1987 to 2017},
  author = {Mali{\v c}ki, Mario and Jeron{\v c}i{\'c}, Ana and Aalbersberg, IJsbrand Jan and Bouter, Lex and {ter Riet}, Gerben},
  year = {2021},
  month = oct,
  journal = {Nature Communications},
  volume = {12},
  number = {1},
  pages = {5840},
  publisher = {{Nature Publishing Group}},
  issn = {2041-1723},
  doi = {10.1038/s41467-021-26027-y},
  urldate = {2021-12-01},
  abstract = {To gain insight into changes of scholarly journals' recommendations, we conducted a systematic review of studies that analysed journals' Instructions to Authors (ItAs). We summarised results of 153 studies, and meta-analysed how often ItAs addressed: 1) authorship, 2) conflicts of interest, 3) data sharing, 4) ethics approval, 5) funding disclosure, and 6) International Committee of Medical Journal Editors' Uniform Requirements for Manuscripts. For each topic we found large between-study heterogeneity. Here, we show six factors that explained most of that heterogeneity: 1) time (addressing of topics generally increased over time), 2) country (large differences found between countries), 3) database indexation (large differences found between databases), 4) impact factor (topics were more often addressed in highest than in lowest impact factor journals), 5) discipline (topics were more often addressed in Health Sciences than in other disciplines), and 6) sub-discipline (topics were more often addressed in general than in sub-disciplinary journals).},
  copyright = {2021 The Author(s)},
  langid = {english},
  keywords = {Authorship,Ethics,Funding,Journalism,Publishing},
  annotation = {Bandiera\_abtest: a Cc\_license\_type: cc\_by Cg\_type: Nature Research Journals Primary\_atype: Research Subject\_term: Authorship;Ethics;Funding;Journalism;Publishing Subject\_term\_id: authorship;ethics;funding;journalism;publishing},
  file = {/Users/james/Zotero/storage/88J9B5RE/Maliki et al. - 2021 - Systematic review and meta-analyses of studies ana.pdf;/Users/james/Zotero/storage/VXRE5YAV/Maliki et al_2021_Systematic review and meta-analyses of studies analysing instructions to.pdf;/Users/james/Zotero/storage/4KQ6YQUR/s41467-021-26027-y.html}
}

@article{malterudQualitativeResearchStandards2001,
  title = {Qualitative Research: Standards, Challenges, and Guidelines},
  shorttitle = {Qualitative Research},
  author = {Malterud, K.},
  year = {2001},
  month = aug,
  journal = {Lancet (London, England)},
  volume = {358},
  number = {9280},
  pages = {483--488},
  issn = {0140-6736},
  doi = {10.1016/S0140-6736(01)05627-6},
  abstract = {Qualitative research methods could help us to improve our understanding of medicine. Rather than thinking of qualitative and quantitative strategies as incompatible, they should be seen as complementary. Although procedures for textual interpretation differ from those of statistical analysis, because of the different type of data used and questions to be answered, the underlying principles are much the same. In this article I propose relevance, validity, and reflexivity as overall standards for qualitative inquiry. I will discuss the specific challenges in relation to reflexivity, transferability, and shared assumptions of interpretation, which are met by medical researchers who do this type of research, and I will propose guidelines for qualitative inquiry.},
  langid = {english},
  pmid = {11513933},
  keywords = {Guidelines as Topic,Humans,Observation,Research,Research Design}
}

@article{malterudSampleSizeQualitative2016,
  title = {Sample {{Size}} in {{Qualitative Interview Studies}}: {{Guided}} by {{Information Power}}},
  shorttitle = {Sample {{Size}} in {{Qualitative Interview Studies}}},
  author = {Malterud, Kirsti and Siersma, Volkert Dirk and Guassora, Ann Dorrit},
  year = {2016},
  month = nov,
  journal = {Qualitative Health Research},
  volume = {26},
  number = {13},
  pages = {1753--1760},
  publisher = {{SAGE Publications Inc}},
  issn = {1049-7323},
  doi = {10.1177/1049732315617444},
  urldate = {2022-10-12},
  abstract = {Sample sizes must be ascertained in qualitative studies like in quantitative studies but not by the same means. The prevailing concept for sample size in qualitative studies is ?saturation.? Saturation is closely tied to a specific methodology, and the term is inconsistently applied. We propose the concept ?information power? to guide adequate sample size for qualitative studies. Information power indicates that the more information the sample holds, relevant for the actual study, the lower amount of participants is needed. We suggest that the size of a sample with sufficient information power depends on (a) the aim of the study, (b) sample specificity, (c) use of established theory, (d) quality of dialogue, and (e) analysis strategy. We present a model where these elements of information and their relevant dimensions are related to information power. Application of this model in the planning and during data collection of a qualitative study is discussed.},
  langid = {english},
  file = {/Users/james/Library/Mobile Documents/iCloud~QReader~MarginStudy/Documents/DPhil/Malterud et al_2016_Sample Size in Qualitative Interview Studies.pdf}
}

@article{maSurveyBasicMedical2017,
  title = {Survey of Basic Medical Researchers on the Awareness of Animal Experimental Designs and Reporting Standards in {{China}}},
  author = {Ma, Bin and Xu, Jia-ke and Wu, Wen-jing and Liu, Hong-yan and Kou, Cheng-kun and Liu, Na and Zhao, Lulu},
  year = {2017},
  month = apr,
  journal = {PLoS ONE},
  volume = {12},
  number = {4},
  pages = {e0174530},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0174530},
  urldate = {2021-12-29},
  abstract = {Objective To investigate the awareness and use of the Systematic Review Center for Laboratory Animal Experimentation's (SYRCLE) risk-of-bias tool, the Animal Research: Reporting of In Vivo Experiments (ARRIVE) reporting guidelines, and Gold Standard Publication Checklist (GSPC) in China in basic medical researchers of animal experimental studies. Methods A national questionnaire-based survey targeting basic medical researchers was carried in China to investigate the basic information and awareness of SYRCLE's risk of bias tool, ARRIVE guidelines, GSPC, and animal experimental bias risk control factors. The EpiData3.1 software was used for data entry, and Microsoft Excel 2013 was used for statistical analysis in this study. The number of cases (n) and percentage (\%) of classified information were statistically described, and the comparison between groups (i.e., current students vs. research staff) was performed using chi-square test. Results A total of 298 questionnaires were distributed, and 272 responses were received, which included 266 valid questionnaires (from 118 current students and 148 research staff). Among the 266 survey participants, only 15.8\% was aware of the SYRCLE's risk of bias tool, with significant difference between the two groups (P = 0.003), and the awareness rates of ARRIVE guidelines and GSPC were only 9.4\% and 9.0\%, respectively; 58.6\% survey participants believed that the reports of animal experimental studies in Chinese literature were inadequate, with significant difference between the two groups (P = 0.004). In addition, only approximately 1/3 of the survey participants had read systematic reviews and meta-analysis reports of animal experimental studies; only 16/266 (6.0\%) had carried out/participated in and 11/266 (4.1\%) had published systematic reviews/meta-analysis of animal experimental studies. Conclusions The awareness and use rates of SYRCLE's risk-of-bias tool, the ARRIVE guidelines, and the GSPC were low among Chinese basic medical researchers. Therefore, specific measures are necessary to promote and popularize these standards and specifications and to introduce these standards into guidelines of Chinese domestic journals as soon as possible to raise awareness and increase use rates of researchers and journal editors, thereby improving the quality of animal experimental methods and reports.},
  pmcid = {PMC5381903},
  pmid = {28380050},
  keywords = {\_tablet,*Animal Experimentation/st [Standards],*awareness,*China,*experimental design,*Publications/st [Standards],*Research Personnel/sn [Statistics \textbackslash\& Numerical Data],*Research Personnel/sn [Statistics \& Numerical Data],*scientist,Animal Shells,Animals,Bias,checklist,chi square test,China,controlled study,doctor patient relation,editor,experimental study,gold standard,human,Humans,Medical journals,Medical risk factors,Medicine and health sciences,meta analysis,Metaanalysis,nonhuman,practice guideline,publication,questionnaire,Research Design,Research Personnel/px [Psychology],Risk Factors,software,student,Survey research,Surveys,systematic review,Systematic reviews},
  file = {/Users/james/Zotero/storage/DH45CEBH/Ma et al_2017_Survey of basic medical researchers on the awareness of animal experimental.pdf;/Users/james/Zotero/storage/MWND7YIQ/Ma et al_2017_Survey of basic medical researchers on the awareness of animal experimental.pdf;/Users/james/Zotero/storage/KVMY7Y8Z/article.html}
}

@article{mccallDevelopmentMobileApp2021,
  title = {Development of a {{Mobile App}} to {{Support Self-management}} of {{Anxiety}} and {{Depression}} in {{African American Women}}: {{Usability Study}}},
  shorttitle = {Development of a {{Mobile App}} to {{Support Self-management}} of {{Anxiety}} and {{Depression}} in {{African American Women}}},
  author = {McCall, Terika and Ali, Muhammad Osama and Yu, Fei and Fontelo, Paul and Khairat, Saif},
  year = {2021},
  month = aug,
  journal = {JMIR formative research},
  volume = {5},
  number = {8},
  pages = {e24393},
  issn = {2561-326X},
  doi = {10.2196/24393},
  abstract = {BACKGROUND: Anxiety and depressive disorders are the most common mental health conditions among African American women. Despite the need for mental health care, African American women significantly underuse mental health services. Previous mobile health studies revealed significant improvements in anxiety or depressive symptoms after intervention. The use of mobile apps offers the potential to eliminate or mitigate barriers for African American women who are seeking access to mental health services and resources. OBJECTIVE: This study aims to evaluate the usability of the prototype of an app that is designed for supporting the self-management of anxiety and depression in African American women. METHODS: Individual usability testing sessions were conducted with 15 participants in Chapel Hill, North Carolina. Cognitive walkthrough and think-aloud protocols were used to evaluate the user interface. Eye-tracking glasses were used to record participants' visual focus and gaze path as they performed the tasks. The Questionnaire for User Interface Satisfaction was administered after each session to assess the participants' acceptance of the app. RESULTS: Participants rated the usability of the prototype positively and provided recommendations for improvement. The average of the mean scores for usability assessments (ie, overall reactions to the software, screen, terminology and app information, learning, and app capabilities) ranged from 7.2 to 8.8 on a scale of 0-9 (low to high rating) for user tasks. Most participants were able to complete each task with limited or no assistance. Design recommendations included improving the user interface by adding graphics and color, adding a tutorial for first-time users, curating a list of Black women therapists within the app, adding details about tracking anxiety and depression in the checkup graphs, informing users that they can use the talk-to-text feature for journal entries to reduce burden, relabeling the mental health information icon, monitoring for crisis support, and improving clickthrough sequencing. CONCLUSIONS: This study provides a better understanding of user experience with an app tailored to support the management of anxiety and depression for African American women, which is an underserved group. As African American women have high rates of smartphone ownership, there is a great opportunity to use mobile technology to provide access to needed mental health services and resources. Future work will include incorporating feedback from usability testing and focus group sessions to refine and develop the app further. The updated app will undergo iterative usability testing before launching the pilot study to evaluate the feasibility and acceptability of the prototype.},
  langid = {english},
  pmcid = {PMC8408754},
  pmid = {34133313},
  keywords = {African Americans,anxiety,depression,digital health,mental health,mHealth,mobile applications,mobile phone,telemedicine,user-centered design,women},
  file = {/Users/james/Library/Mobile Documents/iCloud~QReader~MarginStudy/Documents/DPhil/McCall et al_2021_Development of a Mobile App to Support Self-management of Anxiety and.pdf}
}

@article{mcdonoughj.FamiliarityNonindustryAuthors2011,
  title = {Familiarity of Non-Industry Authors with Good Publication Practice and Clinical Data Reporting Guidelines},
  author = {{McDonough J.} and {O'Dunne A.} and Choi B. and {Margerum B.} and {Sutton D.}},
  year = {2011},
  journal = {Current Medical Research and Opinion},
  series = {7th {{Annual Meeting}} of the {{International Society}} for {{Medical Publication Professionals}}, {{ISMPP}}. {{Arlington}}, {{VA United States}}.},
  volume = {27},
  pages = {S9},
  issn = {0300-7995},
  abstract = {Objective: This study evaluated the familiarity of non-industry authors with guidelines for good publication practice and clinical data reporting. Research design and methods: Non-industry authors for \{\textbackslash textgreater\}=1 publication in the last 2 years involving a single communications agency completed a nine-question online survey that evaluated experiences with professional medical writers and familiarity with guidelines (not, a little, somewhat, or very familiar). Result(s): Of 287 authors contacted, 8\textbackslash\% (23/287) responded to \{\textbackslash textgreater\}=1 question. Among respondents, 65\textbackslash\% and 30\textbackslash\% had received editorial assistance on \{\textbackslash textless\}=2 and 3-5 publications, respectively; 48\textbackslash\% received significant or full-service (including outline, drafts, copy edit) assistance. More than 50\textbackslash\% of respondents were somewhat or very familiar with guidelines of the International Committee of Medical Journal Editors and Good Publication Practice (GPP), while \{\textbackslash textgreater\}50\textbackslash\% of respondents were not or a little familiar with guidelines of GPP2, Consolidated Standards of Reporting Trials, European Medical Writers Association, and American Medical Writers Association. Many respondents (27-68\textbackslash\%) were not familiar with \{\textbackslash textgreater\}=1 of the guidelines. Only 23\textbackslash\% of respondents indicated that their institution has a specific policy regarding use of professional medical writers. A majority (77\textbackslash\%) agreed that there is a role for professional medical writers in medical publications. High levels of satisfaction with professional medical writers were reported; 83\textbackslash\% were very or extremely satisfied with overall writing quality and 96\textbackslash\% were very or extremely satisfied with grammar and writing style. Conclusion(s): A significant proportion of non-industry authors were not familiar with key guidelines governing good publication practice and clinical data reporting.},
  langid = {english},
  keywords = {\_tablet,*clinical study,*human,*industry,*information processing,*society,editor,grammar,interpersonal communication,medical literature,methodology,policy,QES-exclude,Research Design,satisfaction,writing},
  file = {/Users/james/Zotero/storage/3RNGGXPU/McDonough et al_Familiarity of Non-industry Authors With Good Publication Practice and Clinical.pdf;/Users/james/Zotero/storage/EH9LYLMS/McDonough J. et al_2011_Familiarity of non-industry authors with good publication practice and clinical.pdf}
}

@misc{MedRxivOrgPreprint,
  title = {{{medRxiv}}.Org - the Preprint Server for {{Health Sciences}}},
  urldate = {2023-10-17},
  howpublished = {https://www.medrxiv.org/}
}

@article{michieBehaviorChangeTechnique2013,
  title = {The Behavior Change Technique Taxonomy (v1) of 93 Hierarchically Clustered Techniques: Building an International Consensus for the Reporting of Behavior Change Interventions},
  shorttitle = {The Behavior Change Technique Taxonomy (v1) of 93 Hierarchically Clustered Techniques},
  author = {Michie, Susan and Richardson, Michelle and Johnston, Marie and Abraham, Charles and Francis, Jill and Hardeman, Wendy and Eccles, Martin P. and Cane, James and Wood, Caroline E.},
  year = {2013},
  month = aug,
  journal = {Annals of Behavioral Medicine: A Publication of the Society of Behavioral Medicine},
  volume = {46},
  number = {1},
  pages = {81--95},
  issn = {1532-4796},
  doi = {10.1007/s12160-013-9486-6},
  abstract = {BACKGROUND: CONSORT guidelines call for precise reporting of behavior change interventions: we need rigorous methods of characterizing active content of interventions with precision and specificity. OBJECTIVES: The objective of this study is to develop an extensive, consensually agreed hierarchically structured taxonomy of techniques [behavior change techniques (BCTs)] used in behavior change interventions. METHODS: In a Delphi-type exercise, 14 experts rated labels and definitions of 124 BCTs from six published classification systems. Another 18 experts grouped BCTs according to similarity of active ingredients in an open-sort task. Inter-rater agreement amongst six researchers coding 85 intervention descriptions by BCTs was assessed. RESULTS: This resulted in 93 BCTs clustered into 16 groups. Of the 26 BCTs occurring at least five times, 23 had adjusted kappas of 0.60 or above. CONCLUSIONS: "BCT taxonomy v1," an extensive taxonomy of 93 consensually agreed, distinct BCTs, offers a step change as a method for specifying interventions, but we anticipate further development and evaluation based on international, interdisciplinary consensus.},
  langid = {english},
  pmid = {23512568},
  keywords = {Behavior Therapy,Cluster Analysis,Consensus,Humans,Treatment Outcome},
  file = {/Users/james/Library/Mobile Documents/iCloud~QReader~MarginStudy/Documents/DPhil/Michie et al_2013_The behavior change technique taxonomy (v1) of 93 hierarchically clustered.pdf}
}

@article{michieBehaviourChangeWheel2011,
  title = {The Behaviour Change Wheel: {{A}} New Method for Characterising and Designing Behaviour Change Interventions},
  shorttitle = {The Behaviour Change Wheel},
  author = {Michie, Susan and {van Stralen}, Maartje M. and West, Robert},
  year = {2011},
  month = apr,
  journal = {Implementation Science},
  volume = {6},
  number = {1},
  pages = {42},
  issn = {1748-5908},
  doi = {10.1186/1748-5908-6-42},
  urldate = {2021-10-14},
  abstract = {Improving the design and implementation of evidence-based practice depends on successful behaviour change interventions. This requires an appropriate method for characterising interventions and linking them to an analysis of the targeted behaviour. There exists a plethora of frameworks of behaviour change interventions, but it is not clear how well they serve this purpose. This paper evaluates these frameworks, and develops and evaluates a new framework aimed at overcoming their limitations.},
  keywords = {Behaviour Change,Behaviour Change Intervention,Behaviour Change Technique,Intervention Function,Target Behaviour},
  file = {/Users/james/Zotero/storage/6I9TL5NX/Michie et al_2011_The behaviour change wheel.pdf;/Users/james/Zotero/storage/3BSPFRJJ/1748-5908-6-42.html}
}

@book{michieBehaviourChangeWheel2014,
  title = {The {{Behaviour Change Wheel}}: {{A Guide}} to {{Designing Interventions}}},
  author = {Michie, Susan and Atkins, Lou and West, Robert},
  year = {2014},
  publisher = {{Silverback Publishing}},
  address = {{London}}
}

@article{michieMakingPsychologicalTheory2005,
  title = {Making Psychological Theory Useful for Implementing Evidence Based Practice: A Consensus Approach},
  shorttitle = {Making Psychological Theory Useful for Implementing Evidence Based Practice},
  author = {Michie, S. and Johnston, M. and Abraham, C. and Lawton, R. and Parker, D. and Walker, A.},
  year = {2005},
  month = feb,
  journal = {BMJ Quality \& Safety},
  volume = {14},
  number = {1},
  pages = {26--33},
  publisher = {{BMJ Publishing Group Ltd}},
  issn = {2044-5415, 2044-5423},
  doi = {10.1136/qshc.2004.011155},
  urldate = {2023-01-09},
  abstract = {Background: Evidence-based guidelines are often not implemented effectively with the result that best health outcomes are not achieved. This may be due to a lack of theoretical understanding of the processes involved in changing the behaviour of healthcare professionals. This paper reports the development of a consensus on a theoretical framework that could be used in implementation research. The objectives were to identify an agreed set of key theoretical constructs for use in (1) studying the implementation of evidence based practice and (2) developing strategies for effective implementation, and to communicate these constructs to an interdisciplinary audience. Methods: Six phases of work were conducted to develop a consensus: (1) identifying theoretical constructs; (2) simplifying into construct domains; (3) evaluating the importance of the construct domains; (4) interdisciplinary evaluation; (5) validating the domain list; and (6) piloting interview questions. The contributors were a ``psychological theory'' group (n = 18), a ``health services research'' group (n = 13), and a ``health psychology'' group (n = 30). Results: Twelve domains were identified to explain behaviour change: (1) knowledge, (2) skills, (3) social/professional role and identity, (4) beliefs about capabilities, (5) beliefs about consequences, (6) motivation and goals, (7) memory, attention and decision processes, (8) environmental context and resources, (9) social influences, (10) emotion regulation, (11) behavioural regulation, and (12) nature of the behaviour. Conclusions: A set of behaviour change domains agreed by a consensus of experts is available for use in implementation research. Applications of this domain list will enhance understanding of the behaviour change processes inherent in implementation of evidence-based practice and will also test the validity of these proposed domains.},
  chapter = {Original Article},
  copyright = {Copyright 2005 Quality and Safety in Health Care},
  langid = {english},
  pmid = {15692000},
  file = {/Users/james/Library/Mobile Documents/iCloud~QReader~MarginStudy/Documents/DPhil/Michie et al_2005_Making psychological theory useful for implementing evidence based practice.pdf}
}

@article{millsAdvancingComplexityScience2019,
  title = {Advancing Complexity Science in Healthcare Research: The Logic of Logic Models},
  shorttitle = {Advancing Complexity Science in Healthcare Research},
  author = {Mills, Thomas and Lawton, Rebecca and Sheard, Laura},
  year = {2019},
  month = mar,
  journal = {BMC Medical Research Methodology},
  volume = {19},
  number = {1},
  pages = {55},
  issn = {1471-2288},
  doi = {10.1186/s12874-019-0701-4},
  urldate = {2024-01-01},
  abstract = {Logic models are commonly used in evaluations to represent the causal processes through which interventions produce outcomes, yet significant debate is currently taking place over whether they can describe complex interventions which adapt to context. This paper assesses the logic models used in healthcare research from a complexity perspective. A typology of existing logic models is proposed, as well as a formal methodology for deriving more flexible and dynamic logic models.},
  keywords = {Complex interventions,Complexity,Complexity science,Context,Facilitation,Implementation models,Logic models,Program theory},
  file = {/Users/james/Library/Mobile Documents/iCloud~QReader~MarginStudy/Documents/DPhil/Mills et al_2019_Advancing complexity science in healthcare research.pdf}
}

@article{moherDescribingReportingGuidelines2011a,
  title = {Describing Reporting Guidelines for Health Research: A Systematic Review},
  shorttitle = {Describing Reporting Guidelines for Health Research},
  author = {Moher, David and Weeks, Laura and Ocampo, Mary and Seely, Dugald and Sampson, Margaret and Altman, Douglas G. and Schulz, Kenneth F. and Miller, Donald and Simera, Iveta and Grimshaw, Jeremy and Hoey, John},
  year = {2011},
  month = jul,
  journal = {Journal of Clinical Epidemiology},
  volume = {64},
  number = {7},
  pages = {718--742},
  issn = {0895-4356},
  doi = {10.1016/j.jclinepi.2010.09.013},
  urldate = {2021-12-29},
  abstract = {Objective To describe the process of development, content, and methods of implementation of reporting guidelines for health research. Study Design and Setting A systematic review of publications describing health research reporting guidelines developed using consensus. Results Eighty-one reporting guidelines for health research were included in the review. The largest number of guidelines do not focus on a specific study type (n=35; 43\%), whereas those that do primarily refer to reporting of randomized controlled trials (n=16; 35\%). Most of the guidelines (n=76; 94\%) include a checklist of recommended reporting items, with a median of 21 checklist items (range: 5\textendash 64 items). Forty-seven (58\%) reporting guidelines were classified as new guidance. Explanation documents were developed for 11 (14\%) reporting guidelines. Reporting-guideline developers provided little information about the guideline development process. Developers of 50 (62\%) reporting guidelines encouraged endorsement, most commonly by including guidelines in journal instructions to authors (n=18; 36\%). Conclusions Reporting-guideline developers need to endeavor to maximize the quality of their product. Recently developed guidance is likely to facilitate more robust guideline development. Journal editors can be more confident in endorsing reporting guidelines that have followed these approaches.},
  langid = {english},
  keywords = {*Biomedical Research/st [Standards],*Guidelines as Topic/st [Standards],*medical research,*practice guideline,*Publishing/st [Standards],*Research Design/st [Standards],author,Biomedical Research/mt [Methods],checklist,Consensus,consensus development,editor,Health Care,health care planning,human,Humans,information,medical documentation,medical literature,methodology,Peer Review,priority journal,publication,Quality Assurance,randomized controlled trial (topic),Reporting guidelines,Research,Research methodology,review,scientific literature,systematic review,Systematic review},
  file = {/Users/james/Zotero/storage/V64UXIU5/Moher et al_2011_Describing reporting guidelines for health research.pdf}
}

@article{moherGuidanceDevelopersHealth2010,
  title = {Guidance for Developers of Health Research Reporting Guidelines},
  author = {Moher, David and Schulz, Kenneth F. and Simera, Iveta and Altman, Douglas G.},
  year = {2010},
  month = feb,
  journal = {PLOS Medicine},
  volume = {7},
  number = {2},
  pages = {e1000217},
  publisher = {{Public Library of Science}},
  issn = {1549-1676},
  doi = {10.1371/journal.pmed.1000217},
  urldate = {2021-04-22},
  abstract = {David Moher and colleagues from the EQUATOR network offer guidance and recommended steps for developing health research reporting guidelines.},
  langid = {english},
  keywords = {\_tablet,Database searching,Medical journals,Peer review,Randomized controlled trials,Research design,Research reporting guidelines,Scientific publishing,Systematic reviews},
  file = {/Users/james/Zotero/storage/7HFGXCC9/Moher et al_2010_Guidance for Developers of Health Research Reporting Guidelines.pdf;/Users/james/Zotero/storage/BN9FQXX7/Moher et al_2010_Guidance for developers of health research reporting guidelines.pdf;/Users/james/Zotero/storage/RCRVDMJT/Moher et al_2010_Guidance for Developers of Health Research Reporting Guidelines.pdf;/Users/james/Zotero/storage/RGURDIRS/article.html;/Users/james/Zotero/storage/XJ6R4TZR/article.html}
}

@article{mollerUsabilityTestingUser2013,
  title = {Usability {{Testing}} of {{User Manuals}}},
  author = {M{\o}ller, Margrethe H.},
  year = {2013},
  month = jan,
  journal = {Communication \& Language at Work},
  volume = {2},
  number = {2},
  pages = {51--59},
  issn = {2245-5744},
  doi = {10.7146/claw.v1i2.7892},
  urldate = {2020-11-10},
  abstract = {Many guidelines and several standards exist for the development of good user manuals. But even though technical writers comply with all guidelines, problems will typically arise when users apply the manual in practice. Therefore, it is useful to have real users test the manual before it is published. This article discusses user tests in the form of think-aloud tests, with examples from the research project ''User Manuals for older adults''.},
  copyright = {Copyright (c) 2015 Communication \& Language at Work},
  langid = {english},
  keywords = {\_tablet,protocol,testing,usability,user manuals},
  file = {/Users/james/Zotero/storage/SB84NEV4/Mller_2013_Usability Testing of User Manuals.pdf;/Users/james/Zotero/storage/8CTJ9RSI/7892.html}
}

@article{mookMotivationOrganizationAction,
  title = {Motivation : The Organization of Action},
  shorttitle = {Motivation},
  author = {Mook, Douglas G.},
  journal = {(No Title)},
  urldate = {2023-07-14},
  langid = {english}
}

@article{nedovicEvaluationEndorsementSTrengthening2016,
  title = {Evaluation of the {{Endorsement}} of the {{STrengthening}} the {{REporting}} of {{Genetic Association Studies}} ({{STREGA}}) {{Statement}} on the {{Reporting Quality}} of {{Published Genetic Association Studies}}},
  author = {Nedovic, Darko and Panic, Nikola and Pastorino, Roberta and Ricciardi, Walter and Boccia, Stefania},
  year = {2016},
  month = aug,
  journal = {Journal of Epidemiology},
  volume = {26},
  number = {8},
  pages = {399--404},
  issn = {1349-9092},
  doi = {10.2188/jea.JE20150173},
  abstract = {The STrengthening the REporting of Genetic Association studies (STREGA) statement was based on the STrengthening the REporting of OBservational studies in Epidemiology (STROBE) statement, and it was published in 2009 in order to improve the reporting of genetic association (GA) studies. Our aim was to evaluate the impact of STREGA endorsement on the quality of reporting of GA studies published in journals in the field of genetics and heredity (GH). Quality of reporting was evaluated by assessing the adherence of papers to the STREGA checklist. After identifying the GH journals that endorsed STREGA in their instructions for authors, we randomly appraised papers published in 2013 from journals endorsing STREGA that published GA studies (Group A); in GH journals that never endorsed STREGA (Group B); in GH journals endorsing STREGA, but in the year preceding its endorsement (Group C); and in the same time period as Group C from GH journals that never endorsed STREGA (Group D). The STREGA statement was referenced in 29 (18.1\%) of 160 GH journals, of which 18 (62.1\%) journals published GA studies. Among the 18 journals endorsing STREGA, we found a significant increase in the overall adherence to the STREGA checklist over time (A vs C; P {$<$} 0.0001). Adherence to the STREGA checklist was significantly higher in journals endorsing STREGA compared to those that did not endorse the statement (A vs B; P = 0.04). No significant improvement was detected in the adherence to STREGA items in journals not endorsing STREGA over time (B vs D; P {$>$} 0.05). The endorsement of STREGA resulted in an increase in quality of reporting of GA studies over time, while no similar improvement was reported for journals that never endorsed STREGA.},
  langid = {english},
  pmcid = {PMC4967660},
  pmid = {27349199},
  keywords = {Genetic Association Studies,Humans,Periodicals as Topic,Publishing,Research Report},
  file = {/Users/james/Library/Mobile Documents/iCloud~QReader~MarginStudy/Documents/DPhil/Nedovic et al_2016_Evaluation of the Endorsement of the STrengthening the REporting of Genetic.pdf}
}

@misc{NHSWebsite2018,
  title = {The {{NHS}} Website},
  year = {16 Aug 2018, 12:27 a.m.},
  journal = {nhs.uk},
  urldate = {2023-10-03},
  abstract = {Find information and advice on health conditions, symptoms, healthy living, medicines and how to get help.},
  chapter = {Homepage},
  howpublished = {https://www.nhs.uk/},
  langid = {english}
}

@misc{NICEClinicalGuidelines,
  title = {{{NICE}} Clinical Guidelines | {{Tools}} and Resources | {{The}} Guidelines Manual | {{Guidance}} | {{NICE}}},
  publisher = {{NICE}},
  urldate = {2023-01-10},
  abstract = {The guidelines manual},
  howpublished = {https://www.nice.org.uk/process/pmg6/resources/how-nice-clinical-guidelines-are-developed-an-overview-for-stakeholders-the-public-and-the-nhs-2549708893/chapter/nice-clinical-guidelines},
  langid = {english}
}

@misc{NICENationalInstitute,
  type = {{{CorporatePage}}},
  title = {{{NICE}} | {{The National Institute}} for {{Health}} and {{Care Excellence}}},
  journal = {NICE},
  publisher = {{NICE}},
  urldate = {2023-10-03},
  abstract = {NICE helps practitioners and commissioners get the best care to patients, fast, while ensuring value for the taxpayer.},
  howpublished = {https://www.nice.org.uk/},
  langid = {english}
}

@inproceedings{nielsenMathematicalModelFinding1993,
  title = {A Mathematical Model of the Finding of Usability Problems},
  booktitle = {Proceedings of the {{INTERACT}} '93 and {{CHI}} '93 {{Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Nielsen, Jakob and Landauer, Thomas K.},
  year = {1993},
  month = may,
  series = {{{CHI}} '93},
  pages = {206--213},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/169059.169166},
  urldate = {2023-12-12},
  abstract = {For 11 studies, we find that the detection of usability problems as a function of number of users tested or heuristic evaluators employed is well modeled as a Poisson process. The model can be used to plan the amount of evaluation required to achieve desired levels of thoroughness or benefits. Results of early tests can provide estimates of the number of problems left to be found and the number of additional evaluations needed to find a given fraction. With quantitative evaluation costs and detection values, the model can estimate the numbers of evaluations at which optimal cost/benefit ratios are obtained and at which marginal utility vanishes. For a ``medium'' example, we estimate that 16 evaluations would be worth their cost, with maximum benefit/cost ratio at four.},
  isbn = {978-0-89791-575-5},
  keywords = {cost-benefit analysis,heuristic evaluation,iterative design,Poisson models,usability engineering,usability problems,user testing},
  file = {/Users/james/Library/Mobile Documents/iCloud~QReader~MarginStudy/Documents/DPhil/Nielsen_Landauer_1993_A mathematical model of the finding of usability problems.pdf}
}

@article{obrienStandardsReportingQualitative2014,
  title = {Standards for {{Reporting Qualitative Research}}: {{A Synthesis}} of {{Recommendations}}},
  shorttitle = {Standards for {{Reporting Qualitative Research}}},
  author = {O'Brien, Bridget C. and Harris, Ilene B. and Beckman, Thomas J. and Reed, Darcy A. and Cook, David A.},
  year = {2014},
  month = sep,
  journal = {Academic Medicine},
  volume = {89},
  number = {9},
  pages = {1245--1251},
  issn = {1040-2446},
  doi = {10.1097/ACM.0000000000000388},
  urldate = {2022-10-07},
  abstract = {Purpose~         Standards for reporting exist for many types of quantitative research, but currently none exist for the broad spectrum of qualitative research. The purpose of the present study was to formulate and define standards for reporting qualitative research while preserving the requisite flexibility to accommodate various paradigms, approaches, and methods.         Method~         The authors identified guidelines, reporting standards, and critical appraisal criteria for qualitative research by searching PubMed, Web of Science, and Google through July 2013; reviewing the reference lists of retrieved sources; and contacting experts. Specifically, two authors reviewed a sample of sources to generate an initial set of items that were potentially important in reporting qualitative research. Through an iterative process of reviewing sources, modifying the set of items, and coding all sources for items, the authors prepared a near-final list of items and descriptions and sent this list to five external reviewers for feedback. The final items and descriptions included in the reporting standards reflect this feedback.         Results~         The Standards for Reporting Qualitative Research (SRQR) consists of 21 items. The authors define and explain key elements of each item and provide examples from recently published articles to illustrate ways in which the standards can be met.         Conclusions~         The SRQR aims to improve the transparency of all aspects of qualitative research by providing clear standards for reporting qualitative research. These standards will assist authors during manuscript preparation, editors and reviewers in evaluating a manuscript for potential publication, and readers when critically appraising, applying, and synthesizing study findings.},
  langid = {american},
  keywords = {\_tablet},
  file = {/Users/james/Zotero/storage/6YDDEEPQ/OBrien et al_2014_Standards for Reporting Qualitative Research.pdf;/Users/james/Zotero/storage/BWTCIS8F/OBrien et al_2014_Standards for Reporting Qualitative Research.pdf}
}

@article{ocathainThreeTechniquesIntegrating2010a,
  title = {Three Techniques for Integrating Data in Mixed Methods Studies},
  author = {O'Cathain, A. and Murphy, E. and Nicholl, J.},
  year = {2010},
  month = sep,
  journal = {BMJ},
  volume = {341},
  number = {sep17 1},
  pages = {c4587-c4587},
  issn = {0959-8138, 1468-5833},
  doi = {10.1136/bmj.c4587},
  urldate = {2023-11-16},
  langid = {english},
  keywords = {to read},
  file = {/Users/james/Zotero/storage/EVJVW6XH/O'Cathain et al. - 2010 - Three techniques for integrating data in mixed met.pdf}
}

@article{pagePRISMA2020Statement2021,
  title = {The {{PRISMA}} 2020 Statement: An Updated Guideline for Reporting Systematic Reviews},
  shorttitle = {The {{PRISMA}} 2020 Statement},
  author = {Page, Matthew J. and McKenzie, Joanne E. and Bossuyt, Patrick M. and Boutron, Isabelle and Hoffmann, Tammy C. and Mulrow, Cynthia D. and Shamseer, Larissa and Tetzlaff, Jennifer M. and Akl, Elie A. and Brennan, Sue E. and Chou, Roger and Glanville, Julie and Grimshaw, Jeremy M. and Hr{\'o}bjartsson, Asbj{\o}rn and Lalu, Manoj M. and Li, Tianjing and Loder, Elizabeth W. and {Mayo-Wilson}, Evan and McDonald, Steve and McGuinness, Luke A. and Stewart, Lesley A. and Thomas, James and Tricco, Andrea C. and Welch, Vivian A. and Whiting, Penny and Moher, David},
  year = {2021},
  month = mar,
  journal = {BMJ (Clinical research ed.)},
  volume = {372},
  pages = {n71},
  issn = {1756-1833},
  doi = {10.1136/bmj.n71},
  langid = {english},
  pmcid = {PMC8005924},
  pmid = {33782057},
  keywords = {\_tablet,*practice guideline,*Preferred Reporting Items for Systematic Reviews and Meta-Analyses,*procedures,*reproducibility,article,checklist,evidence based medicine,human,Humans,Medical Writing,meta analysis,Meta-Analysis as Topic,methodology,nomenclature,practice guideline,Practice Guidelines as Topic,publishing,Quality Control,research,Research Design,Statistics as Topic,systematic review,Systematic Reviews as Topic,Terminology as Topic},
  file = {/Users/james/Zotero/storage/BFN6DX9I/Page et al_2021_The PRISMA 2020 statement.pdf}
}

@article{pageUpdatingGuidanceReporting2021,
  title = {Updating Guidance for Reporting Systematic Reviews: Development of the {{PRISMA}} 2020 Statement},
  shorttitle = {Updating Guidance for Reporting Systematic Reviews},
  author = {Page, Matthew J and McKenzie, Joanne E and Bossuyt, Patrick M and Boutron, Isabelle and Hoffmann, Tammy C and Mulrow, Cynthia D and Shamseer, Larissa and Tetzlaff, Jennifer M and Moher, David},
  year = {2021},
  month = jun,
  journal = {Journal of Clinical Epidemiology},
  volume = {134},
  pages = {103--112},
  issn = {0895-4356},
  doi = {10.1016/j.jclinepi.2021.02.003},
  urldate = {2021-10-03},
  abstract = {Objectives To describe the processes used to update the PRISMA 2009 statement for reporting systematic reviews, present results of a survey conducted to inform the update, summarize decisions made at the PRISMA update meeting, and describe and justify changes made to the guideline. Methods We reviewed 60 documents with reporting guidance for systematic reviews to generate suggested modifications to the PRISMA 2009 statement. We invited 220 systematic review methodologists and journal editors to complete a survey about the suggested modifications. The results of these projects were discussed at a 21-member in-person meeting. Following the meeting, we drafted the PRISMA 2020 statement and refined it based on feedback from co-authors and a convenience sample of 15 systematic reviewers. Results The review of 60 documents revealed that all topics addressed by the PRISMA 2009 statement could be modified. Of the 110 survey respondents, more than 66\% recommended keeping six of the original checklist items as they were and modifying 15 of them using wording suggested by us. Attendees at the in-person meeting supported the revised wording for several items but suggested rewording for most to enhance clarity, and further refinements were made over six drafts of the guideline. Conclusions The PRISMA 2020 statement consists of updated reporting guidance for systematic reviews. We hope that providing this detailed description of the development process will enhance the acceptance and uptake of the guideline and assist those developing and updating future reporting guidelines.},
  langid = {english},
  keywords = {\_tablet,Meta-analysis,QES-maybe,Reporting guidelines,Reproducibility,Systematic reviews,Transparency},
  file = {/Users/james/Zotero/storage/VTGE6BG5/Page et al_2021_Updating guidance for reporting systematic reviews.pdf;/Users/james/Zotero/storage/MQDKKPK5/S0895435621000408.html}
}

@article{pandisActiveImplementationStrategy2014,
  title = {Active Implementation Strategy of {{CONSORT}} Adherence by a Dental Specialty Journal Improved Randomized Clinical Trial Reporting},
  author = {Pandis, Nikolaos and Shamseer, Larissa and Kokich, Vincent G. and Fleming, Padhraig S. and Moher, David},
  year = {2014},
  month = sep,
  journal = {Journal of Clinical Epidemiology},
  volume = {67},
  number = {9},
  pages = {1044--1048},
  publisher = {{Elsevier}},
  issn = {0895-4356, 1878-5921},
  doi = {10.1016/j.jclinepi.2014.04.001},
  urldate = {2023-09-22},
  langid = {english},
  pmid = {24837296},
  keywords = {CONSORT,CONSORT compliance,CONSORT implementation,Dental journal,Orthodontics,Reporting of RCTs},
  file = {/Users/james/Zotero/storage/KY4S9EWB/Pandis et al. - 2014 - Active implementation strategy of CONSORT adherenc.pdf}
}

@misc{PastelFastestVisual,
  title = {Pastel | {{Fastest}} Visual Website Feedback Tool for Web Designers, Developers and Agencies},
  urldate = {2023-10-03},
  abstract = {Pastel is the easiest, and fastest way for web designers, developers, and agencies to collect feedback on the websites they're building.},
  howpublished = {https://usepastel.com/}
}

@misc{PenelopeAi,
  title = {Penelope.Ai},
  journal = {Penelope.ai},
  urldate = {2020-02-14},
  abstract = {Penelope.ai is an online tool that automatically checks whether scientific manuscripts meet journal requirements. It helps editors process manuscripts faster and helps authors polish their work before submitting to a journal.},
  howpublished = {https://www.penelope.ai},
  langid = {american},
  file = {/Users/james/Zotero/storage/HK8U72WF/www.penelope.ai.html}
}

@misc{PersonasHealthEducation,
  title = {Personas | {{Health Education England}}},
  journal = {Health Education England | Digital Transformation},
  urldate = {2023-10-06},
  abstract = {Persona's have been created to showcase the types of individuals who can use the framework.},
  howpublished = {https://digital-transformation.hee.nhs.uk/building-a-digital-workforce/dart-ed/horizon-scanning/ai-and-digital-healthcare-technologies/applying-the-framework-and-next-steps/personas},
  langid = {english}
}

@article{phillipsa.PilotTestingGuideline2015,
  title = {Pilot Testing of the Guideline for Reporting of Evidence-Based Practice Educational Interventions and Teaching (Greet)},
  author = {{Phillips A.} and {Lewis L.K.} and {McEvoy M.P.} and {Galipeau J.} and {Glasziou P.} and {Moher D.} and {Tilson J.K.} and {Williams M.T.}},
  year = {2015},
  journal = {Physiotherapy (United Kingdom)},
  series = {World {{Confederation}} for {{Physical Therapy Congress}} 2015. {{Singapore Singapore}}.},
  volume = {101},
  pages = {eS1203--eS1204},
  issn = {0031-9406},
  abstract = {Background: The importance of evidence-based practice (EBP) is well recognised in the education of health professionals. Despite a growing number of published educational interventions for EBP, several systematic reviews have been unable to determine best practice for EBP education. Contributing to the difficulty is the inconsistent reporting of interventions. While there are reporting guidelines for study designs, there are few to describe interventions and none for the reporting of educational interventions for EBP. To address this issue, the Guideline for Reporting Evidence-based practice Educational interventions and Teaching (GREET) was developed. Purpose(s): To determine the usability (wording, layout and ease of use) of the GREET checklist and the accompanying explanation and elaboration (E\&E) paper. Method(s): This pilot study used a cross-sectional, descriptive design. The GREET checklist is comprised of 17 items arising from a systematic review and Delphi consensus survey. The E\&E paper was developed to enhance the use and understanding of the GREET checklist. Tertiary health professional students with and without prior exposure to EBP education or reporting guidelines were invited to use the GREET checklist and E\&E paper to review a research study containing an educational intervention for EBP. Participants were asked to rate the completeness of the reporting for each of the GREET checklist items ('Yes - fully', 'Yes - partially', 'No - not reported', or 'not clear') and to rate the usability for each checklist item and the overall usability for the GREET checklist and E\&E paper using a five point Likert scale (1 = poor to 5 = excellent). Chi square analyses (chi2) were undertaken to determine whether there were any differences in ratings between those with and without previous exposure to EBP education or reporting guidelines. Result(s): Thirty-one students (n = 11 undergraduate, n=20 postgraduate) participated. The majority rated the overall usability for the GREET checklist as good or very good (80\%), and the E\&E paper as very good or excellent (77\%). Regarding wording and layout, the majority of participants rated the items in the GREET checklist (91+/-9\%) and the E\&Epaper (94+/-6\%) as easy to use. Participants' prior exposure to EBP education or reporting guidelines did not appear to influence the results, with no significant differences found between the participant ratings for the GREET checklist or the E\&E paper based on their previous exposure. Conclusion(s): Pilot testing demonstrated that the GREET checklist and E\&E paper were easy to use and understand by people with varying experience and exposure to EBP or reporting guidelines. Minor modifications are planned to improve the clarity of the wording for the GREET checklist and the E\&E paper prior to disseminating the final versions. Implications: If used appropriately, the GREET checklist and the E\&E paper may enable greater consistency in the reporting of educational interventions for EBP and permit accurate replication and synthesis of studies. Ultimately, adherence to the GREET checklist could enable the evidence-base for EBP education to be established and potentially enable best practice for EBP education to be determined.},
  langid = {english},
  keywords = {\_tablet,*evidence based practice,*physiotherapy,*teaching,checklist,chi square test,consensus,education,exposure,health practitioner,human,Likert scale,pilot study,postgraduate student,student,study design,synthesis,systematic review,systematic review (topic)},
  file = {/Users/james/Zotero/storage/K2FXEN7Q/Phillips A. et al_2015_Pilot testing of the guideline for reporting of evidence-based practice.pdf;/Users/james/Zotero/storage/84U8ULLP/S0031940615021616.html}
}

@article{plumePublishPerishRise2014,
  title = {Publish or Perish? {{The}} Rise of the Fractional Author\ldots},
  shorttitle = {Publish or Perish?},
  author = {Plume, Andrew and van Weijen, Daphne},
  year = {2014},
  month = sep,
  journal = {Research Trends},
  volume = {1},
  number = {38},
  issn = {2213-4441}
}

@misc{PopupBuilderThat,
  title = {Popup {{Builder That Boosts Sales}}.},
  journal = {Popup Smart},
  urldate = {2023-07-31},
  abstract = {A no-code tool to increase e-commerce sales, build email lists and engage with your visitors in just 5-minutes.},
  howpublished = {https://popupsmart.com/},
  langid = {american}
}

@misc{positRStudioIntegratedDevelopment,
  title = {The {{RStudio Integrated Development Environment}} ({{IDE}}) Is the Preferred Tools for Data Scientists Who Develop in {{R}} \& {{Python}}.},
  author = {{Posit}},
  journal = {Posit},
  urldate = {2023-08-04},
  abstract = {The RStudio Integrated Development Environment (IDE) is the preferred tools for data scientists who develop in R \& Python.},
  howpublished = {https://posit.co/products/open-source/rstudio/},
  langid = {english}
}

@article{pouwelsQualityReportingConfounding2016,
  title = {Quality of Reporting of Confounding Remained Suboptimal after the~{{STROBE}} Guideline},
  author = {Pouwels, Koen B. and Widyakusuma, Niken N. and Groenwold, Rolf H. H. and Hak, Eelko},
  year = {2016},
  month = jan,
  journal = {Journal of Clinical Epidemiology},
  volume = {69},
  pages = {217--224},
  issn = {0895-4356},
  doi = {10.1016/j.jclinepi.2015.08.009},
  urldate = {2023-08-17},
  abstract = {Objectives Poor quality of reporting of confounding has been observed in observational studies prior the STrenghtening the Reporting of Observational studies in Epidemiology (STROBE) statement, a reporting guideline for observational studies. We assessed whether the reporting of confounding improved after the STROBE statement. Study Design and Setting We searched MEDLINE for all articles about observational cohort and case\textendash control studies on interventions with a hypothesized beneficial effect in five general medical and five epidemiologic journals published between January 2010 and December 2012. We abstracted data for the baseline period before the publication of the STROBE statement (January 2004\textendash April 2007) from a prior study. Six relevant items related to confounding were scored for each article. A comparison of the median number of items reported in both periods was made. Results In total, 174 articles published before and 220 articles published after the STROBE statement were included. The median number reported items was similar before and after the publication of the STROBE statement [median, 4; interquartile range [IQR], 3\textendash 5 vs. median, 4; IQR, 3.75\textendash 5]. However, the distribution of the number of reported items shifted somewhat to the right (P~=~0.01). Conclusion Although the quality of reporting of confounding improved in certain aspects, the overall quality remains suboptimal.},
  keywords = {Confounding factors,Editorial policies,Epidemiology,Guideline adherence,Guidelines as topics,Publishing/standards},
  file = {/Users/james/Library/Mobile Documents/iCloud~QReader~MarginStudy/Documents/DPhil/Pouwels et al_2016_Quality of reporting of confounding remained suboptimal after the STROBE.pdf}
}

@article{pradyAssessingUtilityStandards2007,
  title = {Assessing the Utility of the Standards for Reporting Trials of Acupuncture ({{STRICTA}}): {{A}} Survey of Authors},
  shorttitle = {Assessing the {{Utility}} of the {{Standards}} for {{Reporting Trials}} of {{Acupuncture}} ({{STRICTA}})},
  author = {Prady, Stephanie L. and MacPherson, Hugh},
  year = {2007},
  month = nov,
  journal = {The Journal of Alternative and Complementary Medicine},
  volume = {13},
  number = {9},
  pages = {939--943},
  issn = {1075-5535, 1557-7708},
  doi = {10.1089/acm.2007.7186},
  urldate = {2021-03-30},
  abstract = {Objective: To inform the potential revision of Standards for Reporting Interventions in Controlled Trials of Acupuncture (STRICTA), we sought the opinion of acupuncture trial authors and systematic reviewers to rank the utility of the guidelines and asked trial authors about their experiences using them. Design: Questionnaires ranking STRICTA items and qualitative responses about experience using the guidelines. Sample: The authors of 38 randomized controlled acupuncture trials randomly selected from a systematic search of those published in 2004 and 2005 were contacted with a questionnaire. Authors of 14 Cochrane acupuncture systematic reviews or protocols published in the same time frame were also sent a questionnaire. Results: Fifty-four percent (54\%) (28/52) of the sample responded. Among the trial authors, 58\% (11/19) used STRICTA to help guide their writing, but more than half of these reported that the editing process had removed some or all of the STRICTA-specific items. STRICTA was seen as a helpful reference, but authors requested that some items be clarified. Respondents tended to rank the utility of STRICTA highly overall, but five items in particular were not highly valued; three of these pertained to details on the trial acupuncturists' background. Authors flagged potential difficulties of reporting unusual trial designs in the current format of STRICTA. Conclusions: Authors of acupuncture trials and systematic reviews believe that STRICTA contributes to the reporting of acupuncture interventions and rate it highly. Because very few acupuncture studies are published in STRICTA-adopting journals, the editing process for journals unaware of the guidelines may be responsible for deleting acupuncture intervention-specific items. Several items remain unclear, and the relevance of STRICTA to some trial designs is questioned. A review of STRICTA is warranted to clarify and reconsider items, and targeted promotion to non\textendash complementary and alternative medicine journals should be considered.},
  langid = {english},
  keywords = {\_tablet,*acupuncture,*Acupuncture Therapy/mt [Methods],*Acupuncture Therapy/st [Standards],*Controlled Clinical Trials as Topic/st [Standards],*health care utilization,*Medical Records/st [Standards],*Peer Review,Acupuncture therapy,alternative medicine,article,Clinical trials,Guidelines as Topic,health survey,human,humans,Humans,medical literature,Methods,physician,practice guideline,priority journal,Publishing/st [Standards],qualitative analysis,Quality of Health Care,questionnaire,randomization,Research Design/st [Standards],Research/st [Standards],standard,Standards,United States},
  file = {/Users/james/Zotero/storage/8INI72IV/Prady_MacPherson_2007_Assessing the Utility of the Standards for Reporting Trials of Acupuncture.pdf}
}

@article{pragerBarriersReportingGuideline2021,
  title = {Barriers to Reporting Guideline Adherence in Point-of-Care Ultrasound Research: A Cross-Sectional Survey of Authors and Journal Editors},
  shorttitle = {Barriers to Reporting Guideline Adherence in Point-of-Care Ultrasound Research},
  author = {Prager, Ross and Gagnon, Luke and Bowdridge, Joshua and Unni, Rudy R and McGrath, Trevor A and Cobey, Kelly and Bossuyt, Patrick M and McInnes, Matthew D F},
  year = {2021},
  month = jan,
  journal = {BMJ Evidence-Based Medicine},
  pages = {bmjebm-2020-111604},
  issn = {2515-446X, 2515-4478},
  doi = {10.1136/bmjebm-2020-111604},
  urldate = {2021-04-02},
  abstract = {Objective               Although the literature supporting the use of point-of-care ultrasound (POCUS) continues to grow, incomplete reporting of primary diagnostic accuracy studies has previously been identified as a barrier to translating research into practice and to performing unbiased systematic reviews. This study assesses POCUS investigator and journal editor attitudes towards barriers to adhering to the Standards for Reporting of Diagnostic Accuracy Studies (STARD) 2015 guidelines.                                         Design, setting, participants               Two separate surveys using a 5-point Likert scale were sent to POCUS study investigators and journal editors to assess for knowledge, attitude and behavioural barriers to the complete reporting of POCUS research. Respondents were identified based on a previous study assessing STARD 2015 adherence for POCUS studies published in emergency medicine, anaesthesia and critical care journals. Responses were anonymously linked to STARD 2015 adherence data from the previous study. Written responses were thematically grouped into the following categories: knowledge, attitude and behavioural barriers to quality reporting, or other. Likert response items are reported as median with IQRs.                                         Main outcome measures               The primary outcome was the median Likert score for the investigator and editor surveys assessing knowledge, attitude and behavioural beliefs about barriers to adhering to the STARD 2015 guidelines.                                         Results               The investigator survey response rate was 18/69 (26\%) and the editor response rate was 5/21 (24\%). Most investigator respondents were emergency medicine practitioners (13/21, 62\%). Two-thirds of investigators were aware of the STARD 2015 guidelines (12/18, 67\%) and overall agreed that incomplete reporting limits generalisability and the ability to detect risk of bias (median 4 (4, 5)). Investigators felt that the STARD 2015 guidelines were useful, easy to find and easy to use (median 4 (4, 4.25); median 4 (4, 4.25) and median 4 (3, 4), respectively). There was a shared opinion held by investigators and editors that the peer review process be primarily responsible for ensuring complete research reporting (median 4 (3, 4) and median 4 (3.75, 4), respectively). Three of 18 authors (17\%) felt that the English publication language of STARD 2015 was a barrier to adherence.                                         Conclusions               Although investigators and editors recognise the importance of completely reported research, reporting quality is still a core issue for POCUS research. The shared opinion held by investigators and editors that the peer review process be primarily responsible for reporting quality is potentially problematic; we view completely reported research as an integral part of the research process that investigators are responsible for, with the peer review process serving as another additional layer of quality control. Endorsement of reporting guidelines by journals, auditing reporting guideline adherence during the peer review process and translation of STARD 2015 guidelines into additional languages may improve reporting completeness for the acute POCUS literature.                                         Trial registration number                                Open Science Framework Registry (                 https://osf.io/5pzxs/                 ).},
  langid = {english},
  keywords = {\_tablet,*editor,*emergency medicine,*intensive care,*point of care ultrasound,*protocol compliance,*radiology,adult,anesthesia,article,Cesarean Section,Cross-Sectional Studies,diagnostic accuracy,diagnostic test accuracy study,female,Guideline Adherence,human,human experiment,language,Likert scale,male,outcome assessment,peer review,practice guideline,QES-include,quality control,systematic review},
  file = {/Users/james/Zotero/storage/BQ5APDL3/Prager et al_2021_Barriers to reporting guideline adherence in point-of-care ultrasound research.pdf}
}

@misc{ProjetMiRoR,
  title = {Projet {{MiRoR}}},
  journal = {Projet MiRoR},
  urldate = {2021-02-06},
  abstract = {An innovative and ambitious joint doctoral training programme},
  howpublished = {http://miror-ejd.eu/},
  langid = {american},
  file = {/Users/james/Zotero/storage/GRZIZ7TL/miror-ejd.eu.html}
}

@article{ProposalStructuredReporting1994,
  title = {A Proposal for Structured Reporting of Randomized Controlled Trials. {{The Standards}} of {{Reporting Trials Group}}},
  year = {1994},
  month = dec,
  journal = {JAMA},
  volume = {272},
  number = {24},
  pages = {1926--1931},
  issn = {0098-7484},
  langid = {english},
  pmid = {7990245},
  keywords = {Publishing,Quality Control,Randomized Controlled Trials as Topic}
}

@misc{qsrinternationalptyltd.NVivo2020,
  title = {{{NVivo}}},
  author = {{QSR International Pty Ltd.}},
  year = {2020},
  month = mar
}

@misc{QuartoOpenSource,
  title = {Quarto: {{An}} Open Source Technical Publishing System for Creating Beautiful Articles, Websites, Blogs, Books, Slides, and More. {{Supports Python}}, {{R}}, {{Julia}}, and {{JavaScript}}.},
  journal = {Quarto},
  urldate = {2023-08-04},
  abstract = {An open source technical publishing system for creating beautiful articles, websites, blogs, books, slides, and more. Supports Python, R, Julia, and JavaScript.},
  howpublished = {https://quarto.org/},
  langid = {english}
}

@article{radert.MethodsDocumentingSystematic2014,
  title = {Methods for Documenting Systematic Review Searches: A Discussion of Common Issues},
  author = {{Rader T.} and {Mann M.} and {Stansfield C.} and {Cooper C.} and {Sampson M.}},
  year = {2014},
  journal = {Research synthesis methods},
  volume = {5},
  number = {2},
  pages = {98--115},
  issn = {1759-2887 (electronic)},
  abstract = {INTRODUCTION: As standardized reporting requirements for systematic reviews are being adopted more widely, review authors are under greater pressure to accurately record their search process. With careful planning, documentation to fulfill the Preferred Reporting Items for Systematic Reviews and Meta-Analyses requirements can become a valuable tool for organizing a systematic review literature search and planning updates., METHODS: A working group of information specialists convened to discuss current practice and were informed by a Web-based survey of over 260 systematic review authors, trials search coordinators, librarians, and other information specialists conducted in February/March 2011., DISCUSSION: Survey responses provided insight into current practices and difficulties of reporting searches. These included a lack of time, tools, clear understanding of the requirements, and uncertainty about responsibility for documenting these elements. This paper will present some of the practical aspects of documenting the systematic literature search. Section 1 provides background information and rationale for this paper. Section 2 discusses issues and recommendations arising from survey results. Section 3 outlines specific elements to be recorded. Section 4 guides the reader through the information management process. Section 5 concludes with implications for future research and practice. These principles are applicable to any large literature search for systematic reviews, health technology assessments, and guideline development.Copyright \textcopyright{} 2013 John Wiley \& Sons, Ltd.},
  langid = {english},
  keywords = {\_tablet,*database management system,*factual database,*literature,*procedures,*research,documentation,documenting searches,information retrieval,meta analysis (topic),PRISMA,reporting standards,search strategies,systematic reviews},
  file = {/Users/james/Zotero/storage/AP2W5V6L/Rader T. et al_2014_Methods for documenting systematic review searches.pdf;/Users/james/Zotero/storage/5FVELKCL/jrsm.html}
}

@article{ramirezf.danielMethodologicalRigorPreclinical2017,
  title = {Methodological {{Rigor}} in {{Preclinical Cardiovascular Studies}}},
  author = {{Ramirez F. Daniel} and {Motazedian Pouya} and {Jung Richard G.} and {Di Santo Pietro} and {MacDonald Zachary D.} and {Moreland Robert} and {Simard Trevor} and {Clancy Aisling A.} and {Russo Juan J.} and {Welch Vivian A.} and {Wells George A.} and {Hibbert Benjamin}},
  year = {2017},
  month = jun,
  journal = {Circulation Research},
  volume = {120},
  number = {12},
  pages = {1916--1926},
  publisher = {{American Heart Association}},
  doi = {10.1161/CIRCRESAHA.117.310628},
  urldate = {2020-11-21},
  abstract = {Rationale:Methodological sources of bias and suboptimal reporting contribute to irreproducibility in preclinical science and may negatively affect research translation. Randomization, blinding, sample size estimation, and considering sex as a biological variable are deemed crucial study design elements to maximize the quality and predictive value of preclinical experiments.Objective:To examine the prevalence and temporal patterns of recommended study design element implementation in preclinical cardiovascular research.Methods and Results:All articles published over a 10-year period in 5 leading cardiovascular journals were reviewed. Reports of in vivo experiments in nonhuman mammals describing pathophysiology, genetics, or therapeutic interventions relevant to specific cardiovascular disorders were identified. Data on study design and animal model use were collected. Citations at 60 months were additionally examined as a surrogate measure of research impact in a prespecified subset of studies, stratified by individual and cumulative study design elements. Of 28\,636 articles screened, 3396 met inclusion criteria. Randomization was reported in 21.8\%, blinding in 32.7\%, and sample size estimation in 2.3\%. Temporal and disease-specific analyses show that the implementation of these study design elements has overall not appreciably increased over the past decade, except in preclinical stroke research, which has uniquely demonstrated significant improvements in methodological rigor. In a subset of 1681 preclinical studies, randomization, blinding, sample size estimation, and inclusion of both sexes were not associated with increased citations at 60 months.Conclusions:Methodological shortcomings are prevalent in preclinical cardiovascular research, have not substantially improved over the past 10 years, and may be overlooked when basing subsequent studies. Resultant risks of bias and threats to study validity have the potential to hinder progress in cardiovascular medicine as preclinical research often precedes and informs clinical trials. Stroke research quality has uniquely improved in recent years, warranting a closer examination for interventions to model in other cardiovascular fields.},
  keywords = {\_tablet},
  file = {/Users/james/Zotero/storage/8HVYK5VN/Ramirez F. Daniel et al_2017_Methodological Rigor in Preclinical Cardiovascular Studies.pdf;/Users/james/Zotero/storage/RKUHUF93/CIRCRESAHA.117.html}
}

@article{rethlefsenPRISMASExtensionPRISMA2021,
  title = {{{PRISMA-S}}: An Extension to the {{PRISMA}} Statement for Reporting Literature Searches in Systematic Reviews},
  shorttitle = {{{PRISMA-S}}},
  author = {Rethlefsen, Melissa L. and Kirtley, Shona and Waffenschmidt, Siw and Ayala, Ana Patricia and Moher, David and Page, Matthew J. and Koffel, Jonathan B. and Blunt, Heather and Brigham, Tara and Chang, Steven and Clark, Justin and Conway, Aislinn and Couban, Rachel and {de Kock}, Shelley and Farrah, Kelly and Fehrmann, Paul and Foster, Margaret and Fowler, Susan A. and Glanville, Julie and Harris, Elizabeth and Hoffecker, Lilian and Isojarvi, Jaana and Kaunelis, David and Ket, Hans and Levay, Paul and Lyon, Jennifer and McGowan, Jessie and Murad, M. Hassan and Nicholson, Joey and Pannabecker, Virginia and Paynter, Robin and Pinotti, Rachel and {Ross-White}, Amanda and Sampson, Margaret and Shields, Tracy and Stevens, Adrienne and Sutton, Anthea and Weinfurter, Elizabeth and Wright, Kath and Young, Sarah and {PRISMA-S Group}},
  year = {2021},
  month = jan,
  journal = {Systematic Reviews},
  volume = {10},
  number = {1},
  pages = {39},
  issn = {2046-4053},
  doi = {10.1186/s13643-020-01542-z},
  urldate = {2021-03-05},
  abstract = {Literature searches underlie the foundations of systematic reviews and related review types. Yet, the literature searching component of systematic reviews and related review types is often poorly reported. Guidance for literature search reporting has been diverse, and, in many cases, does not offer enough detail to authors who need more specific information about reporting search methods and information sources in a clear, reproducible way. This document presents the PRISMA-S (Preferred Reporting Items for Systematic reviews and Meta-Analyses literature search extension) checklist, and explanation and elaboration.},
  keywords = {\_tablet,*information retrieval,*reproducibility,article,Delphi study,editor,human,Information retrieval,Literature search,Preferred Reporting Items for Systematic Reviews and Meta-Analyses,Reporting guidelines,Reproducibility,Search strategies,systematic review,Systematic reviews},
  file = {/Users/james/Zotero/storage/Y3QY5AYA/Rethlefsen et al_2021_PRISMA-S.pdf;/Users/james/Zotero/storage/XRXPDC8Z/s13643-020-01542-z.html}
}

@incollection{robertsEstablishingCoherentReporting2014,
  title = {Establishing a {{Coherent Reporting Guidelines Policy}} in {{Health Journals}}},
  booktitle = {Guidelines for {{Reporting Health Research}}: {{A User}}'s {{Manual}}},
  author = {Roberts, Jason L. and Houle, Timothy T. and Loder, Elizabeth W. and Penzien, Donald B. and Turner, Dana P. and Rothrock, John F.},
  editor = {Moher, David and Altman, Douglas G. and Schulz, Kenneth F. and Simera, Iveta and Wager, Elizabeth},
  year = {2014},
  month = jul,
  edition = {1},
  pages = {308--317},
  publisher = {{Wiley}},
  doi = {10.1002/9781118715598.ch29},
  urldate = {2023-10-11},
  isbn = {978-0-470-67044-6 978-1-118-71559-8},
  langid = {english},
  file = {/Users/james/Zotero/storage/4P2Q9DPH/Roberts et al. - 2014 - Establishing a Coherent Reporting Guidelines Polic.pdf}
}

@article{rogersLocatingQualitativeStudies2018,
  title = {Locating Qualitative Studies in Dementia on {{MEDLINE}}, {{EMBASE}}, {{CINAHL}}, and {{PsycINFO}}: {{A}} Comparison of Search Strategies},
  shorttitle = {Locating Qualitative Studies in Dementia on {{MEDLINE}}, {{EMBASE}}, {{CINAHL}}, and {{PsycINFO}}},
  author = {Rogers, Morwenna and Bethel, Alison and Abbott, Rebecca},
  year = {2018},
  journal = {Research Synthesis Methods},
  volume = {9},
  number = {4},
  pages = {579--586},
  issn = {1759-2887},
  doi = {10.1002/jrsm.1280},
  urldate = {2021-02-07},
  abstract = {Background Qualitative research in dementia improves understanding of the experience of people affected by dementia. Searching databases for qualitative studies is problematic. Qualitative-specific search strategies might help with locating studies. Objective To examine the effectiveness (sensitivity and precision) of 5 qualitative strategies on locating qualitative research studies in dementia in 4 major databases (MEDLINE, EMBASE, PsycINFO, and CINAHL). Methods Qualitative dementia studies were checked for inclusion on MEDLINE, EMBASE, PsycINFO, and CINAHL. Five qualitative search strategies (subject headings, simple free-text terms, complex free-text terms, and 2 broad-based strategies) were tested for study retrieval. Specificity, precision and number needed to read were calculated. Results Two hundred fourteen qualitative studies in dementia were included. PsycINFO and CINAHL held the most qualitative studies out the 4 databases studied (N = 171 and 166, respectively) and both held unique records (N = 14 and 7, respectively). The controlled vocabulary strategy in CINAHL returned 96\% (N = 192) of studies held; by contrast, controlled vocabulary in PsycINFO returned 7\% (N = 13) of studies held. The broad-based strategies returned more studies (93-99\%) than the other free-text strategies (22-82\%). Precision ranged from 0.061 to 0.004 resulting in a number needed to read to obtain 1 relevant study ranging from 16 (simple free-text search in CINAHL) to 239 (broad-based search in EMBASE). Conclusion Qualitative search strategies using 3 broad terms were more sensitive than long complex searches. The controlled vocabulary for qualitative research in CINAHL was particularly effective. Furthermore, results indicate that MEDLINE and EMBASE offer little benefit for locating qualitative dementia research if CINAHL and PSYCINFO are also searched.},
  copyright = {\textcopyright{} 2017 John Wiley \& Sons, Ltd.},
  langid = {english},
  file = {/Users/james/Zotero/storage/7ILHQTS3/jrsm.html}
}

@article{rosumeckValidationStudyRevealed2020,
  title = {A Validation Study Revealed Differences in Design and Performance of Search Filters for Qualitative Research in {{PsycINFO}} and {{CINAHL}}},
  author = {Rosumeck, Stefanie and Wagner, Mandy and Wallraf, Simon and Euler, Ulrike},
  year = {2020},
  month = dec,
  journal = {J Clin Epidemiol},
  volume = {128},
  pages = {101--108},
  publisher = {{Elsevier}},
  issn = {0895-4356, 1878-5921},
  doi = {10.1016/j.jclinepi.2020.09.031},
  urldate = {2021-01-26},
  abstract = {{$<$}h2{$>$}Abstract{$<$}/h2{$><$}h3{$>$}Objectives{$<$}/h3{$><$}p{$>$}Search filters can support qualitative evidence of information retrieval. Various search filters are available for the bibliographic databases PsycINFO and CINAHL. To date, no comparative overview of validation results of search filters verified with an independent gold standard exists.{$<$}/p{$><$}h3{$>$}Study Design and Setting{$<$}/h3{$><$}p{$>$}Identified search filters for PsycINFO and CINAHL were tested for plausibility. Gold standards were generated according to the relative recall approach using references included in an overview of systematic reviews of qualitative studies. All included references were collected and checked for indexing in PsycINFO and CINAHL. Validation tests for each search filter were conducted in both databases to determine whether the references of the gold standards could be retrieved or not.{$<$}/p{$><$}h3{$>$}Results{$<$}/h3{$><$}p{$>$}Twelve search filters for PsycINFO and fifteen for CINAHL were validated. The complexity and design of these search filters vary, as well as the validation results for the databases. When locating primary studies of qualitative research, the best sensitivity and precision ratio (among filters with a sensitivity of {$>$}80\%) was achieved with a filter by McKibbon et al. for PsycINFO and a filter by Wilczynski et al. for CINAHL.{$<$}/p{$><$}h3{$>$}Conclusion{$<$}/h3{$><$}p{$>$}Project-specific requirements and resources influence the choice of a specific search filter for PsycINFO and CINAHL.{$<$}/p{$>$}},
  langid = {english},
  pmid = {32987157},
  file = {/Users/james/Zotero/storage/SITA7HK4/Rosumeck et al_2020_A validation study revealed differences in design and performance of search.pdf;/Users/james/Zotero/storage/KGWATPGW/fulltext.html}
}

@article{santoMethodsResultsStudies2023,
  title = {Methods and Results of Studies on Reporting Guideline Adherence Are Poorly Reported: A Meta-Research Study},
  shorttitle = {Methods and Results of Studies on Reporting Guideline Adherence Are Poorly Reported},
  author = {Santo, Tiffany Dal and Rice, Danielle B. and Amiri, Lara S. N. and Tasleem, Amina and Li, Kexin and Boruff, Jill T. and Geoffroy, Marie-Claude and Benedetti, Andrea and Thombs, Brett D.},
  year = {2023},
  month = jul,
  journal = {Journal of Clinical Epidemiology},
  volume = {159},
  pages = {225--234},
  publisher = {{Elsevier}},
  issn = {0895-4356, 1878-5921},
  doi = {10.1016/j.jclinepi.2023.05.017},
  urldate = {2023-08-15},
  langid = {english},
  pmid = {37271424},
  keywords = {Checklist,Checklists,Replicability,Reproducibility,Research waste,Research-on-research}
}

@article{santoMethodsResultsStudies2023a,
  title = {Methods and Results of Studies on Reporting Guideline Adherence Are Poorly Reported: A Meta-Research Study},
  shorttitle = {Methods and Results of Studies on Reporting Guideline Adherence Are Poorly Reported},
  author = {Santo, Tiffany Dal and Rice, Danielle B. and Amiri, Lara S. N. and Tasleem, Amina and Li, Kexin and Boruff, Jill T. and Geoffroy, Marie-Claude and Benedetti, Andrea and Thombs, Brett D.},
  year = {2023},
  month = jul,
  journal = {Journal of Clinical Epidemiology},
  volume = {159},
  pages = {225--234},
  publisher = {{Elsevier}},
  issn = {0895-4356, 1878-5921},
  doi = {10.1016/j.jclinepi.2023.05.017},
  urldate = {2023-08-17},
  langid = {english},
  pmid = {37271424},
  keywords = {Checklist,Checklists,Replicability,Reproducibility,Research waste,Research-on-research},
  file = {/Users/james/Library/Mobile Documents/iCloud~QReader~MarginStudy/Documents/DPhil/Santo et al_2023_Methods and results of studies on reporting guideline adherence are poorly.pdf}
}

@misc{SciELO,
  title = {About {{SciELO}}},
  urldate = {2021-02-19},
  howpublished = {https://scielo.org/en/about-scielo},
  file = {/Users/james/Zotero/storage/MJS25CTE/about-scielo.html}
}

@misc{ScimagoJournalCountry,
  title = {Scimago {{Journal}} \& {{Country Rank}}},
  urldate = {2020-11-06},
  howpublished = {https://www.scimagojr.com/},
  file = {/Users/james/Zotero/storage/9KNVZPEY/www.scimagojr.com.html}
}

@article{sertARRIVEGuidelinesUpdated2020,
  title = {The {{ARRIVE}} Guidelines 2.0: {{Updated}} Guidelines for Reporting Animal Research},
  shorttitle = {The {{ARRIVE}} Guidelines 2.0},
  author = {du Sert, Nathalie Percie and Hurst, Viki and Ahluwalia, Amrita and Alam, Sabina and Avey, Marc T. and Baker, Monya and Browne, William J. and Clark, Alejandra and Cuthill, Innes C. and Dirnagl, Ulrich and Emerson, Michael and Garner, Paul and Holgate, Stephen T. and Howells, David W. and Karp, Natasha A. and Lazic, Stanley E. and Lidster, Katie and MacCallum, Catriona J. and Macleod, Malcolm and Pearl, Esther J. and Petersen, Ole H. and Rawle, Frances and Reynolds, Penny and Rooney, Kieron and Sena, Emily S. and Silberberg, Shai D. and Steckler, Thomas and W{\"u}rbel, Hanno},
  year = {2020},
  month = jul,
  journal = {PLOS Biology},
  volume = {18},
  number = {7},
  pages = {e3000410},
  publisher = {{Public Library of Science}},
  issn = {1545-7885},
  doi = {10.1371/journal.pbio.3000410},
  urldate = {2020-10-31},
  abstract = {Reproducible science requires transparent reporting. The ARRIVE guidelines (Animal Research: Reporting of In Vivo Experiments) were originally developed in 2010 to improve the reporting of animal research. They consist of a checklist of information to include in publications describing in vivo experiments to enable others to scrutinise the work adequately, evaluate its methodological rigour, and reproduce the methods and results. Despite considerable levels of endorsement by funders and journals over the years, adherence to the guidelines has been inconsistent, and the anticipated improvements in the quality of reporting in animal research publications have not been achieved. Here, we introduce ARRIVE 2.0. The guidelines have been updated and information reorganised to facilitate their use in practice. We used a Delphi exercise to prioritise and divide the items of the guidelines into 2 sets, the ``ARRIVE Essential 10,'' which constitutes the minimum requirement, and the ``Recommended Set,'' which describes the research context. This division facilitates improved reporting of animal research by supporting a stepwise approach to implementation. This helps journal editors and reviewers verify that the most important items are being reported in manuscripts. We have also developed the accompanying Explanation and Elaboration (E\&E) document, which serves (1) to explain the rationale behind each item in the guidelines, (2) to clarify key concepts, and (3) to provide illustrative examples. We aim, through these changes, to help ensure that researchers, reviewers, and journal editors are better equipped to improve the rigour and transparency of the scientific process and thus reproducibility.},
  langid = {english},
  keywords = {\_tablet,*animal experiment,*Animal Experimentation,*animal research,*animal research reporting,*clinical research,*Guidelines as Topic,*information processing,*medical research,*practice guideline,*research,*Research Report,*veterinary study,agriculture,animal,animal care,animal housing,animal husbandry,Animal Shells,Animals,ARRIVE,article,artificial intelligence,checklist,Checklist,clinical practice,clinical protocol,controlled study,data analysis,data mining,data processing,Delphi exercise,Delphi study,editor,editorial,ethics,exercise,Experimental design,experimental study,guideline,health care personnel,human,implementation science,in vivo study,information,information processing,methodology,monitoring,morbidity,nonhuman,organization,outcome assessment,priority journal,protocol compliance,publication,QES-include,quality control,randomization,registration,reproducibility,Reproducibility,Reproducibility of Results,research,Research design,Research Report,Research reporting guidelines,Research validity,rigor,sample size,Science policy,scientific literature,scientist,statistical analysis,Statistical data,Statistical methods,study design},
  file = {/Users/james/Zotero/storage/M3AFIVQF/Sert et al_2020_The ARRIVE guidelines 2.pdf;/Users/james/Zotero/storage/RAP6P9M7/Sert et al_2020_The ARRIVE guidelines 2.pdf;/Users/james/Zotero/storage/SE52QGDJ/Sert et al_2020_The ARRIVE guidelines 2.pdf;/Users/james/Zotero/storage/6NJQLQXU/article.html;/Users/james/Zotero/storage/XWQBY866/article.html}
}

@article{sharpCrosssectionalBibliometricStudy2019,
  title = {A Cross-Sectional Bibliometric Study Showed Suboptimal Journal Endorsement Rates of {{STROBE}} and Its Extensions},
  author = {Sharp, Melissa K and Tokali{\'c}, Ru{\v z}ica and G{\'o}mez, Guadalupe and Wager, Elizabeth and Altman, Douglas G and Hren, Darko},
  year = {2019},
  journal = {Journal of clinical epidemiology},
  volume = {107},
  pages = {42--50},
  publisher = {{Elsevier Inc}},
  issn = {0895-4356},
  abstract = {{$<$}p{$>$}The STrengthening the Reporting of Observational Studies in Epidemiology (STROBE) statement provides guidance on reporting observational studies. Many extensions have been created for specialized methods or fields. We determined endorsement prevalence and typology by journals in extension-related fields.{$<$}/p{$>$} {$<$}p{$>$}A published protocol defined search strategies to identify journals publishing observational studies (2007\textendash 2017) across seven fields relating to STROBE extensions. We extracted text regarding STROBE, seven STROBE extensions, reporting guidelines Consolidated Standards of Reporting Trials and Preferred Reporting Items for Systematic Reviews and Meta-Analyses, and transparent reporting documents/groups: International Committee of Medical Journal Editors, Committee on Publication Ethics (COPE), and the Enhancing the QUAlity and Transparency Of health Research (EQUATOR) networks. Relationships between endorsing STROBE, endorsing other guidelines, and journal impact...},
  langid = {english},
  keywords = {Epidemiologic Research Design,Guidelines As Topic,Information Dissemination/Methods,Medicine,Observational Studies,Reporting Guidelines,Strobe},
  file = {/Users/james/Zotero/storage/J94WNQL3/Sharp et al_2019_A cross-sectional bibliometric study showed suboptimal journal endorsement.pdf;/Users/james/Zotero/storage/Q55ADG5Z/Sharp et al. - 2019 - A cross-sectional bibliometric study showed subopt.pdf;/Users/james/Zotero/storage/JK7SDAP2/S0895435618305377.html;/Users/james/Zotero/storage/LX2VE9W8/S0895435618305377.html}
}

@article{sharpOnlineSurveySTROBE2020,
  title = {Online Survey about the {{STROBE}} Statement Highlighted Diverging Views about Its Content, Purpose, and Value},
  author = {Sharp, Melissa K and Glonti, Ketevan and Hren, Darko},
  year = {2020},
  journal = {Journal of clinical epidemiology},
  volume = {123},
  pages = {100--106},
  publisher = {{Elsevier Inc}},
  issn = {0895-4356},
  abstract = {{$<$}p{$>$}The endorsement rates of The STrengthening the Reporting of OBservational studies in Epidemiology (STROBE) Statement are low and little is known about authors' opinions about this reporting guideline. We conducted an online survey with observational study authors on attitude toward and experiences with the STROBE Statement with the aim of understanding how to effectively implement STROBE.{$<$}/p{$>$} {$<$}p{$>$}A thematic analysis on the responses to an open-ended question was conducted using inductive coding. Two coders classified responses independently into themes using a codebook. The inter-rater agreement ranged from 87.7 to 99.9\%.{$<$}/p{$>$} {$<$}p{$>$}15\% (n = 150) of survey participants (n = 1,015) shared perceptions and insights on STROBE. We established four themes: 1) perceptions of the checklist, 2) academic confidence, 3) use in education and training, and 4) journal endorsement and use in peer review. Views were diverse and revealed multiple misunderstandings about the...},
  langid = {english},
  keywords = {\_tablet,*Epidemiologic Research Design,*information dissemination,*Information Dissemination/mt [Methods],*Observational Studies as Topic/mt [Methods],*Observational Studies as Topic/sn [Statistics \textbackslash\& Numerical Data],*practice guideline,*Research Report/st [Standards],*Surveys and Questionnaires/sn [Statistics \textbackslash\& Numerical Data],adult,article,attitude,career,checklist,education,Epidemiologic Research Design,Guidelines As Topic,human,human experiment,Humans,Information Dissemination/Methods,Internet,interrater reliability,major clinical study,Medicine,Observational Studies,Observational Studies as Topic/st [Standards],observational study,peer review,perception,QES-include,Strobe Reporting Guidelines,thematic analysis},
  file = {/Users/james/Zotero/storage/G6D25YMJ/Sharp et al_2020_Online survey about the STROBE statement highlighted diverging views about its.pdf;/Users/james/Zotero/storage/EBH3995R/S0895435619307176.html;/Users/james/Zotero/storage/UYXI5AEU/S0895435619307176.html}
}

@article{sharpUsingSTROBEStatement2019,
  title = {Using the {{STROBE}} Statement: Survey Findings Emphasized the Role of Journals in Enforcing Reporting Guidelines},
  shorttitle = {Using the {{STROBE}} Statement},
  author = {Sharp, Melissa K. and Bertizzolo, Lorenzo and Rius, Roser and Wager, Elizabeth and G{\'o}mez, Guadalupe and Hren, Darko},
  year = {2019},
  month = dec,
  journal = {Journal of Clinical Epidemiology},
  volume = {116},
  pages = {26--35},
  issn = {0895-4356},
  doi = {10.1016/j.jclinepi.2019.07.019},
  urldate = {2021-12-29},
  abstract = {Objectives The objective of the study was to identify factors affecting the use of the Strengthening the Reporting of Observational Studies in Epidemiology (STROBE) statement, specifically authors' attitudes toward and experiences with it. Study Design and Setting An online survey was distributed to authors of observational studies recruited via social media, personal network snowballing, and mass mailings using targeted search strategies. Data on demographics, awareness, motivators, and usage were collected in conjunction with a modified Unified Theory of Acceptance and Use of Technology (UTAUT) scale on which confirmatory factor analysis (CFA) was performed. Results One thousand fifteen participants completed the survey. Of these, 185 (18.2\%) indicated they had never heard of STROBE nor used it previously, 195 (19.2\%) had heard of it but never used it, and 635 (62.6\%) had used it. Journals promoting STROBE were both key motivators and awareness mechanisms; peers and educational workshops were also important influencing factors to a lesser degree. The internal consistency of the modified UTAUT scale was strong (Cronbach's alpha~=~0.94). CFA supported a four-factor model with 23 questions. Conclusion The endorsement of STROBE by journals is key to authors' awareness and use of the guideline. We tested and validated our scale which can guide future research on reporting guidelines.},
  langid = {english},
  keywords = {\_tablet,*information dissemination,*Periodicals as Topic/st [Standards],*practice guideline,*Research Report/st [Standards],*writing,adult,article,awareness,confirmatory factor analysis,Cronbach alpha coefficient,Epidemiologic research design,female,Guideline Adherence,Guidelines as topic,Guidelines as Topic,human,human experiment,Humans,Information dissemination/methods,internal consistency,Internet,major clinical study,male,Observational studies,Observational Studies as Topic,observational study,Online survey,QES-exclude,Scientific writing,social media,STROBE,Surveys and Questionnaires},
  file = {/Users/james/Zotero/storage/BQA9N74G/Sharp et al_2019_Using the STROBE statement.pdf;/Users/james/Zotero/storage/KIH6TBIM/Sharp et al_2019_Using the STROBE statement.pdf;/Users/james/Zotero/storage/NRJX9DTE/Sharp et al_2019_Using the STROBE statement.pdf;/Users/james/Zotero/storage/6FNRSNGS/S0895435619304998.html;/Users/james/Zotero/storage/RUTMDFH7/S0895435619304998.html}
}

@misc{SinoMed,
  title = {{{SinoMed}}},
  urldate = {2021-03-05},
  howpublished = {http://www.sinomed.ac.cn/},
  file = {/Users/james/Zotero/storage/C5TG7MKC/www.sinomed.ac.cn.html}
}

@article{skivingtonNewFrameworkDeveloping2021,
  title = {A New Framework for Developing and Evaluating Complex Interventions: Update of {{Medical Research Council}} Guidance},
  shorttitle = {A New Framework for Developing and Evaluating Complex Interventions},
  author = {Skivington, Kathryn and Matthews, Lynsay and Simpson, Sharon Anne and Craig, Peter and Baird, Janis and Blazeby, Jane M and Boyd, Kathleen Anne and Craig, Neil and French, David P and McIntosh, Emma and Petticrew, Mark and {Rycroft-Malone}, Jo and White, Martin and Moore, Laurence},
  year = {2021},
  month = sep,
  journal = {BMJ},
  pages = {n2061},
  issn = {1756-1833},
  doi = {10.1136/bmj.n2061},
  urldate = {2021-10-01},
  langid = {english},
  keywords = {\_tablet},
  file = {/Users/james/Zotero/storage/BN2EJTND/Skivington et al_2021_A new framework for developing and evaluating complex interventions.pdf;/Users/james/Zotero/storage/SXGWNL75/Skivington et al_2021_A new framework for developing and evaluating complex interventions.pdf;/Users/james/Zotero/storage/BH2YWW3R/bmj.html}
}

@article{smythNaturalHistoryConducting2015,
  title = {The Natural History of Conducting and Reporting Clinical Trials: Interviews with Trialists},
  shorttitle = {The Natural History of Conducting and Reporting Clinical Trials},
  author = {Smyth, Rebecca MD and Jacoby, Ann and Altman, Douglas G. and Gamble, Carrol and Williamson, Paula R.},
  year = {2015},
  month = jan,
  journal = {Trials},
  volume = {16},
  number = {1},
  pages = {16},
  issn = {1745-6215},
  doi = {10.1186/s13063-014-0536-6},
  urldate = {2023-08-11},
  abstract = {To investigate the nature of the research process as a whole, factors that might influence the way in which research is carried out, and how researchers ultimately report their findings.},
  keywords = {Equipoise,Interviews,Qualitative,Recruitment,Research reporting,Trial protocols,Trialists},
  file = {/Users/james/Library/Mobile Documents/iCloud~QReader~MarginStudy/Documents/DPhil/Smyth et al_2015_The natural history of conducting and reporting clinical trials.pdf}
}

@misc{stmassociationSTMGlobalBrief,
  title = {{{STM Global Brief}} 2021 \textendash{} {{Economics}} \& {{Market Size}}},
  author = {{STM Association}},
  urldate = {2023-07-31},
  howpublished = {https://www.stm-assoc.org/wp-content/uploads/2022\_08\_24\_STM\_White\_Report\_a4\_v15.pdf},
  file = {/Users/james/Zotero/storage/BZJZMD6Z/2022_08_24_STM_White_Report_a4_v15.pdf}
}

@article{struthersGoodReportsDevelopingWebsite2021,
  title = {{{GoodReports}}: Developing a Website to Help Health Researchers Find and Use Reporting Guidelines},
  shorttitle = {{{GoodReports}}},
  author = {Struthers, Caroline and Harwood, James and {de Beyer}, Jennifer Anne and Dhiman, Paula and Logullo, Patricia and Schl{\"u}ssel, Michael},
  year = {2021},
  month = oct,
  journal = {BMC medical research methodology},
  volume = {21},
  number = {1},
  pages = {217},
  issn = {1471-2288},
  doi = {10.1186/s12874-021-01402-x},
  abstract = {BACKGROUND: Th EQUATOR Network improves the quality and transparency in health research, primarily by promoting awareness and use of reporting guidelines. In 2018, the UK EQUATOR Centre launched GoodReports.org , a website that helps authors find and use reporting guidelines. This paper describes the tool's development so far. We describe user experience and behaviour of using GoodReports.org both inside and outside a journal manuscript submission process. We intend to use our findings to inform future development and testing of the tool. METHODS: We conducted a survey to collect data on user experience of the GoodReports website. We cross-checked a random sample of 100 manuscripts submitted to a partner journal to describe the level of agreement between the tool's checklist recommendation and what we would have recommended. We compared the proportion of authors submitting a completed reporting checklist alongside their manuscripts between groups exposed or not exposed to the GoodReports tool. We also conducted a study comparing completeness of reporting of manuscript text before an author received a reporting guideline recommendation from GoodReports.org with the completeness of the text subsequently submitted to a partner journal. RESULTS: Seventy percent (423/599) of survey respondents rated GoodReports 8 or more out of 10 for usefulness, and 74\% (198/267) said they had made changes to their manuscript after using the website. We agreed with the GoodReports reporting guideline recommendation in 84\% (72/86) of cases. Of authors who completed the guideline finder questionnaire, 14\% (10/69) failed to submit a completed checklist compared to 30\% (41/136) who did not use the tool. Of the 69 authors who received a GoodReports reporting guideline recommendation, 20 manuscript pairs could be reviewed before and after use of GoodReports. Five included more information in their methods section after exposure to GoodReports. On average, authors reported 57\% of necessary reporting items before completing a checklist on GoodReports.org and 60\% after. CONCLUSION: The data suggest that reporting guidance is needed early in the writing process, not at submission stage. We are developing GoodReports by adding more reporting guidelines and by creating editable article templates. We will test whether GoodReports users write more complete study reports in a randomised trial targeting researchers starting to write health research articles.},
  langid = {english},
  pmcid = {PMC8520646},
  pmid = {34657590},
  keywords = {\_tablet,*education,*practice guideline,*reproducibility,*software,adult,article,Behavior Therapy,checklist,Checklist,controlled study,Education,female,human,human experiment,Humans,male,medical research,questionnaire,random sample,randomized controlled trial,Reporting guidelines,Reproducibility,Research Design,Software,Standards,writing,Writing},
  file = {/Users/james/Zotero/storage/YE7W9EU5/Struthers et al_2021_GoodReports.pdf}
}

@article{svensoyQualitativeStudyResearchers2021,
  title = {A Qualitative Study on Researchers' Experiences after Publishing Scientific Reports on Major Incidents, Mass-Casualty Incidents, and Disasters},
  author = {Svens{\o}y, Johannes Nordsteien and Nilsson, Helene and Rimstad, Rune},
  year = {2021},
  month = oct,
  journal = {Prehospital and Disaster Medicine},
  volume = {36},
  number = {5},
  pages = {536--542},
  publisher = {{Cambridge University Press}},
  issn = {1049-023X, 1945-1938},
  doi = {10.1017/S1049023X21000911},
  urldate = {2022-01-04},
  abstract = {Introduction and Objective: Scientific reporting on major incidents, mass-casualty incidents (MCIs), and disasters is challenging and made difficult by the nature of the medical response. Many obstacles might explain why there are few and primarily non-heterogenous published articles available. This study examines the process of scientific reporting through first-hand experiences from authors of published reports. It aims to identify learning points and challenges that are important to address to mitigate and improve scientific reporting after major incidents. Methods: This was a qualitative study design using semi-structured interviews. Participants were selected based on a comprehensive literature search. Ten researchers, who had published reports on major incidents, MCIs, or disasters from 2013-2018 were included, of both genders, from eight countries on three continents. The researchers reported on large fires, terrorist attacks, shootings, complex road accidents, transportation accidents, and earthquakes. Results: The interview was themed around initiation, workload, data collection, guidelines/templates, and motivation factors for reporting. The most challenging aspects of the reporting process proved to be a lack of dedicated time, difficulties concerning data collection, and structuring the report. Most researchers had no prior experience in reporting on major incidents. Guidelines and templates were often chosen based on how easily accessible and user-friendly they were. Conclusion and Relevance: There are few articles presenting first-hand experience from the process of scientific reporting on major incidents, MCIs, and disasters. This study presents motivation factors, challenges during reporting, and factors that affected the researchers' choice of reporting tools such as guidelines and templates. This study shows that the structural tools available for gathering data and writing scientific reports need to be more widely promoted to improve systematic reporting in Emergency and Disaster Medicine. Through gathering, comparing, and analyzing data, knowledge can be acquired to strengthen and improve responses to future major incidents. This study indicates that transparency and willingness to share information are requisite for forming a successful scientific report.},
  langid = {english},
  keywords = {*mass disaster,*practice guideline,*publishing,*qualitative research,adult,article,disaster,disaster medicine,earthquake,female,fire,gender,guideline,human,learning,major incident,male,mass-casualty incident,motivation,reporting,semi structured interview,systematic review,terrorism,traffic accident,workload,writing},
  file = {/Users/james/Zotero/storage/DMDVHQHU/Svensy et al_2021_A Qualitative Study on Researchers Experiences after Publishing Scientific.pdf;/Users/james/Zotero/storage/CCTQHMZZ/E9D7F39DD262CD863A9B7A0BEBAF217E.html}
}

@article{szinayInfluencesUptakeHealth2021,
  title = {Influences on the {{Uptake}} of {{Health}} and {{Well-being Apps}} and {{Curated App Portals}}: {{Think-Aloud}} and {{Interview Study}}},
  shorttitle = {Influences on the {{Uptake}} of {{Health}} and {{Well-being Apps}} and {{Curated App Portals}}},
  author = {Szinay, Dorothy and Perski, Olga and Jones, Andy and Chadborn, Tim and Brown, Jamie and Naughton, Felix},
  year = {2021},
  month = apr,
  journal = {JMIR mHealth and uHealth},
  volume = {9},
  number = {4},
  pages = {e27173},
  publisher = {{JMIR Publications Inc., Toronto, Canada}},
  doi = {10.2196/27173},
  urldate = {2023-11-16},
  abstract = {Background: Health and well-being smartphone apps can provide a cost-effective solution to addressing unhealthy behaviors. The selection of these apps tends to occur in commercial app stores, where thousands of health apps are available. Their uptake is often influenced by popularity indicators. However, these indicators are not necessarily associated with app effectiveness or evidence-based content. Alternative routes to app selection are increasingly available, such as via curated app portals, but little is known about people's experiences of them. Objective: The aim of this study is to explore how people select health apps on the internet and their views on curated app portals. Methods: A total of 18 UK-based adults were recruited through social media and asked during an in-person meeting to verbalize their thoughts while searching for a health or well-being app on the internet on a platform of their choice. The search was then repeated on 2 curated health app portals: the National Health Service Apps Library and the Public Health England One You App portal. This was followed by semistructured interviews. Data were analyzed using framework analysis, informed by the Capability, Opportunity, Motivation-Behavior model and the Theoretical Domains Framework. Results: Searching for health and well-being apps on the internet was described as a minefield. App uptake appeared to be influenced by participants' capabilities such as app literacy skills and health and app awareness, and opportunities including the availability of apps, app esthetics, the price of an app, and social influences. Motivation factors that seemed to affect the uptake were perceived competence, time efficiency, perceived utility and accuracy of an app, transparency about data protection, commitment and social identity, and a wide range of emotions. Social influences and the perceived utility of an app were highlighted as particularly important. Participants were not previously aware of curated portals but found the concept appealing. Curated health app portals appeared to engender trust and alleviate data protection concerns. Although apps listed on these were perceived as more trustworthy, their presentation was considered disappointing. This disappointment seemed to stem from the functionality of the portals, lack of user guidance, and lack of tailored content to an individual's needs. Conclusions: The uptake of health and well-being apps appears to be primarily affected by social influences and the perceived utility of an app. App uptake via curated health app portals perceived as credible may mitigate concerns related to data protection and accuracy, but their implementation must better meet user needs and expectations.},
  copyright = {Unless stated otherwise, all articles are open-access distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work ("first published in JMIR mHealth and uHealth...") is properly cited with original URL and bibliographic citation information. The complete bibliographic information, a link to the original publication on http://mhealth.jmir.org/, as well as this copyright and license information must be included.},
  langid = {english},
  file = {/Users/james/Library/Mobile Documents/iCloud~QReader~MarginStudy/Documents/DPhil/Szinay et al_2021_Influences on the Uptake of Health and Well-being Apps and Curated App Portals.pdf}
}

@article{tamPerceptionPreferredReporting2019,
  title = {Perception of the {{Preferred Reporting Items}} for {{Systematic Reviews}} and {{Meta-Analyses}} ({{PRISMA}}) Statement of Authors Publishing Reviews in Nursing Journals: A Cross-Sectional Online Survey},
  shorttitle = {Perception of the {{Preferred Reporting Items}} for {{Systematic Reviews}} and {{Meta-Analyses}} ({{PRISMA}}) Statement of Authors Publishing Reviews in Nursing Journals},
  author = {Tam, Wilson W. S. and Tang, Arthur and Woo, Brigitte and Goh, Shawn Y. S.},
  year = {2019},
  month = apr,
  journal = {BMJ Open},
  volume = {9},
  number = {4},
  pages = {e026271},
  publisher = {{British Medical Journal Publishing Group}},
  issn = {2044-6055, 2044-6055},
  doi = {10.1136/bmjopen-2018-026271},
  urldate = {2021-09-03},
  abstract = {Objective The Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) statement has been developed as a guideline for reporting systematic reviews and meta-analyses. Despite the prevalent use of the PRISMA statement in medicine and nursing, no studies have examined authors' perception of it. The purpose of this study is to explore the perception of the PRISMA statement of authors who published reviews, meta-analyses, or both in nursing journals. Design Cross-sectional descriptive study. Methods An online survey was conducted among authors who published reviews, meta-analyses, or both in nursing journals between 2011 and 2017. The selected authors' email addresses were extracted from the PUBMED database. A questionnaire\textemdash with a 10-point Likert scale (1\textemdash not important at all to 10\textemdash very important)\textemdash was developed to elicit their responses regarding their perception of not only the PRISMA statement as a whole, but also the individual items therein. Results Invitations were sent to 1960 valid email addresses identified, with 230 responses (response rate: 11.7\%) and 181 completed responses (completion rate: 9.2\%). The average perceived importance of the PRISMA statement was 8.66 (SD=1.35), while the perceived importance for the individual items ranged from 7.74 to 9.32. Six items were rated significantly higher than the average rating, whereas one item was rated significantly lower. Conclusion Most respondents perceived the PRISMA statement as important. Items related to information sources, selection, search-flow presentation, summary of findings, limitations and interpretation were deemed more important while the registration was deemed less so.},
  chapter = {Medical publishing and peer review},
  copyright = {\textcopyright{} Author(s) (or their employer(s)) 2019. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.. This is an open access article distributed in accordance with the Creative Commons Attribution Non Commercial (CC BY-NC 4.0) license, which permits others to distribute, remix, adapt, build upon this work non-commercially, and license their derivative works on different terms, provided the original work is properly cited, appropriate credit is given, any changes made indicated, and the use is non-commercial. See: http://creativecommons.org/licenses/by-nc/4.0/.},
  langid = {english},
  pmid = {31005930},
  keywords = {\_tablet,*nursing,*Nursing,*perception,*Periodicals as Topic/sn [Statistics \textbackslash\& Numerical Data],*publishing,*Quality Control,*Records/sn [Statistics \textbackslash\& Numerical Data],*Review Literature as Topic,adult,Cesarean Section,controlled study,Databases,e-mail,Evidence-Based Medicine,Factual,female,human,human experiment,Humans,Likert scale,male,Medline,meta analysis,PRISMA,publication policy,QES-include,quality of reporting,questionnaire,registration,research reporting,review,systematic review,systematic reviews},
  file = {/Users/james/Zotero/storage/32XARQJR/Tam et al_2019_Perception of the Preferred Reporting Items for Systematic Reviews and.pdf;/Users/james/Zotero/storage/RE4CINKF/Tam et al_2019_Perception of the Preferred Reporting Items for Systematic Reviews and.pdf;/Users/james/Zotero/storage/2AJR4NKP/e026271.html}
}

@article{thomasMethodsThematicSynthesis2008,
  title = {Methods for the Thematic Synthesis of Qualitative Research in Systematic Reviews},
  author = {Thomas, James and Harden, Angela},
  year = {2008},
  month = jul,
  journal = {BMC Medical Research Methodology},
  volume = {8},
  number = {1},
  pages = {45},
  issn = {1471-2288},
  doi = {10.1186/1471-2288-8-45},
  urldate = {2021-01-14},
  abstract = {There is a growing recognition of the value of synthesising qualitative research in the evidence base in order to facilitate effective and appropriate health care. In response to this, methods for undertaking these syntheses are currently being developed. Thematic analysis is a method that is often used to analyse data in primary qualitative research. This paper reports on the use of this type of analysis in systematic reviews to bring together and integrate the findings of multiple qualitative studies.},
  keywords = {\_tablet,Analytical Theme,Healthy Eating,Primary Study,Qualitative Research,Review Question},
  file = {/Users/james/Zotero/storage/Y2534QQE/Thomas_Harden_2008_Methods for the thematic synthesis of qualitative research in systematic reviews.pdf;/Users/james/Zotero/storage/ZBTBNZNK/1471-2288-8-45.html}
}

@article{tongEnhancingTransparencyReporting2012,
  title = {Enhancing Transparency in Reporting the Synthesis of Qualitative Research: {{ENTREQ}}},
  shorttitle = {Enhancing Transparency in Reporting the Synthesis of Qualitative Research},
  author = {Tong, Allison and Flemming, Kate and McInnes, Elizabeth and Oliver, Sandy and Craig, Jonathan},
  year = {2012},
  month = nov,
  journal = {BMC Medical Research Methodology},
  volume = {12},
  number = {1},
  pages = {181},
  issn = {1471-2288},
  doi = {10.1186/1471-2288-12-181},
  urldate = {2021-01-25},
  abstract = {The syntheses of multiple qualitative studies can pull together data across different contexts, generate new theoretical or conceptual models, identify research gaps, and provide evidence for the development, implementation and evaluation of health interventions. This study aims to develop a framework for reporting the synthesis of qualitative health research.},
  keywords = {Qualitative health research,Reporting,Standards,Thematic synthesis},
  file = {/Users/james/Zotero/storage/HNHYLRTB/Tong et al_2012_Enhancing transparency in reporting the synthesis of qualitative research.pdf;/Users/james/Zotero/storage/TNIENABA/1471-2288-12-181.html}
}

@misc{UsageStatisticsMarket,
  title = {Usage {{Statistics}} and {{Market Share}} of {{Traffic Analysis Tools}} for {{Websites}}, {{July}} 2023},
  urldate = {2023-07-31},
  howpublished = {https://w3techs.com/technologies/overview/traffic\_analysis}
}

@book{UXFiveSecondRules2014,
  title = {The {{UX Five-Second Rules}}},
  year = {2014},
  month = jan,
  pages = {19--76},
  publisher = {{Morgan Kaufmann}},
  doi = {10.1016/B978-0-12-800534-7.00002-0},
  urldate = {2021-07-29},
  abstract = {The five-second rules are a set of guidelines designed to assist researchers who wish to use the method to test their designs. They are written with a\ldots},
  isbn = {978-0-12-800534-7},
  langid = {english},
  file = {/Users/james/Zotero/storage/MVPTWKRQ/B9780128005347000020.html}
}

@article{vandenbrouckeStrengtheningReportingObservational2007a,
  title = {Strengthening the {{Reporting}} of {{Observational Studies}} in {{Epidemiology}} ({{STROBE}}): Explanation and Elaboration},
  shorttitle = {Strengthening the {{Reporting}} of {{Observational Studies}} in {{Epidemiology}} ({{STROBE}})},
  author = {Vandenbroucke, Jan P. and {von Elm}, Erik and Altman, Douglas G. and G{\o}tzsche, Peter C. and Mulrow, Cynthia D. and Pocock, Stuart J. and Poole, Charles and Schlesselman, James J. and Egger, Matthias and {STROBE Initiative}},
  year = {2007},
  month = oct,
  journal = {PLoS medicine},
  volume = {4},
  number = {10},
  pages = {e297},
  issn = {1549-1676},
  doi = {10.1371/journal.pmed.0040297},
  abstract = {Much medical research is observational. The reporting of observational studies is often of insufficient quality. Poor reporting hampers the assessment of the strengths and weaknesses of a study and the generalisability of its results. Taking into account empirical evidence and theoretical considerations, a group of methodologists, researchers, and editors developed the Strengthening the Reporting of Observational Studies in Epidemiology (STROBE) recommendations to improve the quality of reporting of observational studies. The STROBE Statement consists of a checklist of 22 items, which relate to the title, abstract, introduction, methods, results and discussion sections of articles. Eighteen items are common to cohort studies, case-control studies and cross-sectional studies and four are specific to each of the three study designs. The STROBE Statement provides guidance to authors about how to improve the reporting of observational studies and facilitates critical appraisal and interpretation of studies by reviewers, journal editors and readers. This explanatory and elaboration document is intended to enhance the use, understanding, and dissemination of the STROBE Statement. The meaning and rationale for each checklist item are presented. For each item, one or several published examples and, where possible, references to relevant empirical studies and methodological literature are provided. Examples of useful flow diagrams are also included. The STROBE Statement, this document, and the associated Web site (http://www.strobe-statement.org/) should be helpful resources to improve reporting of observational research.},
  langid = {english},
  pmcid = {PMC2020496},
  pmid = {17941715},
  keywords = {Case-Control Studies,Cohort Studies,Cross-Sectional Studies,Epidemiologic Research Design,Guidelines as Topic,Observation,Publishing},
  file = {/Users/james/Library/Mobile Documents/iCloud~QReader~MarginStudy/Documents/DPhil/Vandenbroucke et al_2007_Strengthening the Reporting of Observational Studies in Epidemiology (STROBE)2.pdf}
}

@inproceedings{velsenPersonasLinkingPin2012,
  title = {Personas: {{The Linking Pin}} in {{Holistic Design}} for {{eHealth}}},
  shorttitle = {Personas},
  booktitle = {{{eTELEMED}} 2012 : {{The Fourth International Conference}} on {{eHealth}}, {{Telemedicine}}, and {{Social Medicine}}},
  author = {van Velsen, Lex Stefan and van {Gemert-Pijnen}, Julia E. W. C. and Nijland, N. and Beaujean, Desir{\'e}e and van Steenbergen, Jim},
  year = {2012},
  month = jan,
  pages = {128--133},
  urldate = {2023-10-06},
  langid = {english},
  file = {/Users/james/Library/Mobile Documents/iCloud~QReader~MarginStudy/Documents/DPhil/Velsen et al_2012_Personas.pdf}
}

@article{vilaroAdherenceReportingGuidelines2019,
  title = {Adherence to Reporting Guidelines Increases the Number of Citations: The Argument for Including a Methodologist in the Editorial Process and Peer-Review},
  shorttitle = {Adherence to Reporting Guidelines Increases the Number of Citations},
  author = {Vilar{\'o}, Marta and Cort{\'e}s, Jordi and {Selva-O'Callaghan}, Albert and Urrutia, Agust{\'i}n and Ribera, Josep-Maria and Cardellach, Francesc and Basaga{\~n}a, Xavier and Elmore, Matthew and Vilardell, Miquel and Altman, Douglas and Gonz{\'a}lez, Jos{\'e}-Antonio and Cobo, Erik},
  year = {2019},
  month = may,
  journal = {BMC Medical Research Methodology},
  volume = {19},
  pages = {112},
  issn = {1471-2288},
  doi = {10.1186/s12874-019-0746-4},
  urldate = {2023-09-22},
  abstract = {Background From 2005 to 2010, we conducted 2 randomized studies on a journal (Medicina Cl\'inica), where we took manuscripts received for publication and randomly assigned them to either the standard editorial process or to additional processes. Both studies were based on the use of methodological reviewers and reporting guidelines (RG). Those interventions slightly improved the items reported on the Manuscript Quality Assessment Instrument (MQAI), which assesses the quality of the research report. However, masked evaluators were able to guess the allocated group in 62\% (56/90) of the papers, thus presenting a risk of detection bias. In this post-hoc study, we analyse whether those interventions that were originally designed for improving the completeness of manuscript reporting may have had an effect on the number of citations, which is the measured outcome that we used. Methods Masked to the intervention group, one of us used the Web of Science (WoS) to quantify the number of citations that the participating manuscripts received up December 2016. We calculated the mean citation ratio between intervention arms and then quantified the uncertainty of it by means of the Jackknife method, which avoids assumptions about the distribution shape. Results Our study included 191 articles (99 and 92, respectively) from the two previous studies, which all together received 1336 citations. In both studies, the groups subjected to additional processes showed higher averages, standard deviations and annual rates. The intervention effect was similar in both studies, with a combined estimate of a 43\% (95\% CI: 3 to 98\%) increase in the number of citations. Conclusions We interpret that those effects are driven mainly by introducing into the editorial process a senior methodologist to find missing RG items. Those results are promising, but not definitive due to the exploratory nature of the study and some important caveats such as: the limitations of using the number of citations as a measure of scientific impact; and the fact that our study is based on a single journal. We invite journals to perform their own studies to ascertain whether or not scientific repercussion is increased by adhering to reporting guidelines and further involving statisticians in the editorial process. Electronic supplementary material The online version of this article (10.1186/s12874-019-0746-4) contains supplementary material, which is available to authorized users.},
  pmcid = {PMC6544961},
  pmid = {31151417},
  file = {/Users/james/Library/Mobile Documents/iCloud~QReader~MarginStudy/Documents/DPhil/Vilar et al_2019_Adherence to reporting guidelines increases the number of citations.pdf}
}

@misc{VIPChineseMedical,
  title = {{{VIP Chinese Medical Journal Database}}},
  urldate = {2021-03-01},
  howpublished = {http://www.cqvip.com/},
  file = {/Users/james/Zotero/storage/HGI9QJJW/www.cqvip.com.html}
}

@article{vonelmStrengtheningReportingObservational2007,
  title = {Strengthening the Reporting of Observational Studies in Epidemiology ({{STROBE}}) Statement: Guidelines for Reporting Observational Studies},
  shorttitle = {Strengthening the Reporting of Observational Studies in Epidemiology ({{STROBE}}) Statement},
  author = {{von Elm}, Erik and Altman, Douglas G and Egger, Matthias and Pocock, Stuart J and G{\o}tzsche, Peter C and Vandenbroucke, Jan P},
  year = {2007},
  month = oct,
  journal = {BMJ : British Medical Journal},
  volume = {335},
  number = {7624},
  pages = {806--808},
  issn = {0959-8138},
  doi = {10.1136/bmj.39335.541782.AD},
  urldate = {2020-11-16},
  abstract = {Poor reporting of research hampers assessment and makes it less useful. An international group of methodologists, researchers, and journal editors sets out guidelines to improve reports of observational studies},
  pmcid = {PMC2034723},
  pmid = {17947786},
  keywords = {\_tablet},
  file = {/Users/james/Zotero/storage/AQCWPYXW/von Elm et al_2007_Strengthening the reporting of observational studies in epidemiology (STROBE).pdf}
}

@misc{WanfangDataLeading,
  title = {Wanfang {{Data}} - {{A Leading Provider}} of {{Electronic Resources}} for {{China Studies}}},
  urldate = {2021-03-01},
  howpublished = {http://www.wanfangdata.com/},
  file = {/Users/james/Zotero/storage/F9CR94A5/www.wanfangdata.com.html}
}

@misc{WebMobileTag,
  title = {Web \& {{Mobile Tag Management Solutions}} \textendash{} {{Google Tag Manager}}},
  journal = {Google Marketing Platform},
  urldate = {2023-07-31},
  abstract = {Google Tag Manager helps make tag management simple, easy and reliable with tag management solutions that allow small businesses to deploy website tags all in one place.},
  howpublished = {https://marketingplatform.google.com/intl/en\_uk/about/tag-manager/},
  langid = {english}
}

@misc{WebsiteBuilderCreate,
  title = {Website {{Builder}} \textemdash{} {{Create}} a {{Website}} in {{Minutes}}},
  journal = {Squarespace},
  urldate = {2023-08-04},
  abstract = {Create a customizable website or online store with an all-in-one solution from Squarespace. Choose a website template and start your free trial today.},
  howpublished = {https://www.squarespace.com/},
  langid = {american}
}

@misc{WesternPacificRegion,
  title = {Western {{Pacific Region Index Medicus}}},
  urldate = {2021-03-01},
  howpublished = {http://www.wprim.org/},
  file = {/Users/james/Zotero/storage/7VHT6KR9/www.wprim.org.html}
}

@misc{WHOEMROIMEMR,
  title = {{{WHO EMRO}} | {{IMEMR}} | {{Library}}},
  urldate = {2021-03-01},
  howpublished = {http://www.emro.who.int/e-library/imemr/index.html},
  file = {/Users/james/Zotero/storage/KC6V5CD4/index.html}
}

@article{yardleyPersonBasedApproachIntervention2015,
  title = {The {{Person-Based Approach}} to {{Intervention Development}}: {{Application}} to {{Digital Health-Related Behavior Change Interventions}}},
  shorttitle = {The {{Person-Based Approach}} to {{Intervention Development}}},
  author = {Yardley, Lucy and Morrison, Leanne and Bradbury, Katherine and Muller, Ingrid},
  year = {2015},
  month = jan,
  journal = {Journal of Medical Internet Research},
  volume = {17},
  number = {1},
  pages = {e4055},
  publisher = {{JMIR Publications Inc., Toronto, Canada}},
  doi = {10.2196/jmir.4055},
  urldate = {2023-07-14},
  abstract = {This paper describes an approach that we have evolved for developing successful digital interventions to help people manage their health or illness. We refer to this as the \&\#8220;person-based\&\#8221; approach to highlight the focus on understanding and accommodating the perspectives of the people who will use the intervention. While all intervention designers seek to elicit and incorporate the views of target users in a variety of ways, the person-based approach offers a distinctive and systematic means of addressing the user experience of intended behavior change techniques in particular and can enhance the use of theory-based and evidence-based approaches to intervention development. There are two key elements to the person-based approach. The first is a developmental process involving qualitative research with a wide range of people from the target user populations, carried out at every stage of intervention development, from planning to feasibility testing and implementation. This process goes beyond assessing acceptability, usability, and satisfaction, allowing the intervention designers to build a deep understanding of the psychosocial context of users and their views of the behavioral elements of the intervention. Insights from this process can be used to anticipate and interpret intervention usage and outcomes, and most importantly to modify the intervention to make it more persuasive, feasible, and relevant to users. The second element of the person-based approach is to identify \&\#8220;guiding principles\&\#8221; that can inspire and inform the intervention development by highlighting the distinctive ways that the intervention will address key context-specific behavioral issues. This paper describes how to implement the person-based approach, illustrating the process with examples of the insights gained from our experience of carrying out over a thousand interviews with users, while developing public health and illness management interventions that have proven effective in trials involving tens of thousands of users.},
  langid = {english},
  file = {/Users/james/Library/Mobile Documents/iCloud~QReader~MarginStudy/Documents/DPhil/Yardley et al_2015_The Person-Based Approach to Intervention Development.pdf}
}

@article{yardleyUnderstandingReactionsInternetdelivered2010,
  title = {Understanding Reactions to an Internet-Delivered Health-Care Intervention: Accommodating User Preferences for Information Provision},
  shorttitle = {Understanding Reactions to an Internet-Delivered Health-Care Intervention},
  author = {Yardley, Lucy and Morrison, Leanne G. and Andreou, Panayiota and Joseph, Judith and Little, Paul},
  year = {2010},
  month = sep,
  journal = {BMC Medical Informatics and Decision Making},
  volume = {10},
  number = {1},
  pages = {52},
  issn = {1472-6947},
  doi = {10.1186/1472-6947-10-52},
  urldate = {2023-11-16},
  abstract = {It is recognised as good practice to use qualitative methods to elicit users' views of internet-delivered health-care interventions during their development. This paper seeks to illustrate the advantages of combining usability testing with 'theoretical modelling', i.e. analyses that relate the findings of qualitative studies during intervention development to social science theory, in order to gain deeper insights into the reasons and context for how people respond to the intervention. This paper illustrates how usability testing may be enriched by theoretical modelling by means of two qualitative studies of users' views of the delivery of information in an internet-delivered intervention to help users decide whether they needed to seek medical care for their cold or flu symptoms.},
  keywords = {Diagnostic Question,Insuperable Barrier,Social Science Theory,Usability Testing,Vocational Qualification},
  file = {/Users/james/Library/Mobile Documents/iCloud~QReader~MarginStudy/Documents/DPhil/Yardley et al_2010_Understanding reactions to an internet-delivered health-care intervention.pdf}
}

@misc{YourWebsiteYour,
  title = {Your Website, Your Business, Your future{{Wix}}.Com},
  journal = {wix.com},
  urldate = {2023-08-04},
  abstract = {It starts with a website. Build on a platform that gives you the freedom to create, design, and grow online exactly the way you want.},
  howpublished = {https://www.wix.com},
  langid = {english}
}

@article{ziemannPoorReportingQuality2022,
  title = {Poor Reporting Quality of Observational Clinical Studies Comparing Treatments of {{COVID-19}} \textendash{} a Retrospective Cross-Sectional Study},
  author = {Ziemann, Sebastian and Paetzolt, Irina and Gr{\"u}{\ss}er, Linda and Coburn, Mark and Rossaint, Rolf and Kowark, Ana},
  year = {2022},
  month = jan,
  journal = {BMC Medical Research Methodology},
  volume = {22},
  number = {1},
  pages = {23},
  issn = {1471-2288},
  doi = {10.1186/s12874-021-01501-9},
  urldate = {2023-08-11},
  abstract = {During the COVID-19 pandemic, the scientific world is in urgent need for new evidence on the treatment of COVID patients. The reporting quality is crucial for transparent scientific publication. Concerns of data integrity, methodology and transparency were raised. Here, we assessed the adherence of observational studies comparing treatments of COVID 19 to the STROBE checklist in 2020.},
  keywords = {COVID-19,Observational studies,Reporting quality,STROBE statement},
  file = {/Users/james/Library/Mobile Documents/iCloud~QReader~MarginStudy/Documents/DPhil/Ziemann et al_2022_Poor reporting quality of observational clinical studies comparing treatments.pdf}
}
