ICARUS study - ARRIVE
"There is considerable room for improvement, and this study shows that an editorial policy of making ARRIVE checklist completion “mandatory” without compliance checks has little or no impact"

"Journal endorsement of these guidelines appear to have improved reporting quality [15,18]; however, it is often unclear what actions journals take to promote adherence [17]and the extent of editorial involvement is likely to have an impact. Prior reports indicate that assessing compliance with reporting guidelines at the stage of peer review leads to a significant improvement of reporting quality [5]. Other approaches (e.g. actions on the part of funders or institutions) may also be beneficial, but a successful strategy is likely to be **multi-dimensional**. Further, the findings reported here and the limited agreement between outcome assessors both in this study and in the recent investigation of study quality following the introduction of a new editorial policy at Nature journals [12] suggests that an important part of guideline development should be refinement of the content, the number of items (with fewer generally being better), and the agreement between assessors. It may be that a more formal adoption of research improvement strategies, with an original focus on a smaller number of items judged by a stakeholder to be of greatest importance, will allow an incremental approach to enabling and measuring improvement"

"We need therefore a better understanding of the barriers to implementing quality checklists for animal experiments"

"Perhaps unsurprisingly, due to the additional time required for ARRIVE checklist requests, both the number of days manuscripts spent in the PLOS editorial office and the number of days from manuscript submission to AE assignment were found to be significantly longer in the intervention group."

"The editorial resource required to ensure that all accepted publications meet the requirements of the ARRIVE checklist is likely to be considerable, given that PLOS ONE is a high-volume publisher, with around 44,000 submissions per year"

"Another consideration is the perceived clarity of the checklist to authors and reviewers. Although reviewer agreement was generally high, a few questions were less well understood by our outcome assessors which suggests the current guidelines may require clearer dissemination among the research community"

# Kilicoglu



# Deschartres

"Although using reporting guidelines, such as the CONSORT checklist, is associated with more complete reporting,48 49 their implementation varies between journals44-52 with many journals having no policy or mentioning only the existence of the CONSORT statement in the instructions to authors.44-52 We need to promote more active implementation, such as submission of the checklist with the manuscript, as it has been associated with better reporting."

No experience collection - retrospective 
# Dejong

Nothing 

# Nedovic

"Therefore, we suggest that it is not sufficient for journals to simply recommend the use of STREGA to authors in the authors’ instructions; instead, journals should require submission of the STREGA checklist together with the manuscript"

No experience collection - retrospective 

# Howell

No conjecture on why they saw no effect or how to improve SQUIRE.

No attempt to collect data on experience. - retrospective

# Pouwels

"The recently implemented strategy of PLOS Medicine is an interesting solution [17]. Requiring authors to submit a checklist with sufficient text excerpted from the manuscript to explain how they accomplished all applicable items [17] may results in better adherence to the guideline."

Retrospective

# Bastuji-garin



# barnes

# BMJ Open

# Hopewell - WebCONSORT

Not based on any evidence. 

"However, proliferation of these extensions makes their application difficult for a specific trial as it involves combining items from the main CONSORT checklist with those from one or more extensions. This could be cumbersome and difficult to apply in practice and so CONSORT may have limited impact on the reporting quality of these trials. The objective of this study was to evaluate the impact of a simple web-based tool (called WebCONSORT, which incorporates the main CONSORT checklist and different CONSORT extensions) on the completeness of reporting of randomised trials published in biomedical journals. WebCONSORT allows authors to obtain a customised CONSORT checklist and flow diagram specific to their trial design and type of intervention. Our hypothesis was that this tool would allow optimal use of the CONSORT Statement and its extensions, thus leading to an improvement in the transparency of articles related to randomised trials."

Didn't collect any evidence about experience. 

Hypothesised reasons for failure:

* journals already endorsed CONSORT so maybe authors already believed they were complying (but low compliance doesn't support that)
* Customised checklists were very long. Could have been overwhelming. 
* No instructions on how to implement each item, so checklist info alone might not have been enough. 
* Might have been too late. The intervention happened at revision stage. Might be useful to intervene earlier - CobWEB? 

Did find evidence that editors struggle to identify study type. They had to exclude 39% of manuscripts because they were not RCTs, despite clear instructions given to editors and authors. 

Also found evidence that a quarter of authors selected inappropriate CONSORT extension or failed to select the correct one. 

