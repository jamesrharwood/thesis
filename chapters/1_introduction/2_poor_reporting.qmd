## The problem of poor reporting in health research

Facing an uncertain choice during treatment for multiple myeloma, epidemiologist Alessandro Liberati wrote "Why was I forced to make my decision knowing that information was somewhere but not available?"[@liberatiUnfinishedTripUncertainties2004]. When I started my DPhil governments may have been asking the same question. The world was in the grip of COVID-19 and decision makers were wading through a deluge of patchy research articles missing important information @ziemannPoorReportingQuality2022. In the years since, friends and family have had to make treatment decisions where the evidence is of "low certainty" because key details are missing from research articles.

A selfish silver-lining of these tumultuous years was that my family and friends finally understood the problem my thesis addresses: when medical researchers inadequately describe what they did or what they found, other people cannot understand, replicate, or use their work. Research costs huge amounts of time, money, and effort, and the written account is typically its sole legacy. When details are omitted they are lost. The remaining gaps are sources of doubt; are they accidental omissions? Oversights? Cover-ups? Whatever their source, the gaps fragment the full picture, and the potential value to patients drains away.

Early concern over reporting quality often came from frustrated reviewers unable to find the data they needed within research reports. For example, in 1963, Glick @glickInadequaciesReportingClinical1963 found many reports of psychiatric therapy used ambiguous descriptions of treatment duration like "at least two months" or "from one to several months". These descriptions were so vague they were "unsuitable for comparative purposes". More recently, Dechartres found systematic reviewers could not judge the potential for bias in a third of clinical trials because of poorly described methods, thereby limiting the confidence of conclusions @dechartresEvolutionPoorReporting2017.

Reviewers are not the only people affected. When interventions are poorly described, researchers cannot appraise or repeat research. Carp @carpSecretLivesExperiments2012 described how a third of 241 brain imaging studies missed information necessary to interpret and repeat them, like the number of examinations, examination duration, and the resolution of images. Doctors and service providers also need clear descriptions to replicate interventions @glasziouWhatMissingDescriptions2008. As Feinstein noted in 1974 @feinsteinClinicalBiostatisticsXXV1974, it is difficult enough for a clinician to understand the value of unfamiliar procedure, but "it is much more difficult when he is not told what that procedure was". For example, Davidson et al. @davidsonExerciseInterventionsLow2021 reviewed trials describing exercise interventions for chronic back pain and found authors often did not describe interventions sufficiently for other healthcare providers to copy them.

These are a mere handful of many studies documenting poor reporting in medical literature. A 2023 systematic review found 148 published between 2020-2022 alone @santoMethodsResultsStudies2023. All investigated reporting quality in different medical research disciplines, and *almost* all concluded reporting was sub-optimal. Hence, poor reporting is a long-standing problem, plagues all disciplines, devalues research, and derails the uptake of new knowledge into clinical practice.