## The problem of poor reporting in health research

Facing an uncertain choice during treatment for multiple myeloma, epidemiologist Alessandro Liberati wrote "Why was I forced to make my decision knowing that information was somewhere but not available?". We may all ask this question at some point in our lives. 

When I started my PhD, the world was in the grip of COVID-19. A deluge of research ensued #REF, but because much of it was poorly reported #REF, governments and clinicians had to make decisions without inaccessible information. In the years since, my loved ones have had to make treatment decisions where the evidence is of "low certainty" because key details are missing from research articles. 

A selfish silver-lining of these tumultuous years is that my family and friends finally understand the problem my PhD thesis tries to address: when medical researchers inadequately describe what they did or what they found, other people cannot understand, replicate, or use their work. Research costs huge amounts of time, money, and effort, and the written account is typically its sole legacy. When details are omitted they are lost. The remaining gaps are sources of doubt; are they accidental omissions? Oversights? Cover-ups? Whatever their source, the gaps fragment the full picture, and the potential value to patients drains away. 

Early concern over reporting quality often came from frustrated reviewers unable to could the data they needed within research reports. For example, in 1963 Glick @glickInadequaciesReportingClinical1963 found many reports of psychiatric therapy used ambiguous descriptions of treatment duration like "at least two months" or "from one to several months". These descriptions were so vague they were "unsuitable for comparative purposes". More recently, Dechartes found systematic reviewers could not judge the potential for bias in a third of trials because of poorly described methods, thereby limiting the confidence of conclusions @dechartresEvolutionPoorReporting2017. 

Reviewers are not the only people affected. When interventions are poorly described, researchers cannot appraise or repeat research. Carp @carpSecretLivesExperiments2012 described how a third of 241 brain imaging studies missed information necessary to interpret and repeat them, like the number of examinations, examination duration, and the resolution of images. Doctors and service providers also need clear descriptions to replicate interventions @glasziouWhatMissingDescriptions2008. As Feinstein noted in 1974 @feinsteinClinicalBiostatisticsXXV1974, it is difficult enough for a clinician to understand the value of unfamiliar procedure, but "it is much more difficult when he is not told what that procedure was". For example, Davidson et al. @davidsonExerciseInterventionsLow2021 reviewed trials describing exercise interventions for chronic back pain and found authors often did not describe their materials, infrastructure, or training, making it impossible for other healthcare providers to offer the interventions themselves.

These are just some of the many studies documenting poor reporting in medical literature. A 2023 systematic review found 148 published between 2020-2022 alone @santoMethodsResultsStudies2023. All investigated reporting quality in different medical research disciplines, and _almost_ all concluded reporting was sub-optimal. Hence, poor reporting plagues all disciplines, devalues research, and derails the uptake of new knowledge into clinical practice.