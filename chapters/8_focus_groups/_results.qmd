## Results

### Units of study

I held {{< var counts.focus_groups >}} focus groups involving {{< var counts.participants >}} participants in total. Participants included guideline developers (n={{< var counts.guideline_developers >}}), publishing professionals (n={{< var counts.publishers >}}), and academics that study reporting guidelines (n={{< var counts.academics >}}). Although I had intended to include 4 or 5 participants per focus group, in practice it was difficult to coordinate participants across time zones, and so sessions only had 2 or 3 participants. 

Because I invited people to share the invitation I have no way of knowing my recruitment rate. Of the {{< var counts.invitations.total >}} invitations that I sent in total, {{< var counts.invitations.no_response >}} received no response. Of the {{< var counts.invitations.guideline_groups.total >}} guideline groups I invited, {{< var counts.invitations.guideline_groups.attended >}} took part. Of the remainder, {{< var counts.invitations.guideline_groups.no_time >}} guideline groups wanted to participate but were unable to coordinate a time, {{< var counts.invitations.guideline_groups.no_response >}} groups did not respond, and {{< var counts.invitations.guideline_groups.denied >}} group refused to participate; they felt that their guideline didn't need updating because it was highly cited. 

Before the focus groups, my workshops with EQUATOR had generated a list of {{< var counts.EQUATOR_ideas >}} ideas, which formed the initial "ideas document" presented to the first focus group. After the final focus group, participants had extended this list further to include {{< var counts.sub_ideas_pre_jh >}} ideas to address {{< var counts.barriers >}} barriers. Participants identified {{< var counts.stakeholders >}} stakeholders that could enact these ideas including {{< var descriptions.stakeholders >}}. I grouped these ideas into {{< var counts.ideas >}} broader ideas, which I categorised according to whether they could be considered {{< var descriptions.stages >}}. 

In the summary below I have occasionally mentioned which stakeholder group an idea came from, but only when I felt like it added useful context. I have chosen not to label the rest for three reasons. Firstly, stakeholders were all editing the same file, so some ideas would be revisited multiple times by different stakeholders who would build upon the thoughts of previous contributors, editing and extending ideas. Consequently, it wasn't always possible to definitively say _who_ any particular idea came from, as it may have been the product of multiple stakeholders. Secondly, just because a stakeholder didn't edit an idea in the document didn't mean that the idea hadn't also occurred to them. Hence allocating an idea to a stakeholder just because they were the one that wrote it down may be misleading. Thirdly, I didn't consider labelling the  _origin_ of an idea to be useful because I didn't see it as an indication of that idea's _quality_; to the contrary, I had explicitly encouraged participants not to worry about whether an idea was "good".

### Synthesis and summary

Here I describe the aggregated ideas. I use the term "stakeholders" instead of "participants" to clarify that ideas came from the focus group participants _and_ the workshop participants. 

#### {{< var stages.planning >}}

##### Create reporting guidance for protocols and applications

Stakeholders suggested "developing [reporting guidance] for protocols", funding, and ethics applications as a way to encourage authors to consult reporting guidance earlier in their work when they are more likely to have the time, motivation, and ability to reflect and act on it.

##### {{< var IFs.avoid-proliferation >}}

"We need fewer, better, reporting guidelines" wrote one stakeholder, when discussing how authors may struggle to identify which reporting guidelines apply to their work. 

Acknowledging that reporting guideline developers may duplicate each other's work unwittingly, stakeholders wrote that developers should consult EQUATOR's register of reporting guidelines under development before creating a new guideline. Stakeholders noted that "EQUATOR cannot prevent guideline developers from creating duplicate guidelines" but could "improve the registration process for reporting guidelines that are under development", better "highlight [reporting guidelines] that are under development in the main search results", and could "create options and instructions to encourage developers to extend existing guidance instead of duplicating. This could go in the new guidance for guideline developers".

Stakeholders had ideas of how this "extend"ing could be done. They suggested that developers could tailor existing guidance to a particular niche by making different "versions" or "extensions" of existing guidance "e.g., STROBE split into STROBE Cohort, Case-control etc". If only a few items need to be edited or added, stakeholders suggested creating "modular" guidance instead of duplicating an entire guideline. Stakeholders spoke of modules in two different ways. Firstly, new reporting guidelines can be created to substitute for particular items in existing reporting guidelines. Stakeholders named TIDIER as an example of this strategy, which can be substituted for item 5 in CONSORT. Stakeholders identified a second kind of modularity in the JARS guidelines, where a general reporting guideline covering all quantitative psychology research can be mixed-and-matched by modules for specific designs (non-experimental and experimental designs, with or without random assignment, or special modules for longitudinal, n-of-1, or replication studies @appelbaumJournalArticleReporting2018).

When discussing how modules or extensions could be "harmonized" so that they "speak to another", participants suggested resources could have compatible structure, and should not "use different wording for what is essentially the same item". Participant's recommendation to "use similar terminology [across] related guidelines" extended to the title; STROBE-nut, STROBE-ME and STROBE-RDS are more readily identifiable as STROBE extensions than STREGA, ROSES-I, or STROME-ID are. Naming can also indicate when a guideline has been revised: "ARRIVE 2.0 is recognisable as a replacement of ARRIVE", whereas "TIDIER Placebo appears to be an extension but should be called TIDIER 2.0".

##### {{< var IFs.avoid-prescribing-structure >}}

Stakeholders suggested that "[reporting] guidelines should avoid prescribing structure as [it] may clash with journal guidelines". A good example of a structure clash is abstract subheadings; most journals have strict requirements about whether abstracts should have subheadings and what those headings should be. Authors can struggle if reporting guidelines suggest an alternative structure.

##### {{< var IFs.design-agnostic >}}

Stakeholders discussed how _designing_ research is a separate task to _reporting_ it, and that many authors will only encounter reporting guidelines _after_ the manuscript has been written, at which point design advice is less useful. 

Nevertheless, stakeholders cited multiple reasons for including design opinions in reporting guidance. Some suggested it should be included so that authors can "learn for next time", and others wrote that consequences of design choices justify why an item was important to report, but acknowledged that that justifying items in this way can be problematic if developers do not consider all contexts or study types in which their guidance may be used.

Some participants argued that design advice could be removed from reporting guidelines entirely. This was proposed as a solution when considering how authors may feel afraid to report transparently if what they did goes against the design recommendation, or may feel restricted if forced to use a reporting guideline that prescribes design choices. 

Instead, developers could encourage authors to "explain reasons for methods choices, [which may] be legitimate", noting that "the consequence of not choosing one [design] option over another, even if the choice is a rarely used option, may not have major consequence on the results of the study". One stakeholder wrote that authors may feel reassured if told that "editors and peer-reviewers may not judge as harshly when they understand the rationale for the choice". Stakeholders wrote that developers should "encourage transparent reporting over and above good design", and that authors could be encouraged to "describe what they did in plain language to make it clear - if what they did doesn't quite fit with standard terminology (e.g., if they didn't really do theoretical sampling or aren't sure if they did theoretical sampling) then just describe what they did, how they made sampling decisions".

Discussions about removing design advice also arose when considering how including design advice elongates guidance, potentially deterring authors from reading it. To solve this, stakeholders suggested reporting guidelines could link to design resources "elsewhere". For example, if reporting guidance were presented on a website, authors could be given options to "display or hide" design advice by choice, or depending on whether the author was "designing [research], applying for funding, or drafting" a manuscript.

##### {{< var IFs.item-content >}}

Many barriers prompted stakeholders to suggest that specific content should be included for every reporting item.

Firstly, stakeholders noted that authors need to know what to write, and that a brief description could go in checklists and a longer description in the full guidance. Stakeholders suggested this description should include what to write if they didn't or couldn't do something to make it "easy for researchers to report things they are embarrassed about". In these instances, developers could suggest authors "explain reasons" for their choices or "consider the item in their discussion section as a possible limitation" if necessary. Stakeholders also wrote that developers could suggest what to write when an item doesn't apply.

Stakeholders suggested explaining "why [an item] is important and who it is important to" as this isn't always obvious to authors. To make guidelines faster to use, stakeholders suggested indicating which items are most important, perhaps "prioritise[ing] certain items as essential vs. recommended, like ARRIVE 2.0 essential 10" and indicating conditions that make items less or more important, including circumstances that make the item non-applicable.

To help authors who want to keep writing concise or need to reduce word counts, stakeholders suggested advising "when an item can be put into a table, figure, box, supplement, or appendix etc" and to "explain the pros and cons of different options e.g., whether content will be peer reviewed or indexed" by search tools.

Many stakeholders suggested including examples to help authors understand and apply guidance. These examples could include both "good and bad reporting" with an explanation of "how [bad reporting] could be improved". To help authors who are afraid to transparently report limitations, stakeholders suggested including examples of imperfect research that is perfectly-reported. Examples could also include "reporting in different contexts", from different disciplines,  "in multiple languages", and concise reporting e.g., reporting "TIDIER items nicely in a table".

Because examples from the published literature can be "difficult to [...] find and list", stakeholders suggested that examples could be "real or generated" by developers. Examples should be "easy to find" from within the guidance resources. Others suggested a searchable "bank" of examples, or ways to showcase "exemplar papers (e.g., badges)".

Finally, stakeholders discussed the pros and cons of including item-specific design advice, procedural instructions, and appraisal advice, and the different ways of doing it (see [{{< var IFs.design-agnostic >}}](@sec-{{< var IFSecs.design-agnostic >}})).

##### {{< var IFs.rg-introductions >}}

Stakeholders identified that many of the barriers they discussed could be addressed by editing the text that authors might read before using a guideline or checklist. 

For example, stakeholders suggested that reporting guidelines and resources should "clearly state what kind of research the guidance applies to" when considering how authors may struggle to identify which reporting guideline they should use. Additionally, stakeholders suggested guidelines could "point researchers to other guidelines if more relevant, perhaps using 'if, then' rules e.g., 'if you did X then use Y instead of this guideline'". If no better guideline exists for a particular type of study, stakeholders suggested to "warn the user that they can still use this guideline but that they may need to ignore certain questions e.g., 'This guideline is for studies that did X. You can still use it if you did Y, but you will need to ignore items 4, 6, and 8-10'".

To ensure that a reporting guideline for writing manuscripts can also be used for writing protocols, developers could specify "which items need to be considered at protocol/planning stage, and which at results reporting stage." 

Stakeholders warned that developers should be mindful when using words like  _standard_ instead of _guideline_ when introducing a reporting guideline, as these words may influence how prescriptive the user expects the resource to be. In choosing their wording, stakeholders suggested developers should be honest and clear about a guideline's "aim". Developers could also "be clear about what reporting guidelines _are not_". For instance, "when they are not design guidelines or critical appraisal tools" this could be specified and authors could be directed to other tools instead.

Noting that it might not be obvious how or when to use guidance, participants suggested being explicit about this. For example, "tell authors that they don’t need to fill out templates [or checklists] sequentially but can use an order that matches their workflow or decision making. Put this instruction on the template, checklists, and other tools. Example from PRISMA – population and subgroup items are separated in the checklist but go together when thinking/making decisions.". Similarly, authors could benefit from explicit suggestions of how to use reporting guidelines as a team, perhaps by asking "their co-researchers to check their reporting". Finally, stakeholders suggested telling authors how much time the guideline is expected to take them to read and use, why it can be trusted, and where they can read about its development.

##### {{< var IFs.keep-short >}}

"Make guidance shorter" wrote one stakeholder, and "Make checklists shorter", wrote another, when considering how "guideline length [...] may put researchers off" as "long guidelines appear more complex and time consuming" and can challenge word limits.

One stakeholder posited that guidelines could be shorter if developers were "realistic about what they ask for". Another challenged developers to "try using a guideline from start to finish and see how the manuscript ends up". Others wrote that guidelines could be shortened by linking out to content that wasn't directly related to reporting, like design or appraisal advice (see [{{< var IFs.design-agnostic >}}](@sec-{{< var IFSecs.design-agnostic >}})). Guidelines that are "very long or [have] lots of optional items" could be split into multiple versions (see STROBE as an example in [{{< var IFs.avoid-proliferation >}}](@sec-{{< var IFSecs.avoid-proliferation >}})).

Others suggested presenting guidance online with non-essential content collapsed so that guidance appeared short but authors could choose to "display or hide" content. Stakeholders noted that "itemisation can make guidance more digestible, but can also make it harder to get the bigger picture" and makes text appear longer.

#### {{< var stages.development >}}

##### {{< var IFs.ready-to-use >}}

Stakeholders suggested that resources should be in ready-to-use formats. For instance, "checklists should be editable (not PDFs)".

##### {{< var IFs.easy-understand >}}

"Make guidance easier to understand" was written as a solution to help authors who misinterpret, or can't understand, guidance. Stakeholders suggested developers could "make guidance as 'plain language' as possible" or "create plain language versions of existing guidance", whilst being "mindful of language that may appear patronizing".

Stakeholders suggested defining "key words or phrases in a glossary or tooltips", using consistent terms across related resources, translating guidelines and examples, and ensuring these translations are easy to find by making them "searchable", "linked properly" to each other, and "more evident on [the] EQUATOR site".

Stakeholders recognised a need to collect and respond to feedback from "international researchers" representative of the user base across disciplines and institutions, and that this could be sought when developing guidance to "test" it, but also on an ongoing basis to "continually revisit the items in the guidelines that may be confusing or difficult to implement". As an example, one guideline developer contributed that collecting feedback had led them to remove "the word 'context' because users struggled to understand it".

##### {{< var IFs.persuade >}}

When discussing how authors feel about reporting guidelines and checklists, stakeholders reflected on how the wording and presentation of resources can influence authors' perceptions of it.

Stakeholders noted that a poorly formatted checklist, lacking "visual appeal/graphic design", can "appear outdated" or "larger than it is". Stakeholders suggested that developers could use design to "foster feelings of simplicity", and "engage graphic designers" if necessary.

Reassurance seemed especially important to stakeholders when considering how to motivate authors to transparently report items that aren't perfect. Stakeholders suggested that developers could use language and tone of voice to "foster a feeling of confidence, not judgement", perhaps reminding "researchers that all research has limitations". Stakeholders also wrote that reassurance could also be given by including notes aimed at reviewers, and cited JARS as an example "which explains to reviewers why an author may make certain choices", thereby educating reviewers whilst reassuring authors that they won't be penalised for transparency. Stakeholders suggested rewording text and tone of voice to make reporting guidelines and checklists "appear less like 'red tape'", and to reassure authors that "reporting guidelines are just that: guidelines!". 

##### {{< var IFs.create-tools >}}

Stakeholders noted that checklists may be easier to use if they are editable (see [{{< var IFs.ready-to-use >}}](@sec-{{< var IFSecs.ready-to-use >}})), and if authors could complete them with "the relevant text, rather than [the] page/section number" which can be frustrating to keep updated. Although one stakeholder, a publisher, noted that checklists completed with text are difficult to double check, and therefore it would be most useful to include the text _and_ the page number.

To aid writing, stakeholders suggested "templates for drafting" manuscripts, interactive forms and "writing tools (e.g., COBWEB)", "tools for creating figures and tables like PRISMA's flowchart generator", and tools for generating text, like TIDIER's tool for generating intervention description ([#REF](http://www.tidierguide.org/#/author-tool)). However, one stakeholder warned that these kinds of structured writing "provide opportunities for inclusion [of reporting items] but there is always the risk that they exclude more [important items] that are outside the boundaries of the template".

To encourage authors to consider reporting guidance earlier in their research, stakeholders considered to-do lists with items "in the order they are done", or "embed[ing] items into data collection tools" like software for systematic reviewers.

To help reviewers check reporting, stakeholders suggested creating "tools for co-researchers to check each others' work", creating extra guidance for peer reviewers, providing text that can be pasted in reviewer feedback forms to "request additional information" for poorly reported items, or even building a "reviewer tool that generates a report".

Stakeholders noted that tools should presented in ways that "better differentiate" how and when they should be used "e.g., resources for writing vs. checking vs. reviewing".

##### {{< var IFs.findable-resources >}}

Stakeholders had ideas for how to help authors discover and find  resources. Stakeholders wrote about hyperlinks being an important way for authors to discover related guidelines and tools. These could be "horizontal links between related guidelines" and between guideline "documents and tools" like checklists. All resources should "link to one another", ideally "item by item" so that checklist items could link directly to the relevant section of full guidance. Stakeholders noted that hyperlinks can become out of date, and so stakeholders should "fix broken links".

Stakeholders also wrote that resources could be hosted on "a convenient place, such as a unified website". EQUATOR's website is one such place, and participants suggested making it "easier to navigate" and its "search tool more prominent and easier to use". Although some authors will use such search tools, stakeholders recognised that those who browse may benefit from "curated" collections of reporting guidelines or a "manageable list of related, commonly used guidelines". As an example, an author writing a review article may be helped by a page listing "PRISMA, MOOSE, ENTREQ, PRISMA-SRc etc." and that "this page could be kept up to date as guidelines are revised". Another stakeholder (a publisher) warned, however, that journals may not want to link to these pages if the collection has "a much broader scope" and includes guidelines that the journal doesn't endorse.

When discussing how to help authors who are less familiar with study designs, one stakeholder suggested creating "tools to help researchers identify study designs (e.g., a questionnaire)", and another, already familiar with such a tool previously developed by EQUATOR suggested it should "use plain language".

##### {{< var IFs.information-architecture >}}

Stakeholders acknowledged that authors' needs may differ between tasks (e.g., drafting an article vs demonstrating compliance), and that authors may use guidance in different ways; some will read the whole thing from start to finish, whilst others will dip in and out as-and-when they need. Consequently, stakeholders wrote that "having different options available that meet the needs of different users is vital" and that authors should be able to consult guidance in ways that "work for them".

One suggested way of doing this may be to "structure guidance using navigation menus and subheadings" so that "it is easy to find the information you need", making reporting guidelines faster to use and less overwhelming. Another noted that checklists can also be designed, citing TIDIER as "a nice example" that has  "integrated the intervention and placebo into one table" with the active intervention and placebo in adjacent columns.

Dynamically hiding and showing content was floated here again (see [{{< var IFs.keep-short >}}](@sec-{{< var IFSecs.keep-short >}})), with one stakeholder suggesting that users could "filter out" irrelevant content, to only see instructions for their task (e.g., planning, writing, reviewing) or specific to their study. This could be done with a "decision tree" or "branching questions" to determine specific features of the study ("e.g., a systematic review _with_ network meta-analysis _of_ individual participant data"). Answers to these questions could then be used to to "modify" items to create "personalised guidelines", or to generate a "customised reporting checklist" that includes all "main and relevant extension items".

Dynamic content was also seen as a favourable way to embed guideline extensions, with the aim of making them easier to discover without overwhelming the author. For example, noting that "some guidelines 'fit together'...e.g., PRISMA and PRISMA-Abstracts", stakeholders wrote that PRISMA-Abstracts could be "embedded" as collapsed content that interested authors could expand.

#### {{< var stages.dissemination >}}

##### {{< var IFs.value-statement >}}

When first introducing reporting guidelines stakeholders suggested telling authors what reporting guidelines are, "when and how best to use" them, and what benefits to expect. This information could go wherever authors are advised to use reporting guidelines (like like journal instruction pages, registries), EQUATOR's website, social media campaigns, at the start of the guidelines, and could go at the beginning of checklists too "in case people don't read the whole [guideline] paper". This introductory text could be "short, sweet, and to the point". Benefits could be even more prominent by putting them "in a box, or [by using] font or positioning".

<!-- #TODO: check that personal benefits are included elsewhere. E.g., Researchers report caring more about personal, immediate benefits compared to hypothetical benefits to others; More transparent reporting / structured reporting may lead to faster editorial processes as it becomes easy for peer reviewers and editors to review papers about their study, Provide statistics about processing times of articles that follow / don’t follow reporting standards. Emphasise to researchers that clear reporting will minimise the number of times others contact them for clarification -->

##### {{< var IFs.accessible >}}

Stakeholders wrote "Ensure guidance is open access" so that all authors can it. Stakeholders also noted that if guidance is published under a permissive license then others can reuse the content to extend the guidance or build new tools.

##### {{< var IFs.citation >}}

Displaying citation counts on the EQUATOR Network website (or other websites where authors search for reporting guidelines) was described as a way to "provide social proof" and convince authors that guidelines are credible.

To generate these citations, stakeholders suggested explicitly asking "researchers to cite the guideline they used". Stakeholders wrote that if an author cites a guideline they have used, then readers may discover the guideline from that authors' article. 

##### {{< var IFs.testimonials >}}

Stakeholders suggested providing "testimonials" as a way to tackle a few different barriers using education and persuasion. Stakeholders suggested providing "quotes from authors/researchers who felt that reporting guidelines helped their work and who have had positive experiences" such as making "writing easier" or helping "with co-authorship communications".  Stakeholders proposed that testimonials could bring benefits to life, thereby making them more believable.

To make authors care more about research waste caused by poor reporting, stakeholders suggested testimonials from "research consumers for whom an item is important", or quotes that illustrate "how detrimental poor reporting is for end users".

Stakeholders wrote that testimonials from decision makers (like editors, reviewers, and grant-givers) could communicate their "preference for transparent reporting" and convince authors that reporting will be checked. If these testimonials conveyed that transparency is valued above perfectionism, participants suggested this could reassure authors. Stakeholders also suggested collecting positive testimonials from such "nervous researchers".

Finally, stakeholders suggested collecting testimonials from researchers "with a range of experience", including "experienced researchers who have benefited by changing their practices". Diverse case studies would help engage a diverse user base, and challenge assumptions that reporting guidelines are too patronizing for experienced researchers or too complicated for inexperienced ones.

#### {{< var stages.ongoing >}}

##### {{< var IFs.budget-and-fund-reporting >}}

Stakeholders noted that "researchers need budget to allocate time to writing" and that "funders could encourage proper financial/time budgeting for writing", as could research supervisors.

##### {{< var IFs.create-rewards >}}

Stakeholders suggested "offer[ing] some sort of tangible reward/benefit" to motivate guideline use, creating new rewards when necessary. Ideas included "publishers offering a fast-track review/discount", "badges on published articles" or platforms "like publons", or "a certificate after completing training".

##### {{< var IFs.create-spaces >}}

Multiple barriers lead stakeholders to suggest "create[ing] spaces for researchers to connect with other researchers to celebrate and share experiences". These spaces could include "forums, meetings, tea clubs, [and] clinics both in real life and virtual". Such spaces could help authors solicit help and could act as social proof, as seeing "others using and talking about the guidance" may be motivational.

Online discussion spaces were also considered a useful way to gather feedback from users directly (by asking for it) and indirectly (by monitoring discussions). Stakeholders wrote that feedback channels "could be useful to guideline developers", and may also "cultivate a feeling of community ownership" by "communicating an invitational attitude", thereby making guidelines appear less bureaucratic.

<!-- #TODO: make sure consulting user groups, and SQUIRE quotes included in updating guidance section. "

"How can we enable users to give feedback on guidance?
Researchers have opinions on how the guidance could be improved including how to make it clearer, and whether items should be rearranged, separated, combined, added or removed. 
This information could be useful to guideline developers"
"Allow researchers to give user feedback and ask questions
"Developers could consult different user groups when creating guidance to make sure all users understand it as intended"
"Engage as many health professions as possible to use and share examples of guidelines
"Provide ways for researchers to give feedback to guideline developers"
"Make it easier for guideline developers to update guidance"
"Minor updates could be made without publishing a new article"
"Engage as many health professions and editors as possible"

Communicating an invitational attitude among colleagues in various settings is powerful as an extender of the user community"
"Downregulating hierarchy is useful – nationally, gender, issues, professional disciplines"
"Allow researchers to give feedback on guidelines to cultivate a feeling of community ownership" -->

##### {{< var IFs.early-acquisition >}}

Stakeholders thought of ways to "try and shift the time at which researchers discover or use guidelines", hypothesising that "it’s more likely that guidelines will save them time" if used earlier or "at the right time" and "not just upon submission".

Most simply, stakeholders suggested “telling” or “encouraging” authors to use reporting guidelines for planning or drafting research (and not just for demonstrating compliance upon submission). Building upon this, stakeholders suggested organising the EQUATOR Network website to make it obvious which stages of work resources can be used for.

Stakeholders suggested "including [reporting guidelines] in the university teaching and training curriculum and text books" so that students learn about them before running or writing up their first study.

Stakeholders suggested creating reporting guidance for early research outputs like funding applications and protocols (as previously described in [{{< var IFs.create-early-guidance >}}](@sec-{{< var IFSecs.create-early-guidance >}})), and advertising resources through funders, ethics committees, and writing training programmes.

When considering whether authors may need reminders to use a reporting guideline for their next study, stakeholders suggested publishers and EQUATOR could use "email reminders" or strategies used by e-commerce sites "like when you buy something from an online business...then they work hard to gain your custom again".

##### {{< var IFs.endorse-enforce >}}

Stakeholders suggested "encouraging more journals to endorse guidelines" and drew a distinction between endorsing reporting guidelines and promoting them on a website, social media, or email (see [{{< var IFs.promote >}}](@sec-{{< IFSecs.promote >}})). Endorsement was described as a long term commitment to recommend or encourage guideline use, requiring buy-in from organisational leaders, and possibly changes to policies, instructions, infrastructure, and workflows. Promotion, conversely, was described as ephemeral and does not require organisational changes.

Stakeholders drew another distinction between endorsement and enforcement, whereby enforcement meant reporting guidelines are "a requirement" or "condition". Enforcement was further divided into enforcing checklist completion or, noting that checklists may not always accurately reflect manuscript content, checking text for adherence to guidance.

When considering _who_ could enforce guidelines, stakeholders noted that reporting guidelines could be "a requirement for publication", "for registration (where applicable) (e.g., clinical trial registries, PROSPERO)", or when submitting conference abstracts. "Ethics committees and funding organisations" could require that adhere to guidelines, "for example, completion of SPIRIT for clinical trial submissions", or to declare that they will use a guideline when writing their results. To facilitate enforcement, stakeholders suggested that the software academics use to provide funders with updates could ask for completed checklists. One stakeholder suggested that reporting guideline adherence should be a condition of university employment and that a "digital dashboard [may] help audit[ing] and monitoring". Noting that enforcement requires resources, stakeholders suggested to "focus on main RGs and being compliant with them".

##### {{< var IFs.evidence-benefits >}}

Stakeholders suggested that benefits may be more believable if there were evidenced. This could be "evidence that [reporting guidelines] improve the completeness and transparency of the output". For quantifiable benefits, the suggestion was to collect and report data on “acceptance rates, publishing speed, writing speed”. One stakeholder posited that "more transparent reporting / structured reporting may lead to faster editorial processes as it becomes easy for peer reviewers and editors to review papers about their study" and another suggested to "provide statistics about processing times of articles that follow / don’t follow reporting standards" would help evidence this claim and "emphasise to researchers that clear reporting will minimise the number of times others contact them for clarification". However, some stakeholders were sceptical whether data on acceptance rates would show any benefit at all: "Likelihood of being accepted might not be heavily influenced – bad research well reported would still be rejected".

For experiential benefits that cannot be quantified, stakeholders suggested providing case studies or testimonials (see [{{< var IFs.testimonials >}}](@sec-{{< var IFSecs.testimonials >}})).

##### {{< var IFs.apparent-priority >}}

When a journal endorses or enforces reporting guidelines, a few stakeholders suggested making reporting guidelines more prominent within the journal's workflow to make them appear more important. Notes included that "reporting guidelines could be more prominent on journal author guideline pages", or that "if the journal uses any sort of structured peer review (e.g., specific questions related to methodology) to tell authors this explicitly [on author guideline pages and within review feedback] and link it to the reporting guideline content". A third suggestion was that "when journals ‘stitch’ or ‘build’ together the manuscript pdf (including cover letter, manuscript main text, appendices, etc.), prioritise the reporting guideline or move it earlier in the pdf".

However, a few stakeholders (publishers) warned that prioritising guidelines on author instruction pages "is complicated as these [pages] already have to do a lot", although guidelines could be more prominent if the pages "were better organised and/or filterable".

##### {{< var IFs.promote >}}

Stakeholders noted may bodies that could help spread the word that reporting guidelines exist. For example, "professional societies" could "advertise" reporting guidelines, despite not having a role in the funding, regulation or dissemination of research.

Promotion could occur online. Most obviously, on stakeholder guidance web pages. "Email campaigns, social media, blogs" could be useful channels to "share and connect with others [and] drive traffic to guideline website[s]", but "these require time and energy" from the reporting guideline community to set up and manage.

"Conferences and workshops at institutions" were cited as channels to promote reporting guideline offline, as were " seminars, webinars, and presentations" especially in "hard to reach countries/fields". These events were described as useful ways "to assist in the interpretation and use of the guidelines" and could be opportunities for "universities/funders/journals [to speak] together about the importance of reporting guidelines".

To reach students, participants suggested that universities could include reporting guidelines in their curricula, learning materials, or through reporting champions (see [{{< var IFs.reporting-champions >}}](@sec-{{< var IFSecs.reporting-champions >}})).

Stakeholders wrote that "promotion can begin before a guideline has been published so that researchers know about guidelines being developed" and suggested "the provision of a time buffer/phasing period for updating new reporting guidelines which would allow researchers to have information about these new guidelines".

##### {{< var IFs.reporting-champions >}}

Stakeholders wrote that publishers, universities, funders, and ethics committees could have members to promote and facilitate the usage of reporting guidelines, centring on the terms "champions" and "EQUATOR ambassadors". Within publishers, funders, or ethics board, a champion's responsibility may be to "expand knowledge/awareness of guidelines". Within institutions, champions could also "help researchers" by "providing feedback on writing" and that ECRs may feel most comfortable talking with a champion from "an accessible level (e.g., post-doc, library staff)". This could follow a local network model (UKRN was cited as an example) with EQUATOR as the central organiser, and could utilize existing reproducibility networks.

##### {{< var IFs.support >}}

Stakeholders proposed additional teaching as a way to promote reporting guidelines, make them easier to use, and a way to communicate the impacts of poor reporting. Education and training could be general (EQUATOR's publication school was cited as an example) of could be "guideline-specific", and could be delivered in person or online, as courses, videos, or text.

In addition to learning about a particular guideline, stakeholders suggested that students could learn about "writing as a process" and "workflows for documenting and communicating research". This was considered useful as "researchers don’t necessarily understand that reporting is a stage in the research process". Curricula could include "methods studies that indicate the research waste" to teach students why reporting matters, or students could learn for themselves by attempting "to replicate a study or do a systematic review to discover how poorly research is currently reported".

To gain experience in using reporting guidelines, stakeholders suggested students could develop "research protocols (as Bachelor or Master Theses) using reporting guidelines" and that these could "be assessed based on the compliance with the appropriate reporting guideline" in addition to "other criteria more related with methodology". To make this easier, stakeholders suggested structuring courses around reporting guideline items "for example: a course on [randomized controlled trials] covering every single SPIRIT or CONSORT item".

<!-- #TODO consider moving "understanding that reporting is a stage of work" to the budgeting section? -->

##### {{< var IFs.updating >}}

Stakeholders acknowledged that "researchers have opinions on how the guidance could be improved including how to make it clearer, and whether items should be rearranged, separated, combined, added or removed" and that "this information could be useful to guideline developers". Some stakeholders went further, expressing that guidance and websites should be updated "in response to user feedback or changes in the field". Others suggested that "developers could consult different user groups when creating guidance" and "engage as many health professions as possible" so that "professional cultural issues can be usefully accommodated."

However, stakeholders were not forthcoming on how to go about gathering this feedback. One wrote "provide ways for researchers to give feedback to guideline developers" without suggesting any ways to do this. Another simply asked "how can we enable users to give feedback on guidance?". Many guideline developers noted that they required access to extra funding to evaluate, refine, and update their resources. One developer suggested that "minor updates could be made without publishing a new article" if the guidance were disseminated on a website. 
