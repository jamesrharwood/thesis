### Discussion

The aims of this chapter were to create an intervention component table by drawing on the results of all previous chapters, and to turn these components into a prototype ready to test amongst authors. The intervention component table brings together the outputs of all of my previous thesis chapters and links them together; each component comes from an idea (chapter {{< var chapters.focus-groups >}}), addresses one or more barriers (chapters {{< var chapters.synthesis >}}-{{< var chapters.web-audit >}}), using intervention options ranked favourably by EQUATOR staff (chapter {{< var chapters.workshops >}}). My design process relied on this table and I used it again in my next chapter as an analysis framework. Hence this table, although relegated to the appendix because of its size, is a focal point for my thesis: it crystallises all preceding chapters, and formed the basis for all of my subsequent work.

The table includes components derived from all ideas pursuant to the intervention options EQUATOR staff and I prioritised in our workshops. Because I filtered out ideas _not_ in line with these priorities, the list is not exhaustive. Stakeholders using the same set of initial ideas would create different components because of their different priorities and implementation opportunities. For example, a funder may have generated more components related to reporting guidance for applications or protocols, or relating to their application criteria and submission systems. Stakeholders with the power to grant approval (for funding/ethics/publication) may have components related to enforcement. Consequently, although I hope this list will help readers understand the intervention changes I have made and why I have made them, I would encourage other intervention designers to go through this process themselves instead of using this list verbatim.

Throughout the table I have drawn comparisons between the proposed components and existing reality. These comparisons are vague; I use terms like "some" or "rarely". Where possible, I refer to images or examples. Some examples came from my qualitative synthesis (chapter {{< var chapters.synthesis >}}), others came arose organically in my workshops (chapter {{< var chapters.workshops >}}) when participants shared long-standing frustrations with the website or guidelines. Other times, after discussing a barrier or idea, we would look at a few guidelines to see how things are done currently. So this comparison was ad-hoc, and I have included them only to provide context to the proposed changes. I considered making this comparison formal by systematically coding BCTs employed by EQUATOR's website and popular guidelines or by counting how frequently intervention components appear currently. Ultimately, I decided this would not be helpful nor practical. With so many components and so many guidelines, this would have taken too long and I decided instead to prioritise building and testing a prototype. Secondly, I doubted this audit would influence my subsequent design, but would merely quantify how an redesigned intervention differs to the current set-up. Should such a comparison be useful, it would be more appropriate to do it after the redesigned intervention has been refined in response to user feedback, once its design is stabilised.

Using this intervention component table I have created functional prototypes of a redesigned reporting guidelines and the EQUATOR Network home page. Using a framework and a systematic method helped EQUATOR staff and I to make decisions based on evidence and theory, and to reduce the influence of our own subjectivity. Instead of relying on personal preference, we tried to ensure choices reflected the function we were trying to employ. For example, when choosing a background image, instead of asking "do you like this one?", the questions became "what feelings do you think this image conveys? Does it communicate simplicity?". Similarly, when participants disagreed, it was useful to delve into _why_. For example, when sketching layouts for the home page, some EQUATOR staff drew a single, prominent search button. Others drew a plethora of options like "view guidelines by speciality", "view guidelines A-Z". Discussion revealed that whereas some staff prefer to search directly for what they want with laser-like focus, others prefer to "explore", especially when they are not certain what they want or what the website is about. In this instance, the final design takes both use cases into account, but other times we resolved disagreement by referring to the intervention planning table or to similar websites. Hence using a framework and exploring disagreements as a group helped mitigate personal preferences. 

However, many decisions required a degree of subjectivity and, as lead researcher, designer, and developer, often these decisions landed on my shoulders. I tried to mitigate this by prioritizing other people's ideas over my own, and providing many opportunities for feedback. But the result undeniably has my “stamp”. If someone else had built it using the same table of intervention components then some things might be the same (like simplifying the user journey from 5 steps to 2, or the conventional home page layout) but other things would look different (like the choice of wording and images).

My design may have benefited from input from other stakeholders. I describe how I obtained feedback from authors in my next chapter, but I would have liked to include authors, publishers, funders, and other stakeholders from the start of the design process. If EQUATOR decide to take my designs forward, these consultations could still take place, but they were not feasible within the time constraints of my PhD. 

Input from user experience experts and graphic designers would also be useful. We found images to be a time consuming pain point. None of us had the skills to create professional looking graphics ourselves, and we found most free stock images were generic and did not communicate what we needed. 

My experience of working with SRQR's lead developer, Bridget, was was positive; she was supportive, liked the result, and she was interested when my process revealed gaps in SRQR item description. For example, often there was no guidance of what to write if a reporting item was not or could not be done. Some items did not explain why they are important and to whom. Filling these blanks required time and input that SRQR's development team were unable to give at present, and so I left these gaps unfilled for now. I anticipate other guidelines will have similar gaps. I hope other guideline developers will be as open-minded as Bridget was, but I expect others may feel less able or motivated to engage with a redesign, or may feel protective over their writing and resistant to change. 

In addition to filling these gaps, making my redesign "live" would require further technical work. Some of these tasks are administrative and have no behaviour change impact, but there are still {{< var counts.redesign.intervention-components.not_included_unique >}} intervention components outstanding. These components were too difficult or time consuming to include at this stage. For example, I intended to include more examples of reporting items. EQUATOR could add these intervention components at a later date. 

If EQUATOR chooses to adopt these changes and apply them to other guidelines, hundreds of thousands of authors would access these redesigned resources each year. These redesigned resources have potential to benefit authors directly, and also to help other stakeholders. For example, publishers may find enforcing guidelines easier if our redesigned resources prove more user friendly. Guideline developers will benefit from having a ready-to-use dissemination platform based on evidence, with built-in channels for collecting feedback from authors. This feedback may help guideline developers refine their resources further, and could act as evidence to support future funding applications. 


#STRETCH Describe how new site differs to GoodReports

<!-- #TODO: consider moving this paragraph to the design chapter? Initially, and probably because of my background in software development, I looked at user experience literature (e.g., @experienceGuideUsingUserExperience) but quickly realised that heuristics for creating easy-to-use websites don't really generalise to long-form instructional text. Thinking of comparable documents, I then looked into user testing instruction manuals (@mollerUsabilityTestingUser2013) but found that focusing on the document alone neglected other parts of the intervention, like the impact of journal policies or the behaviour of peer reviewers. A conversation with a professor of Human-Computer Interaction was interesting but focussing on information technology design seemed, again, to only cover part of the problem. -->

## Conclusions

By linking components with barriers, functions, and behaviour change techniques, I have justified components using evidence and described how they are theorized to work. This table will help other intervention developers and stakeholders understand what changes I have made and why. It also help me redesign the EQUATOR Network's home page and the SRQR guideline. These new designs include {{< var counts.redesign.intervention-components.included_unique  >}} of the {{< var counts.redesign.intervention-components.unique >}} intervention components I identified, and many of the remainder could be added later. Although my designs may have benefited from including other stakeholders, I explained how I facilitated open discussion, prioritised other's opinions, and used my intervention component table to make decisions. In the next chapter I explain how I refined these designs further by interviewing and observing authors.
