# Discussion

## Description of findings

<!-- 
* short summary of the main findings
* include some interpretation of the data in the context of previous findings, experiences, theory, or a guiding paradigm or approach.
* The discussion provides authors an opportunity to:
  * elaborate on their findings in relation to their research question(s) and study purpose(s);
  * connect their findings to prior empirical work, theories, and/or frameworks; 
  * and discuss implications:
    * describe how findings contribute to or advance the field
    * Implications may include transferability, or specifying the appropriate scope for generalization of the findings beyond the study (e.g., to other settings, populations, time periods, circumstances).
-->

### Summary of results

Participants identified {{< var counts.ideas >}} ideas employing all intervention functions. There were ideas to consider before, during, and after creating guidance, ideas to consider when writing the guidance down into a guideline, ideas about tools to help guidance application, ideas about ongoing activities to support or promote guidance use, and ideas about refining guidance over time in response to feedback. Many of these ideas could be enacted by guideline developers, publishers, and EQUATOR, but participants also saw opportunities for ethics committees, funders, academics, registries, and syllabus writers; stakeholders who are typically less frequently considered.

### Relation to study purpose

My objective was to identify to possible barriers, and I believed that including perspectives from a range of stakeholders would lead to more ideas. This seems to be the case: before this study, I had thought of {{< var counts.ideas_JH >}} ideas, EQUATOR staff then extended this to {{< var counts.ideas_EQUATOR >}}, still far below the number finally identified.
<!-- 
#TODO: results section doesn't link to IFs, although the data does. -->

My second aim was to garner stakeholder buy-in. I had a fair response rate from guideline groups and of those that did respond the reception was positive. Multiple guideline developers volunteered the guideline to be a "guinneapig" for my future work and expressed support for my work. Most developers were accepting of the barriers I presented. Only one developer expressed scepticism that reporting guidelines anything but perfect, and requested additional evidence of authors' negative experiences.

### Relations to previous findings
<!-- 
#TODO: some interpretation of the data in the context of previous findings, experiences, theory, or a guiding paradigm or approach?? Not sure about this -->
Where the barriers I identified previously offer explanations for why previous intervention studies (#REF) have had disappointing results, the ideas generated here provide hypotheses for how these interventions could be improved, and who could improve them.

### Benefits of the BCW

Using the intervention function and policy categories as a guide was an effective way to prompt discussion when participants ran out of ideas or repeatedly focussed on the same type of intervention that had already been documented.

The framework also helped guideline developers detach themselves from their creations and look at them objectively. This was a relief, as I had worried that developers may feel defensive or criticised. Keeping discussion focussed on guidelines _in general_ (not theirs in particular), having evidence for barriers, and including mixed perspectives within groups, also helped.

## Higher observations

Two questions divided participants more than others; whether reporting guidelines should be agnostic to design choices, and whether they should be viewed as rules (standards or requirements), or just a point in the right direction (guidance). The term 'guideline' is used ambiguously in scholarly publishing. NICE defines clinical guidelines as 'recommendations', which is in line with the Cambridge dictionary definition: "information intended to advise people on how something should be done". Thus guidelines "advise" or "recommend" but don't enforce or legislate. However, _journal author guidelines_ can be perceived as _rules_ that researchers have to adhere to if they want to publish, synonymous with _instructions_. Some participants were concerned that reporting guidelines may be perceived as rules, and that authors should be reassured that "guidelines are just that: guidelines!". Conversely, a few participants argued strongly that reporting guidelines should be seen as rules.

These divisions over whether guidelines are guides or rules, and whether they should include opinions about design, may reflect differences between the scope of reporting guidelines, and the perspective of developers. For example, some reporting guidelines cover specific types of study that are homogenous in design and approach (e.g. ontology and epistemology). In this instance, developers may feel comfortable making assumptions or recommendations about design choices, and may be more likely to consider guidelines as standards that can be enforced. In comparison, developers of guidelines with a broader scope may have purposefully tried to not make assumptions about design or approach in an attempt to accommodate studies that share a single feature (e.g. population or method) but vary in all others, such as their design or ontology.

The division could also reflect variation in developers' aims. Transparency may be the end goal for most, but others may consider reporting standards to be a stepping stone towards influencing (what they consider to be) good design.

<!-- #TODO: connect their findings to prior empirical work, theories, and/or frameworks -->

### Implications

#### Contributions to the field

* advancement of the field (of RGs). First time this approach has been taken.
  * First time RG dissemination has been thought of in this way.
  * First step towards a unified dissemination plan backed up by theory
* Implications for my work
  * Will underpin future feasibility and evaluation studies
* Additional implications for EQUATOR (that I don't cover in this thesis)
* Implications for guideline developers
* Implications for other stakeholders

These results will be of use to the reporting guideline community. Developers may find inspiration here when writing or revising guidance. At the time of writing, the EQUATOR Network was in the process of updating its advice for guideline developers and was hoping to redesign their website. These results will be pertinent to both of these projects.

#### Transferability

* generalizability
* transfer to other such interventions
Although only a few reporting guideline development groups took part in this study, most ideas identified were abstract enough to generalise to most reporting guidance, which tend to be developed and distributed in similar ways; (e.g., all development groups will have to consider what guidance to create, its scope, how to communicate it clearly and how to disseminate it). Some ideas may even generalise to other interventions to encourage good research practices (e.g., to communicate personal benefits, not to patronize researchers).

Thinking about transferability, the ideas here could be of interest to developers of other kinds of guidelines or guideline (e.g., clinical guidelines, critical appraisal tools like CASP and latitude #REF). More interestingly (to me at least), is the transferability of the _approach_. Although theories of behaviour change are often used in bealth care and business settings, it appears less common in meta-research. I elaborate on this in (@sec-where-do-i-sit) but focussing on this particular step, identifying ways to change behaviour, without a framework brainstorming may get "stuck" on certain types of intervention (in my experience, regulation, education, and training) and neglect others. Attending a workshop in early 2023, we were tasked with brainstorming ways to reduce bias in funding application assessment. One participant gave a rich account of how their team re-designed their system to minimise opportunity for bias, published case studies of how it affects applicants, how they praise examples of good practice, hold people to account when needed, and run training courses. These examples of environmental restructuring, persuasion, incentivization, and coercion were overlooked by the facilitator, who only wrote down 'training'. Familiarization with behaviour change frameworks would benefit future facilitators.

## Limitations, and future work

limitations:
  
* all western and native english speakers
* We purposefully didn't rate or rank ideas. The BCW suggests using APEASE criteria which stands for #TODO. Different stakeholders will rank ideas differently especially with regards to cost-effectiveness.
* Could have included funders, more journals, or other experts. Whilst analysing the data ideas, the software developer inside of me continued to come up with ideas. For example, when considering how to make resources findable nobody considered search engine optimization. Enriching websites with metadata so that search engines can index them properly is marketing 1-0-1, and including phrases like "how to write" or "how to describe" may help authors find researchers earlier in their research. SEO seems obvious to me as a developer, but was overlooked by participants who may not be as familiar with it.  

future work: