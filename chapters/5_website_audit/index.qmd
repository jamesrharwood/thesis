---
title: "Describing who visits EQUATOR's website for disseminating reporting guidelines, and how visitors use it"
format: 
    html:
        output-file: index.html
    docx:
        output-file: JH-chapter-website-audit.docx
---

## Introduction

When trying to book her COVID vaccine booster, my mother gave up because she could not understand the website booking process. When interventions rely on a website their success relies, in part, on whether people can easily understand and use it. The same is true for reporting guidelines which are disseminated through a number of webpages like journal author guidelines, guideline-specific websites, and the focus of this chapter; the EQUATOR Network's website. 

EQUATOR's organisational aims include maintaining a "comprehensive collection of online resources providing up-to-date information, tools and other materials related to health research reporting" and to assist in the "dissemination and implementation of robust reporting guidelines". The website is the face of this "comprehensive collection" and is key to dissemination. The website's annual traffic has increased from 100,000 users to almost 1 million over the last 10 years, attracting visitors from all around the world. For context, the International Association of Scientific, Technical, and Medical Publishers estimated that 11 million people working in research and development in 2018 @stmassociationSTMGlobalBrief. Whilst these numbers will have grown since, they suggest that EQUATOR's website traffic numbers are within a single order of magnitude of its potential audience size. This is impressive, especially considering how the website was built on a shoestring budget and without any in-house expertise in software, design, or user experience. 

Despite the website's success and rising importance within the medical publishing ecosystem,  there has never been a formal investigation into how successfully the website contributes towards EQUATOR's aim of disseminating reporting guidelines. In chapter {{< var chapters.review >}} I found two studies exploring authors' awareness of EQUATOR and its website [@fullerWhatAffectsAuthors2015; @girayAssessmentKnowledgeAwareness2020a], but no studies asked authors whether they found it easy to use.

I wanted to explore how well EQUATOR's website was serving the organisation's aim of disseminating reporting guidelines, because I expected my findings to extend or add context to the list of barriers I identified in chapters {{< var chapters.synthesis >}} and {{< var chapters.survey >}}. My objectives were to answer the following questions:

1. How many people visit the website each year? 
2. Where (in the world) are visitors from, and how does this compare with the global distribution of researchers?
3. How often do visitors come back?
4. How do visitors get to the website?
5. Do visitors engage with the website?
6. What content do visitors view?
7. What reporting guideline database records do visitors view?
8. How many visitors continue to access guidance on a third party site?
9. How may visitors access publications vs. checklists?
10. Do authors manage to achieve or find what they wanted?

## Methods 

Assessing how effectively a website contributes towards an organisation's objectives is generally referred to as a website service evaluation. There is no standard definition nor approach @allisonComprehensiveFrameworkEvaluate2019. Some evaluations use in-depth qualitative methods like interviews, card-sorting, and observed browsing or task completion. In chapter {{< var chapters.pilot >}} I describe how I use some of these techniques but at this stage I wanted to perform a broad descriptive exploration of user activity examining the types of users, where they come from, and how they interacted with the website, and so I decided to explore user activity using a suite of commonly used software tools: Google Analytics, Google Tag Manager, and an automated exit survey. These are described in @tbl-definitions along with some of the core vocabulary they use.

{{< include _table_definitions.md >}}

#TODO either embed tables throughout or put them all at the end of chapters 

Google Analytics @AnalyticsToolsSolutions is a web analytics service that helps website owners track and understand users' activity. Used by 85% of websites globally, it is the most popular web analytics service by far @UsageStatisticsMarket. EQUATOR has used Google Analytics to collect data since creating their website. Mostly they use the data to report high level impact metrics to funders (such as number of visitors) but they have never used it to evaluate their site in depth.

When evaluating a website, there are a huge number of metrics you can consider; Google Analytics collects over 50 by default [@GA4AutomaticallyCollected; @GA4PredefinedUser], and Google Tag Manager @WebMobileTag allows you to collect additional custom metrics. My first seven research questions could be explored using Google Analytics default data collection settings. Questions eight and nine could not: it recorded which reporting guideline database records visitors looked at, but not how many people went on to view guidance on third party websites, or whether visitors went on to view checklists or full guidance. Therefore I used Google Tag Manager to create two custom metrics: one to count when visitors downloaded a reporting checklist file, and another to count when visitors accessed a third party website. 

The tenth question required exploring whether website users were able to access the _right_ resource. Although Google Analytics could tell us _what_ pages visitors access, it can't tell us what they _needed_, or _why_. To explore this, I decided to use PopupSmart @PopupBuilderThat to build an exit survey (an online questionnaire that pops up when a user appears to be leaving the site, for instance, if their mouse moves towards the close button or URL bar). I decided to use an open ended question in the hope of receiving richer responses. I didn't want to annoy users or block them from using the website, and I wanted to keep the survey short in the hope of maximizing repose rate, and so I decided to limit the survey to a single question. 

We decided against asking "What were you looking for today?" as that wouldn't tell us whether users had found what they needed. We considered "How easy was it to find what you were looking for?" but decided it was too closed, the word "easy" was too  subjective, and it assumed too much about the users' intent. Instead, given that the questionnaire would only appear as users prepared to leave the site, we decided to ask "Why are you leaving?". We intended to add narrower follow up questions in the future, depending on the responses to this initial, broad question. We hoped the open question  would cater to all users, whether or not they found what they needed, or whether they were leaving for any other reason. For example, one EQUATOR member joked "We might get answers like 'because it was not the right website I was looking for, I was looking for geography websites'...! haha" (spoiler alert: this was not far off the mark!).

## Results

### How many people visit the website? 

830 134 users visited equator-network.org in 2021 (see @tbl-users).

### Where (in the world) are visitors from, and how does this compare with the global distribution of researchers?

Over 800,000 users visited the EQUATOR website in 2021 (@tbl-users), 150,000 more than the previous year, thus continuing growth seen since attracting 20,000 visitors in 2008. A third of users were from the United States or United Kingdom. The geographic distribution of users didn't always align with global publishing trends. For example, Brazil accounted for the same proportion of users as the UK (7%) despite producing far fewer citable, medical documents @ScimagoJournalCountry. Conversely, China produces twice as many citable documents as the UK but accounts for only 5% of users. Two fifths of users had their browsers set to a language other than English (Table 4), most frequently Portuguese, Chinese, and Spanish. 

### How often do visitors come back?

Google Analytics classified almost all users as new (see @tbl-users), which means they had not visited the site within the previous 2 years (the default expiry limit for Google Analytics cookies). Most users only visited the site once within 2021. 

{{< include _table_users.md >}}

### How do visitors get to the website?

The source of half of the traffic was labelled as "unknown", meaning that Google Analytics had no way of knowing where that traffic came from (see @tbl-sessions). Although this could be because authors type the URL into their browser, or because they are clicking hyperlinks within offline documents, I believe it is more likely a result of journals incorrectly linking to EQUATOR's website (see discussion). A third of users arrive at the site via a search engine. An eighth of traffic was explicitly labelled as referrals from other websites, most commonly Wiley and Elsevier journals and Manuscript Central. 

A third of sessions begin with users arriving on the home page (see @tbl-landing-pages). Most other sessions begin with authors arriving directly on a reporting guideline database record page. 

### Do visitors engage with the website?

Over half of sessions (53%) ended without the user interacting with the site at all (see @tbl-sessions). Google Analytics calls this behaviour bouncing. Bounce behaviour was similar regardless of which webpage user arrive on: 45% for the home page, >50% for most reporting guideline database record pages. Two thirds of sessions lasted less than 10 seconds, suggesting little interaction.

{{< include _table_sessions.md >}}

{{< include _table_landing_pages.md >}}

### What content do visitors view?

Reporting guideline database record pages were viewed in half of all sessions (see @tbl-sessions). The home page was viewed in a third of sessions. The rest of the website is organised within the menu categories Library, Toolkits, Courses and Events, News, Blog, Librarian Network, and Content. Hardly any of these categories receive meaningful traffic. Only 7% of sessions included a view of any page listed within the Library category. All other content categories were viewed in 1% of sessions or fewer. 

### What guideline database records do visitors view?

There are over 500 reporting guidelines indexed in EQUATOR's database, but few are viewed regularly. STROBE was the most viewed reporting guideline, viewed in 110k out of 600k sessions in the first 6 months of 2022. These numbers dropped rapidly: SQUIRE, the tenth most viewed reporting guideline record, was viewed ten times less frequently than STROBE. Only 13 guideline database records were viewed in more than 1% of sessions (more than 6,000 sessions in six months), all of which appear in the list of "reporting guidelines for main study types" featured on EQUATOR's home page and in a side bar on all reporting guideline sub-pages. Only 65 reporting guideline pages were viewed in more than 0.1% of sessions (more than 600 sessions in six months). The remainder were viewed in hardly any sessions, or were only viewed by _bots_ (software that crawls web pages, often for search engine indexing purposes).

{{< include _table_rgs.md >}}

### How many visitors continue to access guidance on a third party site?

Many users leave the reporting guideline database page without accessing any resources. For example, the STROBE database record was viewed 110,000 times, but the checklist only downloaded 30,000 times (~1 in 3) and the link to the full guidance was only clicked 2,500 times (~1 in 44). Overall, only around 1 in 4 users end up clicking a link that will direct them to a checklist or guideline publication. 

### How many visitors access publications vs. checklists?

Of the ten most viewed reporting guideline database pages, all except COREQ and SRQR offer downloadable checklists. For STROBE, STARD, CONSORT, and SQUIRE, the checklist links are clicked more often than links to the full guidance (15:1, 8:1, 6:1, and 3:1 respectively). For PRISMA, CARE, TRIPOD, SPIRIT, link clicks to each resource are more similar (around 1:1).

### Survey data suggest some visitors may not understand what the website is about, and may not find it useful

Our survey received 33 responses in 2 weeks (see @tbl-survey-responses), after being viewed by 25,660 people, (a response rate of 0.1%).

A few indicated clearly that the user had found what they were looking for; "got what I was looking for!" wrote one user, "found what I needed!" wrote another. Other users had not been so successful, writing "Could not find what I needed", "I cannot find the guidance that I seek", "I don't see what I want", and "could not find any reporting guidelines for reporting guidelines (specifically, abstracts for reporting guidelines)". Some visitors voiced frustration with the website ("i did not under stand any thing", "The site is very complex", "Too big a mess").

Some users hinted at why they were on the website; e.g., "to get reporting guidelines", "a tool called standard for reporting qualitative research". One user wrote "word format would be more easy to fulfil", suggesting they had been looking for a checklist. Others clearly didn't understand what the EQUATOR website was about. Two authors seemed to be looking for requirements for specific journals: one wrote "format for paper submission to Hindawi", and another wrote "awful site.  I just want to know the requirements in terms of number of words and format for a submission and cannot seem to find this anywhere". Another author was looking for a "quality of life questionnaire", another for "scientific research". More cryptically, one visitor simply wrote "ALGERIA", another "Germany" (perhaps EQUATOR staff were correct to worry that their website could be mistaken as a geography resource).

Some users voiced frustration with the survey itself ("do something about your annoying pop up!"). Wary of annoying users and given the poor response rate I decided to take the survey down instead of modifying it.

{{< include _table_survey_responses.md >}}

## Discussion 

Summary:

A core objective of the EQUATOR Network website is to help the global research community to find and access reporting guidelines. My aim in this chapter was to explore how well the website serves that objective. Web analytics show that over 800,000 people visited the website in 2021, thus EQUATOR have been successful in obtaining visitors. However, once they arrive, few visitors engage with the website meaningfully. Half leave within seconds without engaging at all, and even those that stay longer rarely return. The survey responses suggest some users do not understand what the website is about or how to find what they need. Only 1 in 4 visitors click a link to a checklist or to a guideline's PubMed page. Fewer users would end up reaching the full guideline from this PubMed page, as users would have to access the published article (which may be paywalled), and then find the guidance within the publication itself which can be hidden in a table or supplement. Together, these data suggest the website has huge room for improvement.

These findings add context to a number of barriers I identified in my qualitative evidence synthesis in chapter {{< var chapters.synthesis >}} and, conversely, my synthesis offers possible explanation for some findings in this chapter. My synthesis found that authors may primarily use checklists and rarely (if ever) read the full guidance. The data in this study support this theory. Many authors do appear to access checklists over and above full guidance. This could be their intention, or it could be because EQUATOR places links to checklists at the top of reporting guideline database record pages, making them more prominent than links to full guidance. Either way, guideline developers should be aware that, for many authors, checklists may be the primary way they interact with the guidance. Hence guideline developers should ensure checklists link to the full guidance, and should include key information about the guideline like its aim, scope, and how it is intended to be used.

My thematic synthesis suggested some authors may struggle to find the most appropriate guideline for their research. Some of the survey responses echoed this barrier. Besides these survey responses, I had no way of knowing which reporting guideline would have been most appropriate for each visitor. However, some further indirect evidence comes from that fact that very few guidelines receive any meaningful traffic. Only 13 guideline database records were viewed in more than 1% of visits. The remaining guidelines form a long tail, with some guidelines receiving no traffic at all. Of course, some guidelines will naturally be accessed more often (most people would expect general guidance for systematic reviews to be accessed more than, say, guidance for eye-tracking studies in dentistry), and guidelines endorsed by journals will attract more visits than un-endorsed guidelines. But the severity of the skew suggests that authors may not be discovering guidance that is most appropriate for them. Alternatively, a cynic may interpret this skew as evidence that some reporting guidelines simply aren't useful. 

My evidence synthesis also found that authors may not know what reporting guidelines are, why they are useful, or may choose not to use them if the costs outweigh the benefits. These could explain some of the poor engagement seen int his study. If visitors do not know what reporting guidelines are then they may also not understand the purpose of a website that exists to disseminate those guidelines. If the website looks confusing (as suggested by some survey responses), then perhaps visitors expect the costs of using it (time and effort) outweigh the benefits they might get, if any. The data from this study are not sufficient to draw any conclusions here: although they show engagement is poor, the data do not explain why or how it could be improved. This brings me to the first limitation of this study 

### Limitations

Ultimately, numbers can only tell you so much. There are many possible reasons for poor engagement. Perhaps the website's content or structure is too complex, perhaps the design puts people off. These reasons could be explored qualitatively using interviews or think aloud. 

One way to infer why visitors come to the website and what they might be trying to achieve is by looking at which website they were viewing previously. For example, if lots of visitors arrive on EQUATOR's website after clicking a link within a journal's submission system this would suggest they are in the midst of submitting an article and might be looking for a checklist. I had been hopeful that Google Analytics would tell us this information. Unfortunately, half of the traffic comes from "unknown" sources. Google Analytics labels traffic as "unknown" when it has no information about where that traffic comes from. Although it's possible that some of this traffic comes from links within offline documents, it's far more likely that this traffic represents referral traffic from websites that are linking to EQUATOR using links that start with *http* instead of *https*. When a secure website (with an address that starts with *https*) links to a less secure address (starting with *http*) , no referral data gets sent. EQUATOR upgraded its website to use *https* years ago, but journals have continued to link to EQUATOR using the old, less secure, *http* address. Hence a lot of traffic coming from journals and submissions is being labelled as "unknown" and EQUATOR has no way of knowing which journal or stage of submission those referrals are coming from.

Another potential limitation is that Google Analytics couns cookies, not people. If a visitor clears their cookies between visits or uses multiple devices or browsers, the visitor will appear as multiple visitors. Cookies expire after 2 years by default. The proportion of new vs. returning users is thus an overestimation but, nevertheless, still high.

A final limitation is that the data presented here cannot be used to draw comparisons with other websites. For example, I was tempted to compare EQUATOR's bounce rate of 53% with eCommerce benchmarks (around 40%, from an analysis of 1068 european eCommerce websites @ecommercefoundationEcommerceBenchmarkRetail). But this comparison isn't useful. EQUATOR's website is unusual in that it is a free learning resource, not a shop, and its users are different in terms of who they are, what they are trying to do, why they are doing it, and how they get to the website. Consequently it's not clear whether EQUATOR's bounce rate should ideally be lower than, higher than, or equivalent to eCommerce websites. Perhaps it could be useful to compare EQUATOR's website with similar resources but, as yet, I've not found any with publicly available analytics. 

### Implications for future work 

Whilst writing this chapter, potential ways to improve the website naturally occurred to me and I will list some of those here. In my personal opinion, the website violates some common usability heuristics: the design is unattractive, pages are crammed with text and do not follow standard design principles (for example, the search button is situated in a bizarre location). A first step might be qualitative research to better understand who is visiting the website, their reasons for doing so, and their opinions and experiences of using it. This may shed light on why so many visitors leave without engaging. When performing this qualitative research, they should ensure to include the perspectives of non-native English speakers. In the time between writing this chapter and submitting my thesis, EQUATOR added automatic translations to their website to try to help these visitors. They could also consider using search engine optimisation to reach non-English speaking authors. For example, they could create landing pages in Chinese or Spanish, or add foreign language words to reporting guideline meta-data.

Search engine optimisation could also help EQUATOR reach more authors. To rank higher in search engines, EQUATOR could add metadata, optimize their website for mobile phones, and take advantage of Google Search's featured snippets and description features. EQUATOR could consider optimising for keywords that may help catch authors at earlier stages of writing. Google Search Console (a Google product that allows website owners to view how their site performs in Google searches) shows that when users search for "STROBE guidelines," EQUATOR's site appears at the top of search results and 36% click this result. However, if a user searches for "how to write an epidemiological report," EQUATOR drops to 29^th^ place with a click rate of 0%. EQUATOR could optimize its website to attract na√Øve authors at an early stage of writing who may not know guideline acronyms.

Optimizing pages for searchability might also help visitors discover content on the site. Currently only 13 reporting guideline receive meaningful traffic. The rest of EQUATOR's massive website goes largely unvisited. EQUATOR could consider reorganising content to make it easier to find, or pruning dead-weight to simplify the website. 

EQUATOR could also ask journals and submission systems to update how they link to EQUATOR's website. This would result in more correct referral data. This data would tell EQUATOR which journals are successfully recommending reporting guidelines and it would allow EQUATOR to infer visitors' intentions. For example, traffic from submission systems may signify authors who are in the very late stages of writing, and may be seeking a checklist.

These were ideas that came to mind as I writing this chapter. In the following chapters I describe how I worked with stakeholders to to generate ideas systematically to improve the website and to address all barriers identified thus far. 

### Conclusions

This chapter presents a first step in evaluating the EQUATOR Network's website. These data will be a useful baseline against which to compare future changes. The findings add context to some of the barriers I identified in chapters {{< var chapters.synthesis >}} and {{< var chapters.survey >}}, and demonstrate how some of those barriers apply to EQUATOR's website. This context will be useful when considering possibilities to address barriers, which is the subject of later chapters. 

### Reflections on this chapter

At first my supervisors could not understand why I wanted to write this chapter, or why I wanted to look at the EQUATOR website all. I was warned that a website "is not an intervention".  I don't think they realised how significant their website was (in attracting many visitors) or how much it could be improved (by keeping visitors engaged). Besides reporting visitor numbers to funders, EQUATOR made little use of their Google Analytics data and had no idea where visitors were coming from, what content they accessed, or how long they stayed. As a software developers these questions were marketing 1-0-1 to me, but I had to avoid jargon like "conversion rates" or "bounces" as these projected an image of corporate analysis and not research. It took a while for me to learn how to position this chapter and to convince my supervisors it belonged in a thesis. Eventually I believe I succeeded, and I smiled when a supervisor later commented with an echo of my own words: "is it worth reminding the reader that the EQUATOR website and its contents are an intervention to improve transparency and research integrity". I'm glad I succeeded, as the findings from this chapter went on to influence discussions in my workshops with EQUATOR staff in chapter {{< var chapters.workshops >}}, my design choices in chapter {{< var chapters.defining_content >}}, and were echoed by participants I interviewed in chapter {{< var chapters.pilot >}}.