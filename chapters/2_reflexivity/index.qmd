---
title: "Reflections on starting my DPhil"
format: 
    html:
        output-file: index.html
    docx:
        output-file: JH-chapter-reflexivity.docx
---

I use qualitative methods throughout my thesis. Reflection is important in qualitative research as "A researcher's background and position will affect what they choose to investigate, the angle of investigation, the methods judged most adequate for this purpose, the findings considered most appropriate, and the framing and communication of conclusions" @malterudQualitativeResearchStandards2001. More succinctly, "Despite the sterility of the instruments, we never come innocent to a research task" @cloughNarrativesFictionsEducational2002. In this chapter, I examine my own lack of innocence. I reflect on my experiences with reporting guidelines before starting this project, and the experiences of my supervisors. The remaining chapters end with shorter reflections where I consider how my beliefs may have shaped my research and how doing the research had, in turn, shaped my beliefs.

This thesis marks the ten year anniversary of my attempts to improve research reporting. My early interest came from reading about psychology's reproducibility crisis #REF, the cancer reproducibility project #REF, Ben Goldacre's Bad Pharma #REF, and Ioannidis' essay "Why Most Published Research Findings Are False" #REF. I was working in a psychology laboratory at the time, having recently finished a MSc in Neuroscience. The compelling Lancet series on research waste @macleodBiomedicalResearchIncreasing2014 drilled home a magnitude of inefficiencies in medical research. I was most stuck by the article on incomplete or unusable research reports @glasziouReducingWasteIncomplete2014, where a key takeaway was that "although reporting guidelines are important, major improvements need active enforcement" by editors or reviewers. I took Paul Glasziou's words as a call to action, and I set about creating tools to help editors enforce good reporting. 

I began by writing software to check whether a manuscript cited a reporting guideline. Next I wrote code to check the reporting of statistical analyses. These were both pet projects. My first "proper" software was a manuscript checker that evaluates whether a manuscript adheres to journal guidelines @PenelopeAi. I began working with academic journals, and came to appreciate that reporting guidelines are one of many priorities for editors, and often fall behind more pressing issues like ethics, consent, image duplication, and paper mills. 

I later worked with EQUATOR to create GoodReports.org @GoodReportsOrg, a website where authors can find and complete reporting checklists. EQUATOR and I collaborated with BMJ Open in 2018 to see whether authors improved their manuscripts after completing a checklist as part of manuscript submission @struthersGoodReportsDevelopingWebsite2021. The results were disappointing. Few authors made any changes. I was awfully demoralized. 

It was tempting to blame the failure on lazy authors paying lip service to the checklists because they know that equally-lazy editors are not going to care. Indeed, this is a refrain I have heard bandied around by frustrated guideline developers. However, in corporate environments, the customer is always right. If users do not use your product, or do not use it how you would expect them to, then your product may lack usability (users cannot understand or use it), product market fit (users do not need or want it), or awareness (users do not know about it). It is the creator's responsibility to make their product known, foolproof, and useful. 

Doing so, however, is not easy. As a software developer I rarely spoke to users and was happier behind a screen. I preferred to learn about usability best practices through reading. Although began considering usability automatically, if rudimentarily, in everything I built, I rarely tested it with real people. Awareness belongs to the domain of marketing which never appealed to me. Every entrepreneurial book covers marketing 101, including lingo like _value proposition_ (a statement of benefit), _acquisition funnels_ (the buyer's process from awareness, through interest, intent, evaluation, to purchase), and _conversion optimization_ (increasing the percentage of users performing an action). I must have absorbed titbits despite my disinterest as I could write this paragraph easily enough. 

Product market fit, however, was always a black box to me. Books often quote Henry Ford's adage "If I had asked my customers what they wanted, they would have said a faster horse". The quote captures a complexity of product market fit; what people say they want (a faster horse) is not necessarily the best solution (a car). Teasing out product market fit from conversations is difficult and I never mastered it. Instead, I would quickly latch on to an idea before I had properly investigated the problem, even if the idea was a solution nobody needed nor wanted. 

I almost fell into the same trap when starting this DPhil. In my interview I adamantly pitched a tool to allow authors to create personalised checklists by combining reporting guidelines with journal, funder, and institutional requirements. I envisioned something akin to WebCONSORT on steroids. The old me would have happily spent months racing down that rabbit hole. The new me, the me writing this today, is glad I paused and spent a year trying to better understand the problem(s) needing solutions. In hindsight, I now believe the idea to be terrible. The custom checklists would have been incredibly long and probably confusing. 

On starting my DPhil, I did not appreciate how long and confusing checklists could be. I had never used one myself, despite recommending others to do so. I held reporting guidelines in high regard, as did my three initial supervisors. Jen, Michael, and Gary are affiliated with the EQUATOR Network. Gary is Director of the UK EQUATOR Centre and an author of many reporting guidelines and a working-group member for many others. Michael studies reporting completeness, the robustness of reporting guidelines development methods, and the consolidation of different reporting guidelines for the reporting of studies of nutritional interventions. Jen is involved in many studies investigating reporting and reporting guidelines, and runs training on writing and reporting guidelines.

Charlotte joined my supervision team in my second year, once we realised my thesis was fixed on a qualitative course. Qualitative behaviour change research was new territory for Gary, Jen, Michael, and I, and we needed an expert. Charlotte came to my rescue. She has a lot of experience in qualitative research and behaviour change theory, both from her own research and from leading the Oxford course on qualitative methods. However, she had never studied reporting guidelines before, nor any other meta-research phenomenon. Charlotte has published a suggested amendment to a reporting guideline she uses in her own work @alburyGenderConsolidatedCriteria2021. Whereas Jen, Michael, and Gary can be described as reporting guideline advocates, Charlotte was a little more cool-headed. Although she felt that reporting guidelines are useful for writing up quantitative work, she found guidelines for qualitative research frustrating because they were developed from a positivist perspective, and so did not fit a lot of qualitative work.

In summary, I came to this DPhil with an existing passion for improving research, a deep respect for reporting guidelines and EQUATOR, and with determination to make something helpful after rebounding from the disappointing BMJ Open study. I had a software developer's vocabulary and mindset sitting atop slightly rusty, decade-old research experience. Core to this mindset was a belief that if people do not use what you have made in the way you want them to, then it is _your_ responsibility to change what you have made, it is not _their_ responsibility to change their behaviour. The challenge is figuring out what changes you need to make. 

Having set the scene, I'll begin my thesis where I began my research: by trying to understand why authors do not adhere to reporting guidelines. In chapter {{< var chapters.introduction >}} I described the evidence that reporting guidelines have had little effect on reporting quality. I wanted to know _why_. Chapters {{< var chapters.synthesis >}} - {{< var chapters.web-audit >}} describe my mixed method approach to finding possible answers to this question. In the next chapter, I describe how my first step was to seek and synthesise all available qualitative data exploring this question. 