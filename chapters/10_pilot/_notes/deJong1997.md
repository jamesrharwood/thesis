# [Text Evaluation Goals and Methods](https://journals.sagepub.com/doi/epdf/10.1177/1050651997011004003) by de Jong and Schellens

Includes selection, comprehension, application, acceptance, appreciation and relevance.
Evaluation methods can:

* Verify the quality of a document
* troubleshoot and improve a document
* facilitate choice between alternatives

Verification:

* Usuaully quantitative. Large sample, statistics.
* Aim is assess document as whole or in parts, or its characteristics
* Example is the Cloze test where every 5th word is deleted. Proportion of correctly guessed words is indication of comprehensibility.
* Usually done late, as a go/no go decision about whether the text is good enough to be put into circulation.
* interpretation is a challenge. You could compare with similar documents, or with standardised "usability objectives" but there isn't much literature about what those should be
* negative results are also a problem. The test may tell you _something_ is wrong, but not what, or how to fix it.

Troubleshooting:

* Aims to facilitate revision
* Qualitative (compilation of possible problems)
* Can then rank problems by probability, severity and revisability
* Example is "reader protocols" where a participant reads text aloud while verbalizing their thoughts.
* Expertise is required to make sense of the (sometimes numerous) reader problems

Choice supporting:

* aims to identify the pros and cons of alternative forms of presentation
* E.g., choices between styles (narrative vs imperative, text vs tables)
* Can be quantitative or qualitative

Troubleshooting and choice can, if done well, will ensure the document is better than the original or alternative, but not that it is actually good enough. Deficiencies may be "wired in". So they don't give a "product guarantee" but rather a "process guarantee".

## Selection

At top level - selecting the document

* Portfolio method
* text evaluation questionnaire

At second level - selecting content within the document

* Can users find the information they are looking for?
* User protocols (participants are given tasks and asked to read and think aloud as they search the document). Limited by number of search tasks can be tested
* performance test - a way of including more search tasks in a pretest. It is verification-only. Measures the degree to which the task is performed correctly. Can only be used for instructional documents.
* reading behaviour registration - actual reading process is observed and registered by means of technical devices (e.g., eye-movement procedures).

## Comprehension

* Cloze test - verification method
* Comprehension test - also veritifcation
* Any of the non-specific troubleshooting methods (e.g., plus minus) with the caveat that it won't catch _mis_-comprehension errors and that participants may search hard for things to satisfy the researchers.

## Application

* performance test. Can measure the success of outcomes and also the time.
* User protocols also possible

## Acceptance, Appreciation and Relevance / Completeness

* text evaluation questionnaire delivered as semi structured interview (for troubleshooting) or written (verification).
* Focus groups
* attitude questionnaire - verification because impossible to relate back to specific text characteristics.
* motivated choice (choice supporting method)

## Nonspecific methods

* plus minus (spontaneous reading and putting marks in the margin to signal positive or negative reaction. Then discuss marks)
* signaled stopping technique (spontaneous reading and indicating where flow of reading is disrupted and reasons for disruption. Then discuss interruptions)
* reader protocol (simultaneously read aloud and verbailise positive and negative reactions - less natural)

NB the Dutch public information practice uses plus minus and a questionnaire.