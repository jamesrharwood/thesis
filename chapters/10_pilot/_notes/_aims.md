# Possible Objectives

To trouble shoot the intervention and identify improvements. Specifically improvements to:

* Authors' immediate understanding of and feeling towards the intervention
* Authors' ability to navigate the site, find relevant guidance, resources, and content within the guidance.
* Authors' understanding of (conscious and unconscious) and feeling towards the guidance itself

Secondary objective: collect feedback from other stakeholders
Third objective: Gather opinions from guideline stakeholders about what system/infrastructure features are important to them e.g., a content management system, version control, citable web pages, whether they want to be able to edit guideline content themselves or are happy for EQUATOR to take ownership, how best to record comments/feedback from users (comments section like discus, redit, academia.stackexchange, hypothes.is).

## Notes on feasibility study objectives

What are our objectives?
See a useful [list of questions](https://pilotfeasibilitystudies.biomedcentral.com/articles/10.1186/s40814-015-0026-y/tables/2). Interesting questions:
  
    * intervention development. To what extent does the planned intervention need to be refined or adapted to make it more acceptable to users or more relevant or useful to the specific context in which it is delivered?
    * Perceived value, benefits, harms or unintended consequences of the intervention. What value do service providers and intervention users place on the intervention and the outcomes it plans to deliver? What benefits and harms do they feel they have experienced from the intervention so that these can be measured in the full trial?
    * Acceptability of intervention in principle. Are service users or health care providers unhappy with any aspect of the content or delivery of the intervention?
    * Breadth and selection of outcomes. Are outcomes important to service users selected for measurement in the full trialâ€”both primary and secondary? Do some trial participants feel that they have experienced or noticed improvements in some outcomes that need to be included in the full trial?

Generate ideas of how to refine the new site?

    * Show variations of value statement/design
    * Ask authors to describe things in their own words

Assert acceptability?

    * Can that even be done qualitatively?
    * Perhaps we could set quantitative stopping criteria e.g.
        * At least 8/10 people muse be able to describe what reporting guidelines are after 5 second test
        * But would that tell us how to fix? Need qualitative follow-up. E.g., "What would be a better description?"
    * Could use [task scenarios](https://www.nngroup.com/articles/task-scenarios-usability-testing/)

Demonstrate hypothesis potential?

On reflection I'm deciding against this. Doing a quantitative comparison would require a much higher sample size. We could embed a qualitative assessment as part of it. But I suspect this could be better to do _next_, perhaps as a kinda "phase 1" randomised study, in preparation for a "phase 2" randomised study where we actually deploy a new website version and look at impact on reporting in a real journal.

    * Is there sufficient grounds to believe that our modified intervention will be better than existing?
    * E.g., Compare 5 second test performance between old and new site
    * Could use [Microsoft Desirability Toolkit](https://www.nngroup.com/articles/desirability-reaction-words/), here is a [case study](https://dl.acm.org/doi/epdf/10.1145/1753846.1754217)
    * Could record videos if we face objections from RG developers
    * could embed qualitative info into a randomised evaluation of:
      * time to find search
      * time to find correct RG
      * # that find right RG
      * # that correctly understand what RGs are, how they can be used and their benefits
      * # A measure of satisfaction, like System Usability Scale (NB Usability is defined by ISO as effectiveness, efficiency, and satisfaction).

    <!-- Can we obtain ethics for everything just in case, even if we don't do it? Including videos? -->
